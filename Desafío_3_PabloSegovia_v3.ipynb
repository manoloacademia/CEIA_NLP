{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3yeJGnCYxuF"
      },
      "source": [
        "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## Predicción de próxima palabra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv5PEwGzZA9-"
      },
      "source": [
        "### Objetivo\n",
        "El objetivo es entrenar un modelo de lenguaje basado en arquitectura de redes recurrentes a partir de un corpus de texto. En el transcurso del ejercicio se explorarán técnicas de generación de secuencias y se medirá la calidad de las mismas calculando la perplejidad. Parte del ejercicio consiste en estructurar adecuadamente el dataset para este problema."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Y-QdFbHZYj7C"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import io\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, Dropout, Conv1D, Bidirectional, MaxPooling1D\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTvXlEKQZdqx"
      },
      "source": [
        "### Datos\n",
        "Utilizaremos como dataset canciones de bandas de habla inglés."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IkdPfrQJZdB5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e28dd75b-cf87-42c0-f7ef-3676a161a16c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-11 20:56:54--  http://songs_dataset.zip/\n",
            "Resolving songs_dataset.zip (songs_dataset.zip)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘songs_dataset.zip’\n",
            "--2024-04-11 20:56:54--  https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/raw/main/datasets/songs_dataset.zip\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/datasets/songs_dataset.zip [following]\n",
            "--2024-04-11 20:56:55--  https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/datasets/songs_dataset.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2075036 (2.0M) [application/zip]\n",
            "Saving to: ‘songs_dataset.zip’\n",
            "\n",
            "songs_dataset.zip   100%[===================>]   1.98M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-04-11 20:56:55 (152 MB/s) - ‘songs_dataset.zip’ saved [2075036/2075036]\n",
            "\n",
            "FINISHED --2024-04-11 20:56:55--\n",
            "Total wall clock time: 0.5s\n",
            "Downloaded: 1 files, 2.0M in 0.01s (152 MB/s)\n"
          ]
        }
      ],
      "source": [
        "# Descargar la carpeta de dataset\n",
        "import os\n",
        "import platform\n",
        "if os.access('./songs_dataset', os.F_OK) is False:\n",
        "    if os.access('songs_dataset.zip', os.F_OK) is False:\n",
        "        if platform.system() == 'Windows':\n",
        "            !curl https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/datasets/songs_dataset.zip -o songs_dataset.zip\n",
        "        else:\n",
        "            !wget songs_dataset.zip https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/raw/main/datasets/songs_dataset.zip\n",
        "    !unzip -q songs_dataset.zip\n",
        "else:\n",
        "    print(\"El dataset ya se encuentra descargado\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6j-3nQ4lZjfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5604c5b0-600f-4c4f-8a12-4d166fd35792"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['prince.txt',\n",
              " 'johnny-cash.txt',\n",
              " 'lin-manuel-miranda.txt',\n",
              " 'missy-elliott.txt',\n",
              " 'bruce-springsteen.txt',\n",
              " 'lorde.txt',\n",
              " 'drake.txt',\n",
              " 'michael-jackson.txt',\n",
              " 'dolly-parton.txt',\n",
              " 'jimi-hendrix.txt',\n",
              " 'britney-spears.txt',\n",
              " 'bieber.txt',\n",
              " 'bjork.txt',\n",
              " 'dr-seuss.txt',\n",
              " 'disney.txt',\n",
              " 'Lil_Wayne.txt',\n",
              " 'eminem.txt',\n",
              " 'al-green.txt',\n",
              " 'alicia-keys.txt',\n",
              " 'blink-182.txt',\n",
              " 'notorious_big.txt',\n",
              " 'janisjoplin.txt',\n",
              " 'amy-winehouse.txt',\n",
              " 'beatles.txt',\n",
              " 'radiohead.txt',\n",
              " 'notorious-big.txt',\n",
              " 'joni-mitchell.txt',\n",
              " 'Kanye_West.txt',\n",
              " 'bruno-mars.txt',\n",
              " 'kanye.txt',\n",
              " 'nicki-minaj.txt',\n",
              " 'leonard-cohen.txt',\n",
              " 'bob-dylan.txt',\n",
              " 'patti-smith.txt',\n",
              " 'nickelback.txt',\n",
              " 'nirvana.txt',\n",
              " 'lil-wayne.txt',\n",
              " 'adele.txt',\n",
              " 'cake.txt',\n",
              " 'bob-marley.txt',\n",
              " 'paul-simon.txt',\n",
              " 'nursery_rhymes.txt',\n",
              " 'lady-gaga.txt',\n",
              " 'r-kelly.txt',\n",
              " 'kanye-west.txt',\n",
              " 'ludacris.txt',\n",
              " 'dj-khaled.txt',\n",
              " 'rihanna.txt',\n",
              " 'dickinson.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Posibles bandas\n",
        "os.listdir(\"./songs_dataset/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Gb39v3PaZmRH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "outputId": "fae5bbb1-3bd1-46fc-d77b-61aa97807df3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-91c4bad52ba1>:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  df = pd.read_csv('songs_dataset/beatles.txt', sep='/n', header=None)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   0\n",
              "0      Yesterday, all my troubles seemed so far away\n",
              "1        Now it looks as though they're here to stay\n",
              "2  Oh, I believe in yesterday Suddenly, I'm not h...\n",
              "3                  There's a shadow hanging over me.\n",
              "4  Oh, yesterday came suddenly Why she had to go ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c4cf0133-d214-43e0-aaa3-c0b8b3088596\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Yesterday, all my troubles seemed so far away</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Now it looks as though they're here to stay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Oh, I believe in yesterday Suddenly, I'm not h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>There's a shadow hanging over me.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Oh, yesterday came suddenly Why she had to go ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c4cf0133-d214-43e0-aaa3-c0b8b3088596')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c4cf0133-d214-43e0-aaa3-c0b8b3088596 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c4cf0133-d214-43e0-aaa3-c0b8b3088596');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b9022b30-9769-45bc-b1ae-c7bddec6dadc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b9022b30-9769-45bc-b1ae-c7bddec6dadc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b9022b30-9769-45bc-b1ae-c7bddec6dadc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1846,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1380,\n        \"samples\": [\n          \"I just need someone to love\",\n          \"Well it's my birthday too--yeah\",\n          \"Yes, you can radiate everything you are\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Armar el dataset utilizando salto de línea para separar las oraciones/docs\n",
        "df = pd.read_csv('songs_dataset/beatles.txt', sep='/n', header=None)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consideraremos que cada secuencia para este dataset es un verso.\n",
        "\n",
        "Una de las primeras decisiones que hay que tomar es el tamaño de contexto de tokens máximo que puede consumir el modelo. Este podría ser un hiperparámetro del problema.\n",
        "\n",
        "Para elegir el tamaño de contexto máximo para este problema se puede explorar el dataset, para ello:\n",
        "- se consideran las palabras como términos.\n",
        "- se segmentará el texto de todos los versos del dataset y ses explorará la cantidad de términos presentes.\n",
        "\n"
      ],
      "metadata": {
        "id": "VeMpWpiyG5Ya"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "riT898QlZnmF",
        "outputId": "2a6db368-55c4-4ca8-ecbf-98800a322b5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de documentos: 1846\n"
          ]
        }
      ],
      "source": [
        "print(\"Cantidad de documentos:\", df.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Elegir el tamaño del contexto"
      ],
      "metadata": {
        "id": "cP1JdiOIKQWi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "m5FeTaGvbDbw"
      },
      "outputs": [],
      "source": [
        "# Usaremos las utilidades de procesamiento de textos y secuencias de Keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer # equivalente a ltokenizer de nltk\n",
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence # equivalente a word_tokenize de nltk\n",
        "from tensorflow.keras.utils import pad_sequences # se utilizará para padding\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cada verso lo guardamos en una lista\n",
        "text = list(df.loc[:,0])\n",
        "text"
      ],
      "metadata": {
        "id": "jveeyMVKHn9J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08b7cb99-2015-40d4-8de2-452e81778a9e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Yesterday, all my troubles seemed so far away',\n",
              " \"Now it looks as though they're here to stay\",\n",
              " \"Oh, I believe in yesterday Suddenly, I'm not half the man I used to be\",\n",
              " \"There's a shadow hanging over me.\",\n",
              " \"Oh, yesterday came suddenly Why she had to go I don't know she wouldn't say\",\n",
              " 'I said something wrong, now I long for yesterday Yesterday, love was such an easy game to play',\n",
              " 'Now I need a place to hide away',\n",
              " \"Oh, I believe in yesterday Why she had to go I don't know she wouldn't say\",\n",
              " 'I said something wrong, now I long for yesterday Yesterday, love was such an easy game to play',\n",
              " 'Now I need a place to hide away',\n",
              " 'Oh, I believe in yesterday',\n",
              " 'Mm mm mm mm mm mm mm When I find myself in times of trouble, Mother Mary comes to me',\n",
              " 'Speaking words of wisdom, let it be',\n",
              " 'And in my hour of darkness she is standing right in front of me',\n",
              " 'Speaking words of wisdom, let it be',\n",
              " 'Let it be, let it be, let it be, let it be',\n",
              " 'Whisper words of wisdom, let it be And when the broken hearted people living in the world agree',\n",
              " 'There will be an answer, let it be',\n",
              " 'For though they may be parted, there is still a chance that they will see',\n",
              " 'There will be an answer, let it be',\n",
              " 'Let it be, let it be, let it be, let it be',\n",
              " 'There will be an answer, let it be',\n",
              " 'Let it be, let it be, let it be, let it be',\n",
              " 'Whisper words of wisdom, let it be',\n",
              " 'Let it be, let it be, let it be, let it be',\n",
              " 'Whisper words of wisdom, let it be And when the night is cloudy there is still a light that shines on me',\n",
              " 'Shine until tomorrow, let it be',\n",
              " 'I wake up to the sound of music, Mother Mary comes to me',\n",
              " 'Speaking words of wisdom, let it be',\n",
              " 'Let it be, let it be, let it be, yeah, let it be',\n",
              " 'There will be an answer, let it be',\n",
              " 'Let it be, let it be, let it be, yeah, let it be',\n",
              " 'Whisper words of wisdom, let it be Words are flowing out like',\n",
              " 'Endless rain into a paper cup',\n",
              " 'They slither wildly as they slip away across the universe.',\n",
              " 'Pools of sorrow waves of joy',\n",
              " 'Are drifting through my opened mind',\n",
              " 'Possessing and caressing me. Jai Guru Deva. Om',\n",
              " \"Nothing's gonna change my world\",\n",
              " \"Nothing's gonna change my world\",\n",
              " \"Nothing's gonna change my world\",\n",
              " \"Nothing's gonna change my world Images of broken light, which\",\n",
              " 'Dance before me like a million eyes,',\n",
              " 'They call me on and on across the universe.',\n",
              " 'Thoughts meander like a',\n",
              " 'Restless wind inside a letter box',\n",
              " 'They tumble blindly as they make their way across the universe. Jai Guru Deva. Om',\n",
              " \"Nothing's gonna change my world\",\n",
              " \"Nothing's gonna change my world\",\n",
              " \"Nothing's gonna change my world\",\n",
              " \"Nothing's gonna change my world Sounds of laughter, shades of life\",\n",
              " 'Are ringing through my opened ears',\n",
              " 'Inciting and inviting me.',\n",
              " 'Limitless undying love, which',\n",
              " 'Shines around me like a million suns,',\n",
              " 'It calls me on and on across the universe Jai Guru Deva, om.',\n",
              " \"Nothing's gonna change my world\",\n",
              " \"Nothing's gonna change my world\",\n",
              " \"Nothing's gonna change my world\",\n",
              " \"Nothing's gonna change my world Jai Guru Deva\",\n",
              " 'Jai Guru Deva',\n",
              " 'Jai Guru Deva',\n",
              " 'Jai Guru Deva',\n",
              " \"Jai Guru Deva Hey Jude, don't make it bad\",\n",
              " 'Take a sad song and make it better',\n",
              " 'Remember to let her into your heart',\n",
              " \"Then you can start to make it better Hey Jude, don't be afraid\",\n",
              " 'You were made to go out and get her',\n",
              " 'The minute you let her under your skin',\n",
              " 'Then you begin to make it better And anytime you feel the pain, hey Jude, refrain',\n",
              " \"Don't carry the world upon your shoulders\",\n",
              " \"For well you know that it's a fool who plays it cool\",\n",
              " 'By making his world a little colder',\n",
              " \"Nah nah nah nah nah nah nah nah nah Hey Jude, don't let me down\",\n",
              " 'You have found her, now go and get her',\n",
              " 'Remember to let her into your heart',\n",
              " 'Then you can start to make it better So let it out and let it in, hey Jude, begin',\n",
              " \"You're waiting for someone to perform with\",\n",
              " \"And don't you know that it's just you, hey Jude, you'll do\",\n",
              " 'The movement you need is on your shoulder',\n",
              " \"Nah nah nah nah nah nah nah nah nah yeah Hey Jude, don't make it bad\",\n",
              " 'Take a sad song and make it better',\n",
              " 'Remember to let her under your skin',\n",
              " \"Then you'll begin to make it\",\n",
              " 'Better better better better better better, oh Nah nah nah nah nah nah, nah nah nah, hey Jude',\n",
              " 'Nah nah nah nah nah nah, nah nah nah, hey Jude',\n",
              " 'Nah nah nah nah nah nah, nah nah nah, hey Jude',\n",
              " 'Nah nah nah nah nah nah, nah nah nah, hey Jude',\n",
              " 'Nah nah nah nah nah nah, nah nah nah, hey Jude',\n",
              " 'Nah nah nah nah nah nah, nah nah nah, hey Jude',\n",
              " 'Nah nah nah nah nah nah, nah nah nah, hey Jude',\n",
              " 'Nah nah nah nah nah nah, nah nah nah, hey Jude',\n",
              " 'Nah nah nah nah nah nah, nah nah nah, hey Jude',\n",
              " 'Nah nah nah nah nah nah, nah nah nah, hey Jude',\n",
              " 'Nah nah nah nah nah nah, nah nah nah, hey Jude',\n",
              " 'Nah nah nah nah nah nah, nah nah nah, hey Jude',\n",
              " 'Nah nah nah nah nah nah, nah nah nah, hey Jude',\n",
              " 'Nah nah nah nah nah nah, nah nah nah, hey Jude',\n",
              " 'Nah nah nah nah nah nah, nah nah nah, hey Jude',\n",
              " \"Nah nah nah nah nah nah, nah nah nah, hey Jude There are places I'll remember\",\n",
              " 'All my life, though some have changed',\n",
              " 'Some forever, not for better',\n",
              " 'Some have gone and some remain',\n",
              " 'All these places have their moments',\n",
              " 'With lovers and friends I still can recall',\n",
              " 'Some are dead and some are living',\n",
              " \"In my life, I've loved them all But of all these friends and lovers\",\n",
              " 'There is no one compares with you',\n",
              " 'And these memories lose their meaning',\n",
              " 'When I think of love as something new',\n",
              " \"Though I know I'll never lose affection\",\n",
              " 'For people and things that went before',\n",
              " \"I know I'll often stop and think about them\",\n",
              " \"In my life, I love you more Though I know I'll never lose affection\",\n",
              " 'For people and things that went before',\n",
              " \"I know I'll often stop and think about them\",\n",
              " 'In my life, I love you more',\n",
              " 'In my life-- I love you more Blackbird singing in the dead of night',\n",
              " 'Take these broken wings and learn to fly',\n",
              " 'All your life',\n",
              " 'You were only waiting for this moment to arise Blackbird singing in the dead of night',\n",
              " 'Take these sunken eyes and learn to see',\n",
              " 'All your life',\n",
              " 'You were only waiting for this moment to be free Blackbird fly, blackbird fly',\n",
              " 'Into the light of the dark black night Blackbird fly, blackbird fly',\n",
              " 'Into the light of the dark black night Blackbird singing in the dead of night',\n",
              " 'Take these broken wings and learn to fly',\n",
              " 'All your life',\n",
              " 'You were only waiting for this moment to arise',\n",
              " 'You were only waiting for this moment to arise',\n",
              " 'You were only waiting for this moment to arise Here comes the sun (doo doo doo doo)',\n",
              " 'Here comes the sun, and I say',\n",
              " \"It's all right Little darling, it's been a long cold lonely winter\",\n",
              " \"Little darling, it feels like years since it's been here\",\n",
              " 'Here comes the sun',\n",
              " 'Here comes the sun, and I say',\n",
              " \"It's all right Little darling, the smiles returning to the faces\",\n",
              " \"Little darling, it seems like years since it's been here\",\n",
              " 'Here comes the sun',\n",
              " 'Here comes the sun, and I say',\n",
              " \"It's all right Sun, sun, sun, here it comes\",\n",
              " 'Sun, sun, sun, here it comes',\n",
              " 'Sun, sun, sun, here it comes',\n",
              " 'Sun, sun, sun, here it comes',\n",
              " 'Sun, sun, sun, here it comes Little darling, I feel that ice is slowly melting',\n",
              " \"Little darling, it seems like years since it's been clear\",\n",
              " 'Here comes the sun',\n",
              " 'Here comes the sun, and I say',\n",
              " \"It's all right Here comes the sun\",\n",
              " 'Here comes the sun, and I say',\n",
              " \"It's all right\",\n",
              " \"It's all right Once there was a way,\",\n",
              " 'to get back homeward,',\n",
              " 'Once there was a way,',\n",
              " 'to get back home',\n",
              " 'Sleep pretty darling do not cry,',\n",
              " 'and I will sing a lullaby Golden slumbers fill your eyes,',\n",
              " 'smiles awake you when you rise',\n",
              " 'Sleep pretty darling do not cry,',\n",
              " 'and I will sing a lullaby Once there was a way,',\n",
              " 'to get back homeward,',\n",
              " 'Once there was a way,',\n",
              " 'to get back home',\n",
              " 'Sleep pretty darling do not cry,',\n",
              " \"and I will sing a lullaby Boy you're gonna carry that weight,\",\n",
              " 'carry that weight for a long time',\n",
              " \"Boy you're gonna carry that weight,\",\n",
              " 'carry that weight for a long time I never give you my pillow,',\n",
              " 'I only send you my invitations',\n",
              " 'And in the middle of the celebrations,',\n",
              " \"I break down Boy you're gonna carry that weight,\",\n",
              " 'carry that weight for a long time',\n",
              " \"Boy you're gonna carry that weight,\",\n",
              " 'carry that weight for a long time Oh yeah, all right,',\n",
              " 'are you gonna be in my dreams tonight? Love you, love you, love you, love you, love you, love you',\n",
              " 'Love you, love you, love you, love you, love you, love you',\n",
              " 'Love you, love you, love you, love you, love you, love you',\n",
              " 'Love you, love you, love you, love you, love you, love you',\n",
              " 'Love you, love you, love you, love you, love you, love you And in the end,',\n",
              " 'the love you take,',\n",
              " 'is equal to the love you make,',\n",
              " \"Ah Love, love, love, love, love, love, love, love, love. There's nothing you can do that can't be done.\",\n",
              " \"Nothing you can sing that can't be sung.\",\n",
              " 'Nothing you can say, but you can learn',\n",
              " 'How to play the game',\n",
              " \"It's easy.\",\n",
              " \"Nothing you can make that can't be made.\",\n",
              " \"No one you can save that can't be saved.\",\n",
              " 'Nothing you can do, but you can learn',\n",
              " 'How to be you in time',\n",
              " \"It's easy. All you need is love, all you need is love,\",\n",
              " 'All you need is love, love. Love is all you need.',\n",
              " 'Love, love, love, love, love, love, love, love, love.',\n",
              " 'All you need is love, all you need is love,',\n",
              " \"All you need is love, love. Love is all you need. There's nothing you can know that isn't known.\",\n",
              " \"Nothing you can see that isn't shown.\",\n",
              " \"There's nowhere you can be that isn't where\",\n",
              " \"You're meant to be\",\n",
              " \"It's easy. All you need is love, all you need is love,\",\n",
              " 'All you need is love, love. Love is all you need.',\n",
              " 'All you need is love. (All together now).',\n",
              " 'All you need is love. (Everybody).',\n",
              " 'All you need is love, love. Love is all you need.',\n",
              " 'Love is all you need.',\n",
              " 'Love is all you need (Yesterday)',\n",
              " '(Oh yeah)',\n",
              " '(She love you, yeah, yeah, yeah)',\n",
              " '(She love you, yeah, yeah, yeah)',\n",
              " '(Oh, yesterday) There are places I remember all my life',\n",
              " 'Though some have changed',\n",
              " 'Some forever, not for better',\n",
              " 'Some have gone and some remain All these places have their moments',\n",
              " 'Of lovers and friends I still can recall',\n",
              " 'Some are dead and some are living',\n",
              " 'In my life I loved them all And with all these friends and lovers',\n",
              " 'There is no one compares with you',\n",
              " \"And these mem'ries lose their meaning\",\n",
              " \"When I think of love as something new And I know I'll never lose affection\",\n",
              " 'For people and things that went before',\n",
              " \"I know I'll often stop and think about them\",\n",
              " \"In my life I loved you more And I know I'll never lose affection\",\n",
              " 'For people and things that went before',\n",
              " \"I know I'll often stop and think about them\",\n",
              " 'In my life I loved you more',\n",
              " 'In my life I loved you more Let me take you down',\n",
              " \"'Cause I'm going to Strawberry Fields\",\n",
              " 'Nothing is real',\n",
              " 'And nothing to get hung about',\n",
              " 'Strawberry Fields forever Living is easy with eyes closed',\n",
              " 'Misunderstanding all you see',\n",
              " \"It's getting hard to be someone\",\n",
              " 'But it all works out',\n",
              " \"It doesn't matter much to me Let me take you down\",\n",
              " \"'Cause I'm going to Strawberry Fields\",\n",
              " 'Nothing is real',\n",
              " 'And nothing to get hung about',\n",
              " 'Strawberry Fields forever No one I think is in my tree',\n",
              " 'I mean it must be high or low',\n",
              " \"That is you know you can't tune it\",\n",
              " \"But it's all right\",\n",
              " \"That is I think it's not too bad Let me take you down\",\n",
              " \"'Cause I'm going to Strawberry Fields\",\n",
              " 'Nothing is real',\n",
              " 'And nothing to get hung about',\n",
              " \"Strawberry Fields forever Always know sometimes it's me\",\n",
              " \"But you know I know when it's a dream\",\n",
              " 'I think I know I mean a \"Yes\"',\n",
              " \"But it's all wrong\",\n",
              " 'That is I think I disagree Let me take you down',\n",
              " \"'Cause I'm going to Strawberry Fields\",\n",
              " 'Nothing is real',\n",
              " 'And nothing to get hung about',\n",
              " 'Strawberry Fields forever',\n",
              " 'Strawberry Fields forever',\n",
              " 'Strawberry Fields forever Desmond has a barrow in the marketplace',\n",
              " 'Molly is the singer in a band',\n",
              " 'Desmond says to Molly girl I like your face',\n",
              " 'And Molly says this as she takes him by the hand [Chorus]',\n",
              " 'Ob la di ob la da life goes on bra',\n",
              " 'La la how the life goes on',\n",
              " 'Ob la di ob la da life goes on bra',\n",
              " \"La la how the life goes on Desmond takes a trolley to the jeweler's store\",\n",
              " 'Buys a twenty carat golden ring',\n",
              " 'Takes it back to Molly waiting at the door',\n",
              " 'And as he gives it to her she begins to sing [Chorus] In a couple of years they have built',\n",
              " 'A home sweet home',\n",
              " 'With a couple of kids running in the yard',\n",
              " 'Of Desmond and Molly Jones Happy ever after in the market place',\n",
              " 'Desmond lets the children lend a hand',\n",
              " 'Molly stays at home and does her pretty face',\n",
              " 'And in the evening she still sings it with the band [Chorus] In a couple of years they have built',\n",
              " 'A home sweet home',\n",
              " 'With a couple of kids running in the yard',\n",
              " 'Of Desmond and Molly Jones Happy ever after in the market place',\n",
              " 'Molly lets the children lend a hand',\n",
              " 'Desmond stays at home and does his pretty face',\n",
              " \"And in the evening he's a singer with the band [Chorus] And if you want some fun sing ob la di bla da When I get older, losing my hair, many years from now\",\n",
              " 'Will you still be sending me a valentine, birthday greetings, bottle of wine?',\n",
              " \"If I'd been out 'til quarter to three, would you lock the door?\",\n",
              " \"Will you still need me, will you still feed me, when I'm sixty-four? You'll be older too\",\n",
              " 'Ah',\n",
              " 'And, if you say the word, I could stay with you I could be handy, mending a fuse, when your lights have gone',\n",
              " 'You can knit a sweater by the fireside, Sunday mornings, go for a ride',\n",
              " 'Doing the garden, digging the weeds, who could ask for more?',\n",
              " \"Will you still need me, will you still feed me, when I'm sixty-four? Every summer we can rent a cottage\",\n",
              " \"In the Isle of Wight if it's not too dear\",\n",
              " 'We shall scrimp and save',\n",
              " 'Ah',\n",
              " 'Grandchildren on your knee',\n",
              " 'Vera, Chuck, and Dave Send me a postcard, drop me a line, stating point of view',\n",
              " 'Indicate precisely what you mean to say, yours sincerely, wasting away',\n",
              " 'Give me your answer, fill in a form, mine forever more',\n",
              " \"Will you still need me, will you still feed me when I'm sixty-four? Oh yeah I tell you somethin'\",\n",
              " \"I think you'll understand\",\n",
              " \"When I say that somethin'\",\n",
              " 'I want to hold your hand',\n",
              " 'I want to hold your hand',\n",
              " 'I want to hold your hand Oh please say to me',\n",
              " \"You'll let me be your man\",\n",
              " 'And please say to me',\n",
              " \"You'll let me hold your hand\",\n",
              " 'Now, let me hold your hand',\n",
              " 'I want to hold your hand And when I touch you',\n",
              " 'I feel happy inside',\n",
              " \"It's such a feelin' that my love\",\n",
              " \"I can't hide\",\n",
              " \"I can't hide\",\n",
              " \"I can't hide Yeah, you got that somethin'\",\n",
              " \"I think you'll understand\",\n",
              " \"When I say that somethin'\",\n",
              " 'I want to hold your hand',\n",
              " 'I want to hold your hand',\n",
              " 'I want to hold your hand And when I touch you',\n",
              " 'I feel happy inside',\n",
              " \"It's such a feelin' that my love\",\n",
              " \"I can't hide\",\n",
              " \"I can't hide\",\n",
              " \"I can't hide Yeah, you got that somethin'\",\n",
              " \"I think you'll understand\",\n",
              " \"When I feel that somethin'\",\n",
              " 'I want to hold your hand',\n",
              " 'I want to hold your hand',\n",
              " 'I want to hold your hand',\n",
              " \"I want to hold your hand Don't let me down, don't let me down\",\n",
              " \"Don't let me down, don't let me down Nobody ever loved me like she does\",\n",
              " 'Oh, she does, yeah, she does',\n",
              " 'And if somebody loved me like she do me',\n",
              " \"Oh, she do me, yes, she does Don't let me down, don't let me down\",\n",
              " \"Don't let me down, don't let me down I'm in love for the first time\",\n",
              " \"Don't you know it's gonna last\",\n",
              " \"It's a love that lasts forever\",\n",
              " \"It's a love that had no past Don't let me down, don't let me down\",\n",
              " \"Don't let me down, don't let me down And from the first time that she really done me\",\n",
              " 'Oh, she done me, she done me good',\n",
              " 'I guess nobody ever really done me',\n",
              " \"Oh, she done me, she done me good Don't let me down, don't let me down\",\n",
              " \"Don't let me down Help, I need somebody\",\n",
              " 'Help, not just anybody',\n",
              " 'Help, you know I need someone, help When I was younger, so much younger than today',\n",
              " \"I never needed anybody's help in any way\",\n",
              " \"But now these days are gone, I'm not so self assured\",\n",
              " \"Now I find I've changed my mind and opened up the doors Help me if you can, I'm feeling down\",\n",
              " 'And I do appreciate you being round',\n",
              " 'Help me, get my feet back on the ground',\n",
              " \"Won't you please, please help me And now my life has changed in oh so many ways\",\n",
              " 'My independence seems to vanish in the haze',\n",
              " 'But every now and then I feel so insecure',\n",
              " \"I know that I just need you like I've never done before Help me if you can, I'm feeling down\",\n",
              " 'And I do appreciate you being round',\n",
              " 'Help me, get my feet back on the ground',\n",
              " \"Won't you please, please help me When I was younger, so much younger than today\",\n",
              " \"I never needed anybody's help in any way\",\n",
              " \"But now these days are gone, I'm not so self assured\",\n",
              " \"Now I find I've changed my mind and opened up the doors Help me if you can, I'm feeling down\",\n",
              " 'And I do appreciate you being round',\n",
              " 'Help me, get my feet back on the ground',\n",
              " \"Won't you please, please help me, help me, help me, oh Something in the way she moves\",\n",
              " 'Attracts me like no other lover',\n",
              " 'Something in the way she woos me',\n",
              " \"I don't want to leave her now\",\n",
              " 'You know I believe and how Somewhere in her smile she knows',\n",
              " \"That I don't need no other lover\",\n",
              " 'Something in her style that shows me',\n",
              " \"I don't want to leave her now\",\n",
              " \"You know I believe and how You're asking me will my love grow\",\n",
              " \"I don't know, I don't know\",\n",
              " 'You stick around and it may show',\n",
              " \"I don't know, I don't know Something in the way she knows\",\n",
              " 'And all I have to do is think of her',\n",
              " 'Something in the things she shows me',\n",
              " \"I don't want to leave her now\",\n",
              " 'You know I believe and how Here come old flat top',\n",
              " \"He come groovin' up slowly\",\n",
              " 'He got joo joo eyeballs',\n",
              " 'He one holy roller',\n",
              " 'He got hair down to his knee',\n",
              " 'Got to be a joker',\n",
              " 'He just do what he please He wear no shoeshine',\n",
              " 'He got toe jam football',\n",
              " 'He got monkey finger',\n",
              " 'He shoot Coca-Cola',\n",
              " 'He say I know you, you know me',\n",
              " 'One thing I can tell you is',\n",
              " 'You got to be free',\n",
              " 'Come together, right now',\n",
              " 'Over me He bad production',\n",
              " 'He got walrus gumboot',\n",
              " 'He got Ono sideboard',\n",
              " 'He one spinal cracker',\n",
              " 'He got feet down below his knee',\n",
              " 'Hold you in his armchair',\n",
              " 'You can feel his disease',\n",
              " 'Come together, right now',\n",
              " 'Over me He roller coaster',\n",
              " 'He got early warning',\n",
              " 'He got muddy water',\n",
              " 'He one Mojo filter',\n",
              " 'He say one and one and one is three',\n",
              " 'Got to be good looking',\n",
              " \"'Cause he's so hard to see\",\n",
              " 'Come together right now',\n",
              " 'Over me Come together, yeah',\n",
              " 'Come together, yeah',\n",
              " 'Come together, yeah',\n",
              " 'Come together, yeah',\n",
              " 'Come together, yeah',\n",
              " 'Come together, yeah',\n",
              " 'Come together, yeah',\n",
              " 'Come together, yeah',\n",
              " 'Come together, yeah There were bells on a hill',\n",
              " 'But I never heard them ringing',\n",
              " 'No, I never heard them at all',\n",
              " 'Till there was you There were birds in the sky',\n",
              " 'But I never saw them winging',\n",
              " 'No, I never saw them at all',\n",
              " 'Till there was you Then there was music and wonderful roses',\n",
              " 'They tell me in sweet fragrant meadows',\n",
              " 'Of dawn and dew There was love all around',\n",
              " 'But I never heard it singing',\n",
              " 'No I never heard it at all',\n",
              " 'Till there was you Then there was music and wonderful roses',\n",
              " 'They tell me in sweet fragrant meadows',\n",
              " 'Of dawn and dew There was love all around',\n",
              " 'But I never heard it singing',\n",
              " 'No, I never heard it at all',\n",
              " 'Till there was you',\n",
              " 'Till there was you You say you want a revolution',\n",
              " 'Well, you know',\n",
              " 'We all want to change the world',\n",
              " \"You tell me that it's evolution\",\n",
              " 'Well, you know',\n",
              " 'We all want to change the world But when you talk about destruction',\n",
              " \"Don't you know that you can count me out\",\n",
              " \"Don't you know it's gonna be\",\n",
              " 'All right, all right, all right You say you got a real solution',\n",
              " 'Well, you know',\n",
              " \"We'd all love to see the plan\",\n",
              " 'You ask me for a contribution',\n",
              " 'Well, you know',\n",
              " \"We're doing what we can But if you want money for people with minds that hate\",\n",
              " 'All I can tell is brother you have to wait',\n",
              " \"Don't you know it's gonna be\",\n",
              " \"All right, all right, all right You say you'll change the constitution\",\n",
              " 'Well, you know',\n",
              " 'We all want to change your head',\n",
              " \"You tell me it's the institution\",\n",
              " 'Well, you know',\n",
              " 'You better free you mind instead But if you go carrying pictures of chairman Mao',\n",
              " \"You ain't going to make it with anyone anyhow\",\n",
              " \"Don't you know it's gonna be\",\n",
              " 'All right, all right, all right',\n",
              " 'All right, all right, all right',\n",
              " 'All right, all right, all right',\n",
              " 'All right, all right In the town where I was born',\n",
              " 'Lived a man who sailed to sea',\n",
              " 'And he told us of his life',\n",
              " 'In the land of submarines',\n",
              " 'So we sailed up to the sun',\n",
              " 'Till we found a sea of green',\n",
              " 'And we lived beneath the waves',\n",
              " 'In our yellow submarine We all live in a yellow submarine',\n",
              " 'Yellow submarine, yellow submarine',\n",
              " 'We all live in a yellow submarine',\n",
              " 'Yellow submarine, yellow submarine And our friends are all aboard',\n",
              " 'Many more of them live next door',\n",
              " 'And the band begins to play We all live in a yellow submarine',\n",
              " 'Yellow submarine, yellow submarine',\n",
              " 'We all live in a yellow submarine',\n",
              " 'Yellow submarine, yellow submarine (Full speed ahead Mr. Boatswain, full speed ahead',\n",
              " 'Full speed ahead it is, Sergeant.',\n",
              " 'Cut the cable, drop the cable',\n",
              " 'Aye, Sir, aye',\n",
              " 'Captain, captain) As we live a life of ease',\n",
              " 'Every one of us has all we need',\n",
              " 'Sky of blue and sea of green',\n",
              " 'In our yellow submarine We all live in a yellow submarine',\n",
              " 'Yellow submarine, yellow submarine',\n",
              " 'We all live in a yellow submarine',\n",
              " 'Yellow submarine, yellow submarine',\n",
              " 'We all live in a yellow submarine',\n",
              " \"Yellow submarine, yellow submarine Who knows how long I've loved you\",\n",
              " 'You know I love you still',\n",
              " 'Will I wait a lonely lifetime?',\n",
              " 'If you want me to, I will And if I ever saw you',\n",
              " \"I didn't catch your name\",\n",
              " 'But it never really mattered',\n",
              " 'I will always feel the same Love you forever and forever',\n",
              " 'Love you with all my heart',\n",
              " \"Love you whenever we're together\",\n",
              " \"Love you when we're apart And when at last I find you\",\n",
              " 'Your song will fill the air',\n",
              " 'Sing it loud so I can hear you',\n",
              " 'Make it easy to be near you',\n",
              " 'For the things you do endear you to me',\n",
              " 'Oh, you know I will Love you forever and forever',\n",
              " 'Love you with all my heart',\n",
              " \"Love you whenever we're together\",\n",
              " \"Love you when we're apart And when at last I found you\",\n",
              " 'Your song will fill the air',\n",
              " 'Sing it loud so I can hear you',\n",
              " 'Make it easy to be near you',\n",
              " 'All the things you do endear you to me',\n",
              " 'Oh, you know I will',\n",
              " 'Oh, you know I will',\n",
              " 'Oh, you know I will',\n",
              " 'Oh, you know I will What would you think if I sang out of tune',\n",
              " 'Would you stand up and walk out on me',\n",
              " \"Lend me your ears and I'll sing you a song\",\n",
              " \"And I'll try not to sing out of key Oh, I get by with a little help from my friends\",\n",
              " 'Hmm, I get high with a little help from my friends',\n",
              " 'Hmm, going to try with a little help from my friends What do I do when my love is away',\n",
              " 'Does it worry you to be alone?',\n",
              " 'How do I feel by the end of the day',\n",
              " \"Are you sad because you're on your own? No, I get by with a little help from my friends\",\n",
              " 'Hmm, I get high with a little help from my friends',\n",
              " 'Hmm, going to try with a little help from my friends Do you need anybody?',\n",
              " 'I need somebody to love',\n",
              " 'Could it be anybody?',\n",
              " 'I want somebody to love Would you believe in a love at first sight?',\n",
              " \"Yes, I'm certain that it happens all the time\",\n",
              " 'What do you see when you turn out the light?',\n",
              " \"I can't tell you, but I know it's mine Oh, I get by with a little help from my friends\",\n",
              " 'Hmm, I get high with a little help from my friends',\n",
              " 'Hmm, going to try with a little help from my friends Do you need anybody?',\n",
              " 'I just need someone to love',\n",
              " 'Could it be anybody?',\n",
              " 'I want somebody to love Oh, I get by with a little help from my friends',\n",
              " 'Hmm, going to try with a little help from my friends',\n",
              " 'Oh, I get high with a little help from my friends',\n",
              " 'Yes, I get by with a little help from my friends',\n",
              " 'With a little help from my friends I am he as you are he as you are me',\n",
              " 'And we are all together',\n",
              " 'See how they run like pigs from a gun',\n",
              " 'See how they fly',\n",
              " \"I'm crying Sitting on a cornflake\",\n",
              " 'Waiting for the van to come',\n",
              " 'Corporation T-shirt, stupid bloody Tuesday',\n",
              " \"Man you've been a naughty boy\",\n",
              " 'You let your face grow long I am the eggman',\n",
              " 'They are the eggmen',\n",
              " 'I am the walrus',\n",
              " \"Goo goo g' joob Mr. City policeman sitting\",\n",
              " 'Pretty little policemen in a row',\n",
              " 'See how they fly like Lucy in the sky',\n",
              " 'See how they run',\n",
              " \"I'm crying\",\n",
              " \"I'm crying, I'm crying, I'm crying Yellow matter custard\",\n",
              " \"Dripping from a dead dog's eye\",\n",
              " 'Crabalocker fishwife',\n",
              " 'Pornographic priestess',\n",
              " \"Boy, you've been a naughty girl\",\n",
              " 'You let your knickers down I am the eggman',\n",
              " 'They are the eggmen',\n",
              " 'I am the walrus',\n",
              " \"Goo goo g' joob Sitting in an English garden\",\n",
              " 'Waiting for the sun',\n",
              " \"If the sun don't come you get a tan\",\n",
              " 'From standing in the English rain I am the eggman',\n",
              " '(\"How do you do sir\")',\n",
              " 'They are the eggmen',\n",
              " '(\"The man maintains a fortune\")',\n",
              " 'I am the walrus',\n",
              " \"Goo goo g' joob Goo Goo Goo g' joob Expert, texpert choking smokers\",\n",
              " \"Don't you think the joker laughs at you\",\n",
              " '(Ho ho ho hee hee hee hah hah hah)',\n",
              " 'See how they smile like pigs in a sty',\n",
              " 'See how they snide',\n",
              " \"I'm crying Semolina Pilchard\",\n",
              " 'Climbing up the Eiffel tower',\n",
              " 'Elementary penguin singing Hare Krishna',\n",
              " 'Man, you should have seen them kicking',\n",
              " 'Edgar Allen Poe I am the eggman',\n",
              " 'They are the eggmen',\n",
              " 'I am the walrus',\n",
              " \"Goo goo g' joob\",\n",
              " \"Goo goo goo g' joob\",\n",
              " \"Goo goo g' joob\",\n",
              " \"Goo goo goo g' joob\",\n",
              " 'Goo goo',\n",
              " 'Juba juba juba',\n",
              " 'Juba juba juba',\n",
              " 'Juba juba juba',\n",
              " \"Juba juba (Oh I'm tired, servicible villain\",\n",
              " \"Set you down father, rest you) I look at you all see the love there that's sleeping\",\n",
              " 'While my guitar gently weeps',\n",
              " 'I look at the floor and I see it needs sweeping',\n",
              " \"Still my guitar gently weeps. I don't know why nobody told you\",\n",
              " 'How to unfold your love',\n",
              " \"I don't know how someone controlled you\",\n",
              " \"They bought and sold you. I look at the world and I notice it's turning\",\n",
              " 'While my guitar gently weeps',\n",
              " 'With every mistake we must surely be learning',\n",
              " \"Still my guitar gently weeps. I don't know how you were diverted\",\n",
              " 'You were perverted too',\n",
              " \"I don't know how you were inverted\",\n",
              " \"No one alerted you. I look at you all see the love there that's sleeping\",\n",
              " 'While my guitar gently weeps',\n",
              " 'Look at you all',\n",
              " 'Still my guitar gently weeps. Oh yeah, all right',\n",
              " 'Are you gonna be in my dreams tonight? Love you, love you',\n",
              " 'Love you, love you',\n",
              " 'Love you, love you',\n",
              " 'Love you, love you',\n",
              " 'Love you, love you',\n",
              " 'Love you, love you',\n",
              " 'Love you, love you',\n",
              " 'Love you, love you',\n",
              " 'Love you, love you',\n",
              " 'Love you, love you',\n",
              " 'Love you, love you',\n",
              " 'Love you, love you And in the end, the love you take',\n",
              " 'Is equal to the love you make I read the news today, oh boy',\n",
              " 'About a lucky man who made the grade',\n",
              " 'And though the news was rather sad',\n",
              " 'Well I just had to laugh I saw the photograph',\n",
              " 'He blew his mind out in a car',\n",
              " \"He didn't notice that the lights had changed\",\n",
              " 'A crowd of people stood and stared',\n",
              " \"They'd seen his face before\",\n",
              " 'Nobody was really sure',\n",
              " 'If he was from the House of Lords I saw a film today, oh boy',\n",
              " 'The English Army had just won the war',\n",
              " 'A crowd of people turned away',\n",
              " 'But I just had to look',\n",
              " 'Having read the book',\n",
              " \"I'd love to turn you on Woke up, fell out of bed\",\n",
              " 'Dragged a comb across my head',\n",
              " 'Found my way downstairs and drank a cup',\n",
              " 'And looking up I noticed I was late',\n",
              " 'Found my coat and grabbed my hat',\n",
              " 'Made the bus in seconds flat',\n",
              " 'Found my way upstairs and had a smoke',\n",
              " 'Somebody spoke and I went into a dream I read the news today, oh boy',\n",
              " 'Four thousand holes in Blackburn, Lancashire',\n",
              " 'And though the holes were rather small',\n",
              " 'They had to count them all',\n",
              " 'Now they know how many holes it takes to fill the Albert Hall',\n",
              " \"I'd love to turn you on Michelle, ma belle\",\n",
              " 'These are words that go together well',\n",
              " 'My Michelle',\n",
              " 'Michelle, ma belle',\n",
              " 'Sont les mots qui vont tres bien ensemble',\n",
              " 'Tres bien ensemble',\n",
              " 'I love you, I love you, I love you',\n",
              " \"That's all I want to say\",\n",
              " 'Until I find a way',\n",
              " \"I will say the only words I know that you'll understand Michelle, ma belle\",\n",
              " 'Sont les mots qui vont tres bien ensemble',\n",
              " 'Tres bien ensemble',\n",
              " 'I need to, I need to, I need to',\n",
              " 'I need to make you see',\n",
              " 'Oh, what you mean to me',\n",
              " \"Until I do, I'm hoping you will know what I mean\",\n",
              " 'I love you... I want you, I want you, I want you',\n",
              " 'I think you know by now',\n",
              " \"I'll get to you somehow\",\n",
              " \"Until I do, I'm telling you so you'll understand\",\n",
              " 'Michelle, ma belle',\n",
              " 'Sont les mots qui vont tres bien ensemble',\n",
              " 'Tres bien ensemble',\n",
              " \"And I will say the only words I know that you'll understand\",\n",
              " 'My Michelle Penny Lane there is a barber showing photographs',\n",
              " \"Of every head he's had the pleasure to know.\",\n",
              " 'And all the people that come and go',\n",
              " 'Stop and say \"Hello\". On the corner is a banker with a motorcar,',\n",
              " 'And little children laugh at him behind his back.',\n",
              " 'And the banker never wears a mac',\n",
              " 'In the pouring rain, very strange. Penny Lane is in my ears and in my eyes.',\n",
              " 'There beneath the blue suburban skies',\n",
              " 'I sit, and meanwhile back',\n",
              " 'In Penny Lane there is a fireman with an hourglass,',\n",
              " 'And in his pocket is a portrait of the Queen.',\n",
              " 'He likes to keep his fire engine clean,',\n",
              " \"It's a clean machine. Penny Lane is in my ears and in my eyes.\",\n",
              " 'A four of fish and finger pies',\n",
              " 'In summer. Meanwhile back',\n",
              " 'Behind the shelter in the middle of the roundabout',\n",
              " 'The pretty nurse is selling poppies from a tray.',\n",
              " \"And though she feels as if she's in a play,\",\n",
              " 'She is anyway. In Penny Lane the barber shaves another customer,',\n",
              " 'We see the banker sitting waiting for a trim,',\n",
              " 'And then the fireman rushes in',\n",
              " 'From the pouring rain - very strange. Penny Lane is in my ears and in my eyes.',\n",
              " 'There beneath the blue suburban skies',\n",
              " 'I sit, and meanwhile back.',\n",
              " 'Penny Lane is in my ears and in my eyes.',\n",
              " 'There beneath the blue suburban skies',\n",
              " 'Penny Lane! Jojo was a man who thought he was a loner',\n",
              " \"But he knew it wouldn't last\",\n",
              " 'Jojo left his home in Tucson, Arizona',\n",
              " 'For some California grass Get back, get back',\n",
              " 'Get back to where you once belonged',\n",
              " 'Get back, get back',\n",
              " 'Get back to where you once belonged',\n",
              " 'Get back Jojo, go home Get back, get back',\n",
              " 'Back to where you once belonged',\n",
              " 'Get back, get back',\n",
              " 'Back to where you once belonged',\n",
              " 'Get back Jo Sweet Loretta Martin thought she was a woman',\n",
              " 'But she was another man',\n",
              " \"All the girls around her say she's got it coming\",\n",
              " 'But she gets it while she can Get back, get back',\n",
              " 'Get back to where you once belonged',\n",
              " 'Get back, get back',\n",
              " 'Get back to where you once belonged',\n",
              " 'Get back Loretta, go home Get back, get back',\n",
              " 'Get back to where you once belonged',\n",
              " 'Get back, get back',\n",
              " 'Get back to where you once belonged Get back, get back',\n",
              " 'Get back to where you once belonged',\n",
              " 'Get back, get back, get back Once there was a way,',\n",
              " 'To get back homeward. Once there was a way',\n",
              " 'To get back home. Sleep, pretty darling,',\n",
              " 'Dot not cry',\n",
              " 'And I will sing a lullaby. Golden slumbers,',\n",
              " 'Fill your eyes',\n",
              " 'Smiles await you when you rise',\n",
              " 'Sleep pretty darling',\n",
              " 'Do not cry',\n",
              " 'And I will sing a lullaby. Once there was a way',\n",
              " 'To get back homeward Once there was a way',\n",
              " 'To get back home Sleep, pretty darling',\n",
              " 'Do not cry',\n",
              " \"And I will sing a lullaby. You say it's your birthday\",\n",
              " \"It's my birthday too--yeah\",\n",
              " \"They say it's your birthday\",\n",
              " \"We're gonna have a good time\",\n",
              " \"I'm glad it's your birthday\",\n",
              " \"Happy birthday to you. Yes we're going to a party party\",\n",
              " \"Yes we're going to a party party\",\n",
              " \"Yes we're going to a party party. I would like you to dance--Birthday\",\n",
              " 'Take a cha-cha-cha-chance-Birthday',\n",
              " 'I would like you to dance--Birthday',\n",
              " \"Dance You say it's your birthday\",\n",
              " \"Well it's my birthday too--yeah\",\n",
              " \"You say it's your birthday\",\n",
              " \"We're gonna have a good time\",\n",
              " \"I'm glad it's your birthday\",\n",
              " 'Happy birthday to you. Because the world is round it turns me on',\n",
              " 'Because the world is round...aaaaaahhhhhh Because the wind is high it blows my mind',\n",
              " 'Because the wind is high...aaaaaaaahhhh Love is old, love is new',\n",
              " 'Love is all, love is you Because the sky is blue, it makes me cry',\n",
              " 'Because the sky is blue...aaaaaaahhhh Aaaaahhhhhhhhhh... Picture yourself in a boat on a river',\n",
              " 'With tangerine trees and marmalade skies',\n",
              " 'Somebody calls you, you answer quite slowly',\n",
              " 'A girl with kaleidoscope eyes Cellophane flowers of yellow and green',\n",
              " 'Towering over your head',\n",
              " 'Look for the girl with the sun in her eyes',\n",
              " \"And she's gone Lucy in the sky with diamonds\",\n",
              " 'Lucy in the sky with diamonds',\n",
              " 'Lucy in the sky with diamonds',\n",
              " 'Ah Follow her down to a bridge by a fountain',\n",
              " 'Where rocking horse people eat marshmallow pies',\n",
              " 'Everyone smiles as you drift past the flowers',\n",
              " 'That grow so incredibly high Newspaper taxis appear on the shore',\n",
              " 'Waiting to take you away',\n",
              " 'Climb in the back with your head in the clouds',\n",
              " \"And you're gone Lucy in the sky with diamonds\",\n",
              " 'Lucy in the sky with diamonds',\n",
              " 'Lucy in the sky with diamonds',\n",
              " 'Ah Picture yourself on a train in a station',\n",
              " 'With plasticine porters with looking glass ties',\n",
              " 'Suddenly someone is there at the turnstile',\n",
              " 'The girl with the kaleidoscope eyes Lucy in the sky with diamonds',\n",
              " 'Lucy in the sky with diamonds',\n",
              " 'Lucy in the sky with diamonds',\n",
              " 'Ah',\n",
              " 'Lucy in the sky with diamonds',\n",
              " 'Lucy in the sky with diamonds',\n",
              " 'Lucy in the sky with diamonds',\n",
              " 'Ah',\n",
              " 'Lucy in the sky with diamonds',\n",
              " 'Lucy in the sky with diamonds',\n",
              " 'Lucy in the sky with diamonds A bad little kid moved into my neighborhood',\n",
              " \"He won't do nothing right just sitting down and look so good\",\n",
              " \"He don't want to go to school and learn to read and write\",\n",
              " 'Just sits around the house and plays the rock and roll music all night',\n",
              " 'Well, he put some tacks on teachers chair',\n",
              " \"Puts chewing gum in little girl's hair\",\n",
              " 'Man, junior, behave yourself Buy every rock and roll book on the magazine stand',\n",
              " 'Every dime that he get is lost to the jukebox man',\n",
              " \"Well, he worries his teacher till at night she's ready to poop\",\n",
              " 'From rocking and a-rolling spinning in a hula hoop',\n",
              " 'Well, this rock and roll has got to stop',\n",
              " \"Junior's head is hard as rock\",\n",
              " 'Now junior, behave yourself Going tell your mama you better do what she said',\n",
              " 'Get to the barber shop and get that hair cut off your head',\n",
              " 'He took your canary and he fed it to the neighbors cat',\n",
              " \"He gave the cocker spaniel a bath in mother's laundromat\",\n",
              " \"Well, mama's head has got to stop\",\n",
              " \"Junior's head is hard as rock\",\n",
              " 'Now junior, behave yourself I give her all my love',\n",
              " \"That's all I do\",\n",
              " 'And if you saw my love',\n",
              " \"You'd love her to\",\n",
              " 'I love her She gives my everything',\n",
              " 'And tenderly',\n",
              " 'The kiss my lover brings',\n",
              " 'She brings to me',\n",
              " 'And I love her A love like ours',\n",
              " 'Could never die',\n",
              " 'As long as I',\n",
              " 'Have you near me Bright are the stars that shine',\n",
              " 'Dark is the sky',\n",
              " 'I know this love of mine',\n",
              " 'Will never die',\n",
              " 'And I love her Bright are the stars that shine',\n",
              " 'Dark is the sky',\n",
              " 'I know this love of mine',\n",
              " 'Will never die',\n",
              " 'And I love her, ooh You say \"Yes\", I say \"No\".',\n",
              " 'You say \"Stop\" and I say \"Go, go, go\".',\n",
              " 'Oh no.',\n",
              " 'You say \"Goodbye\" and I say \"Hello, hello, hello\".',\n",
              " 'I don\\'t know why you say \"Goodbye\", I say \"Hello, hello, hello\".',\n",
              " 'I don\\'t know why you say goodbye, I say hello. I say \"High\", you say \"Low\".',\n",
              " 'You say \"Why?\" And I say \"I don\\'t know\".',\n",
              " 'Oh no.',\n",
              " 'You say \"Goodbye\" and I say \"Hello, hello, hello\".',\n",
              " 'I don\\'t know why you say \"Goodbye\", I say \"Hello, hello, hello\".',\n",
              " '(Hello, goodbye, hello, goodbye. Hello, goodbye.)',\n",
              " 'I don\\'t know why you say \"Goodbye\", I say \"Hello\". (Hello, goodbye, hello, goodbye. Hello, goodbye. Hello, goodbye.)',\n",
              " 'Why, why, why, why, why, why, do you',\n",
              " 'Say \"Goodbye, goodbye, bye, bye\".',\n",
              " 'Oh no.',\n",
              " 'You say \"Goodbye\" and I say \"Hello, hello, hello\".',\n",
              " 'I don\\'t know why you say \"Goodbye\", I say \"Hello, hello, hello\".',\n",
              " 'I don\\'t know why you say \"Goodbye\", I say \"Hello\". You say \"Yes\", I say \"No\".',\n",
              " '(I say \"Yes\", but I may mean \"No\").',\n",
              " 'You say \"Stop\", I say \"Go, go, go\".',\n",
              " \"(I can stay still it's time to go).\",\n",
              " 'Oh, oh no. You say \"Goodbye\" and I say \"Hello, hello, hello\".',\n",
              " 'I don\\'t know why you say \"Goodbye\", I say \"Hello, hello, hello\".',\n",
              " 'I don\\'t know why you say \"Goodbye\", I say \"Hello, hello, hello\".',\n",
              " 'I don\\'t know why you say \"Goodbye\", I say \"Hello-wow, oh. Hello\".',\n",
              " 'Hela, heba, helloa. Hela, heba, helloa. Hela, heba, helloa.',\n",
              " 'Hela, heba, helloa. (Hela.) Hela, heba, helloa. Hela, heba, helloa.',\n",
              " 'Hela, heba, helloa. Hela, heba, helloa. Hela, heba, helloa. I once had a girl',\n",
              " 'Or should I say she once had me',\n",
              " 'She showed me her room',\n",
              " \"Isn't it good Norwegian wood? She asked me to stay\",\n",
              " 'And she told me to sit anywhere',\n",
              " 'So I looked around',\n",
              " \"And I noticed there wasn't a chair I sat on a rug biding my time\",\n",
              " 'Drinking her wine',\n",
              " 'We talked until two and then she said',\n",
              " '\"It\\'s time for bed\" She told me she worked',\n",
              " 'In the morning and started to laugh',\n",
              " \"I told her I didn't\",\n",
              " 'And crawled off to sleep in the bath And when I awoke I was alone',\n",
              " 'This bird had flown',\n",
              " 'So I lit a fire',\n",
              " \"Isn't it good Norwegian wood? Well, shake it up baby now\",\n",
              " 'Twist and shout',\n",
              " 'Come on, come on, come, come on baby now',\n",
              " 'Come on and work it on out',\n",
              " 'Well, work it on out, honey',\n",
              " 'You know you look so good',\n",
              " \"You know you got me goin' now\",\n",
              " 'Just like I know you would Well, shake it up baby now',\n",
              " 'Twist and shout',\n",
              " 'Come on, come on, come, come on baby now',\n",
              " 'Come on and work it on out',\n",
              " 'You know you twist, little girl',\n",
              " 'You know you twist so fine',\n",
              " 'Come on and twist a little closer now',\n",
              " \"And let me know that you're mine, woo Ah, ah, ah, ah, wow\",\n",
              " 'Baby now',\n",
              " 'Twist and shout',\n",
              " 'Come on, come on, come, come on baby now',\n",
              " 'Come on and work it on out',\n",
              " 'You know you twist, little girl',\n",
              " 'You know you twist so fine',\n",
              " 'Come on and twist a little closer now',\n",
              " \"And let me know that you're mine\",\n",
              " 'Well, shake it, shake it, shake it, baby now',\n",
              " 'Well, shake it, shake it, shake it, baby now',\n",
              " 'Well, shake it, shake it, shake it, baby now',\n",
              " 'Ah, ah, ah, ah She loves you, yeah, yeah, yeah',\n",
              " 'She loves you, yeah, yeah, yeah',\n",
              " \"She loves you, yeah, yeah, yeah You think you've lost your love\",\n",
              " 'Well, I saw her yesterday-yi-yay',\n",
              " \"It's you she's thinking of\",\n",
              " 'And she told me what to say-yi-yay She says she loves you',\n",
              " \"and you know that can't be bad\",\n",
              " 'Yes, she loves you',\n",
              " 'and you know you should be glad She said you hurt her so',\n",
              " 'She almost lost her mind',\n",
              " 'And now she says she knows',\n",
              " \"You're not the hurting kind She says she loves you\",\n",
              " \"and you know that can't be bad\",\n",
              " 'Yes, she loves you',\n",
              " 'and you know you should be glad Oo, she loves you, yeah, yeah, yeah',\n",
              " 'She loves you, yeah, yeah, yeah',\n",
              " 'With a love like that',\n",
              " \"You know you should be glad You know it's up to you\",\n",
              " \"I think it's only fair\",\n",
              " 'Pride can hurt you too',\n",
              " 'Apologize to her Because she loves you',\n",
              " \"and you know that can't be bad\",\n",
              " 'Yes, she loves you',\n",
              " 'and you know you should be glad Oo, she loves you, yeah, yeah, yeah',\n",
              " 'She loves you, yeah, yeah, yeah',\n",
              " 'With a love like that',\n",
              " 'You know you should be glad',\n",
              " 'With a love like that',\n",
              " 'you know you should be glad',\n",
              " 'With a love like that',\n",
              " 'you know you should be glad',\n",
              " 'Yeah, yeah, yeah,',\n",
              " 'Yeah, yeah, yeah, yeah Ah look at all the lonely people',\n",
              " 'Ah look at all the lonely people Eleanor Rigby, picks up the rice',\n",
              " 'In the church where a wedding has been',\n",
              " 'Lives in a dream',\n",
              " 'Waits at the window, wearing the face',\n",
              " 'That she keeps in a jar by the door',\n",
              " 'Who is it for All the lonely people',\n",
              " 'Where do they all come from?',\n",
              " 'All the lonely people',\n",
              " 'Where do they all belong? Father McKenzie, writing the words',\n",
              " 'Of a sermon that no one will hear',\n",
              " 'No one comes near',\n",
              " 'Look at him working, darning his socks',\n",
              " \"In the night when there's nobody there\",\n",
              " 'What does he care All the lonely people',\n",
              " 'Where do they all come from?',\n",
              " 'All the lonely people',\n",
              " 'Where do they all belong? Ah look at all the lonely people',\n",
              " 'Ah look at all the lonely people Eleanor Rigby, died in the church',\n",
              " 'And was buried along with her name',\n",
              " 'Nobody came',\n",
              " 'Father McKenzie, wiping the dirt',\n",
              " 'From his hands as he walks from the grave',\n",
              " 'No one was saved All the lonely people',\n",
              " 'Where do they all come from?',\n",
              " 'All the lonely people',\n",
              " 'Where do they all belong? Well she was just seventeen',\n",
              " 'You know what I mean',\n",
              " 'And the way she looked',\n",
              " 'Was way beyond compare',\n",
              " 'So how could I dance with another,',\n",
              " 'Oh, when I saw her standing there Well she looked at me',\n",
              " 'And I, I could see',\n",
              " 'That before too long',\n",
              " \"I'd fall in love with her\",\n",
              " \"She wouldn't dance with another\",\n",
              " 'Oh, when I saw her standing there Well my heart went boom',\n",
              " 'When I crossed that room',\n",
              " 'And I held her hand in mine Oh we danced through the night',\n",
              " 'And we held each other tight',\n",
              " 'And before too long',\n",
              " 'I fell in love with her',\n",
              " \"Now I'll never dance with another\",\n",
              " 'Oh, when I saw her standing there Well my heart went boom',\n",
              " 'When I crossed that room',\n",
              " 'And I held her hand in mine Oh we danced through the night',\n",
              " 'And we held each other tight',\n",
              " 'And before too long',\n",
              " 'I fell in love with her',\n",
              " \"Now I'll never dance with another\",\n",
              " 'Oh, when I saw her standing there',\n",
              " 'Oh, since I saw her standing there',\n",
              " \"Yeah, well since I saw her standing there Close your eyes and I'll kiss you\",\n",
              " \"Tomorrow I'll miss you\",\n",
              " \"Remember I'll always be true\",\n",
              " \"And then while I'm away\",\n",
              " \"I'll write home every day\",\n",
              " \"And I'll send all my loving to you I'll pretend that I'm kissing\",\n",
              " 'The lips I am missing',\n",
              " 'And hope that my dreams will come true',\n",
              " \"And then while I'm away\",\n",
              " \"I'll write home every day\",\n",
              " \"And I'll send all my loving to you All my loving, I will send to you\",\n",
              " \"All my loving, darling I'll be true Close your eyes and I'll kiss you\",\n",
              " \"Tomorrow I'll miss you\",\n",
              " \"Remember I'll always be true\",\n",
              " \"And then while I'm away\",\n",
              " \"I'll write home every day\",\n",
              " \"And I'll send all my loving to you All my loving, I will send to you\",\n",
              " \"All my loving, darling I'll be true\",\n",
              " 'All my loving, all my loving',\n",
              " \"Woo, all my loving, I will send to you It's been a hard day's night, and I been working like a dog\",\n",
              " \"It's been a hard day's night, I should be sleeping like a log\",\n",
              " \"But when I get home to you I'll find the things that you do\",\n",
              " 'Will make me feel alright You know I work all day to get you money to buy you things',\n",
              " \"And it's worth it just to hear you say you're going to give me everything\",\n",
              " \"So why on earth should I moan, 'cause when I get you alone\",\n",
              " \"You know I feel ok When I'm home everything seems to be right\",\n",
              " \"When I'm home feeling you holding me tight, tight Owww!\",\n",
              " \"So why on earth should I moan, 'cause when I get you alone\",\n",
              " \"You know I feel ok When I'm home everything seems to be right\",\n",
              " \"When I'm home feeling you holding me tight, tight, yeah It's been a hard day's night, and I been working like a dog\",\n",
              " \"It's been a hard day's night, I should be sleeping like a log\",\n",
              " \"But when I get home to you I'll find the things that you do\",\n",
              " 'Will make me feel alright',\n",
              " 'You know I feel alright',\n",
              " 'You know I feel alright... Love, love me do',\n",
              " 'You know I love you',\n",
              " \"I'll always be true\",\n",
              " 'So please, love me do',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# segmentamos el texto con la utilidad de Keras\n",
        "segmented_sentences = [text_to_word_sequence(sentence) for sentence in text]"
      ],
      "metadata": {
        "id": "CMu9CX34J8RQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculamos la longitud de cada secuencia\n",
        "length_sentences = [len(sentence) for sentence in segmented_sentences]"
      ],
      "metadata": {
        "id": "x35rV7QZH49n"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# podemos ver su distribución\n",
        "plt.hist(length_sentences,bins=20)"
      ],
      "metadata": {
        "id": "R8P8vDXRII4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "outputId": "1f3465bc-85a2-49b0-f230-17b4a625a2ad"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 29., 305., 221., 523., 293.,  72., 180.,  97.,  42.,  39.,  22.,\n",
              "         12.,   4.,   3.,   0.,   0.,   2.,   1.,   0.,   1.]),\n",
              " array([ 1.  ,  2.65,  4.3 ,  5.95,  7.6 ,  9.25, 10.9 , 12.55, 14.2 ,\n",
              "        15.85, 17.5 , 19.15, 20.8 , 22.45, 24.1 , 25.75, 27.4 , 29.05,\n",
              "        30.7 , 32.35, 34.  ]),\n",
              " <BarContainer object of 20 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1bop80WB6Cda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Max Content Size calculado**"
      ],
      "metadata": {
        "id": "ljzlvT1A54TV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# a partir de la distribución de longitudes de secuencias elegimos algún criterio\n",
        "# para determinar el máximo tamaño de contexto. En este caso es un percentil, pero\n",
        "# otros criterios también pueden ser válidos con la justificación adecuada.\n",
        "\n",
        "# el -1 es porque el último token será el target\n",
        "max_context_size = int(np.percentile(length_sentences, 90)-1)\n",
        "# max_context_size = int(np.ceil(np.mean(length_sentences))) # criterio de media\n",
        "# max_context_size = int(np.ceil(np.median(length_sentences))) # criterio de mediana\n",
        "print(f'max_context_size: {max_context_size}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wumBNwdjJM3j",
        "outputId": "76ee121c-2d32-4ba9-b30f-a62382d6c5f0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_context_size: 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Max Content Size menor**"
      ],
      "metadata": {
        "id": "fQiWwpID6HzB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_context_size_2 = int(np.percentile(length_sentences, 75)-1)\n",
        "# max_context_size = int(np.ceil(np.mean(length_sentences))) # criterio de media\n",
        "# max_context_size = int(np.ceil(np.median(length_sentences))) # criterio de mediana\n",
        "print(f'max_context_size: {max_context_size_2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4BCePCg87jB",
        "outputId": "d723b25a-6067-476d-e87e-0fb3389b97b6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_context_size: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Tokenizar"
      ],
      "metadata": {
        "id": "2oIUjVU0LB0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tok = Tokenizer()\n",
        "\n",
        "# El tokenizer \"aprende\" las palabras que se usaran\n",
        "# Se construye (fit) una vez por proyecto, se aplica N veces (tal cual un encoder)\n",
        "# El token 0 es reservado y no es asignado. Se utiliza para designar a palabras\n",
        "# fuera del vocabulario aprendido\n",
        "tok.fit_on_texts(segmented_sentences)\n",
        "\n",
        "# Convertimos las palabras a números\n",
        "# entran palabras -> salen números\n",
        "tokenized_sentences = tok.texts_to_sequences(segmented_sentences)"
      ],
      "metadata": {
        "id": "_XKQIpRiLNbg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sentences"
      ],
      "metadata": {
        "id": "9bUqdwyjLYh8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77084903-66ef-4310-ce63-6124e74ab39b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[200, 10, 12, 907, 908, 42, 909, 121],\n",
              " [22, 13, 638, 91, 217, 349, 79, 4, 314],\n",
              " [23, 2, 160, 9, 200, 520, 35, 83, 910, 3, 78, 2, 911, 4, 15],\n",
              " [173, 7, 912, 913, 397, 8],\n",
              " [23, 200, 218, 520, 100, 19, 138, 4, 61, 2, 27, 14, 19, 446, 21],\n",
              " [2,\n",
              "  174,\n",
              "  187,\n",
              "  350,\n",
              "  22,\n",
              "  2,\n",
              "  96,\n",
              "  41,\n",
              "  200,\n",
              "  200,\n",
              "  6,\n",
              "  50,\n",
              "  255,\n",
              "  161,\n",
              "  256,\n",
              "  521,\n",
              "  4,\n",
              "  228],\n",
              " [22, 2, 43, 7, 229, 4, 188, 121],\n",
              " [23, 2, 160, 9, 200, 100, 19, 138, 4, 61, 2, 27, 14, 19, 446, 21],\n",
              " [2,\n",
              "  174,\n",
              "  187,\n",
              "  350,\n",
              "  22,\n",
              "  2,\n",
              "  96,\n",
              "  41,\n",
              "  200,\n",
              "  200,\n",
              "  6,\n",
              "  50,\n",
              "  255,\n",
              "  161,\n",
              "  256,\n",
              "  521,\n",
              "  4,\n",
              "  228],\n",
              " [22, 2, 43, 7, 229, 4, 188, 121],\n",
              " [23, 2, 160, 9, 200],\n",
              " [175,\n",
              "  175,\n",
              "  175,\n",
              "  175,\n",
              "  175,\n",
              "  175,\n",
              "  175,\n",
              "  36,\n",
              "  2,\n",
              "  230,\n",
              "  522,\n",
              "  9,\n",
              "  398,\n",
              "  17,\n",
              "  914,\n",
              "  639,\n",
              "  640,\n",
              "  133,\n",
              "  4,\n",
              "  8],\n",
              " [447, 162, 17, 315, 29, 13, 15],\n",
              " [5, 9, 12, 915, 17, 916, 19, 20, 189, 74, 9, 917, 17, 8],\n",
              " [447, 162, 17, 315, 29, 13, 15],\n",
              " [29, 13, 15, 29, 13, 15, 29, 13, 15, 29, 13, 15],\n",
              " [448, 162, 17, 315, 29, 13, 15, 5, 36, 3, 399, 918, 107, 351, 9, 3, 84, 641],\n",
              " [44, 38, 15, 161, 257, 29, 13, 15],\n",
              " [41, 217, 68, 231, 15, 919, 44, 20, 87, 7, 449, 16, 68, 38, 49],\n",
              " [44, 38, 15, 161, 257, 29, 13, 15],\n",
              " [29, 13, 15, 29, 13, 15, 29, 13, 15, 29, 13, 15],\n",
              " [44, 38, 15, 161, 257, 29, 13, 15],\n",
              " [29, 13, 15, 29, 13, 15, 29, 13, 15, 29, 13, 15],\n",
              " [448, 162, 17, 315, 29, 13, 15],\n",
              " [29, 13, 15, 29, 13, 15, 29, 13, 15, 29, 13, 15],\n",
              " [448,\n",
              "  162,\n",
              "  17,\n",
              "  315,\n",
              "  29,\n",
              "  13,\n",
              "  15,\n",
              "  5,\n",
              "  36,\n",
              "  3,\n",
              "  134,\n",
              "  20,\n",
              "  920,\n",
              "  44,\n",
              "  20,\n",
              "  87,\n",
              "  7,\n",
              "  400,\n",
              "  16,\n",
              "  642,\n",
              "  18,\n",
              "  8],\n",
              " [523, 401, 450, 29, 13, 15],\n",
              " [2, 921, 111, 4, 3, 643, 17, 451, 639, 640, 133, 4, 8],\n",
              " [447, 162, 17, 315, 29, 13, 15],\n",
              " [29, 13, 15, 29, 13, 15, 29, 13, 15, 24, 29, 13, 15],\n",
              " [44, 38, 15, 161, 257, 29, 13, 15],\n",
              " [29, 13, 15, 29, 13, 15, 29, 13, 15, 24, 29, 13, 15],\n",
              " [448, 162, 17, 315, 29, 13, 15, 162, 72, 922, 57, 45],\n",
              " [923, 316, 258, 7, 402, 644],\n",
              " [68, 924, 925, 91, 68, 926, 121, 403, 3, 452],\n",
              " [927, 17, 928, 404, 17, 645],\n",
              " [72, 929, 352, 12, 453, 147],\n",
              " [930, 5, 931, 8, 282, 283, 284, 524],\n",
              " [201, 81, 153, 12, 84],\n",
              " [201, 81, 153, 12, 84],\n",
              " [201, 81, 153, 12, 84],\n",
              " [201, 81, 153, 12, 84, 932, 17, 399, 400, 646],\n",
              " [259, 163, 8, 45, 7, 647, 108],\n",
              " [68, 648, 8, 18, 5, 18, 403, 3, 452],\n",
              " [933, 934, 45, 7],\n",
              " [935, 405, 525, 7, 936, 937],\n",
              " [68, 938, 939, 91, 68, 95, 317, 54, 403, 3, 452, 282, 283, 284, 524],\n",
              " [201, 81, 153, 12, 84],\n",
              " [201, 81, 153, 12, 84],\n",
              " [201, 81, 153, 12, 84],\n",
              " [201, 81, 153, 12, 84, 649, 17, 940, 941, 17, 99],\n",
              " [72, 526, 352, 12, 453, 353],\n",
              " [942, 5, 943, 8],\n",
              " [944, 945, 6, 646],\n",
              " [642, 219, 8, 45, 7, 647, 946],\n",
              " [13, 527, 8, 18, 5, 18, 403, 3, 452, 282, 283, 284, 524],\n",
              " [201, 81, 153, 12, 84],\n",
              " [201, 81, 153, 12, 84],\n",
              " [201, 81, 153, 12, 84],\n",
              " [201, 81, 153, 12, 84, 282, 283, 284],\n",
              " [282, 283, 284],\n",
              " [282, 283, 284],\n",
              " [282, 283, 284],\n",
              " [282, 283, 284, 58, 112, 27, 95, 13, 285],\n",
              " [113, 7, 406, 354, 5, 95, 13, 139],\n",
              " [318, 4, 29, 31, 258, 25, 260],\n",
              " [190, 1, 32, 454, 4, 95, 13, 139, 58, 112, 27, 15, 947],\n",
              " [1, 176, 319, 4, 61, 57, 5, 26, 31],\n",
              " [3, 948, 1, 29, 31, 355, 25, 650],\n",
              " [190, 1, 528, 4, 95, 13, 139, 5, 949, 1, 135, 3, 529, 58, 112, 950],\n",
              " [27, 148, 3, 84, 455, 25, 951],\n",
              " [41, 62, 1, 14, 16, 33, 7, 286, 191, 530, 13, 651],\n",
              " [154, 356, 66, 84, 7, 75, 952],\n",
              " [11, 11, 11, 11, 11, 11, 11, 11, 11, 58, 112, 27, 29, 8, 53],\n",
              " [1, 82, 287, 31, 22, 61, 5, 26, 31],\n",
              " [318, 4, 29, 31, 258, 25, 260],\n",
              " [190, 1, 32, 454, 4, 95, 13, 139, 42, 29, 13, 57, 5, 29, 13, 9, 58, 112, 528],\n",
              " [92, 192, 41, 232, 4, 953, 30],\n",
              " [5, 27, 1, 14, 16, 33, 93, 1, 58, 112, 164, 34],\n",
              " [3, 954, 1, 43, 20, 18, 25, 955],\n",
              " [11, 11, 11, 11, 11, 11, 11, 11, 11, 24, 58, 112, 27, 95, 13, 285],\n",
              " [113, 7, 406, 354, 5, 95, 13, 139],\n",
              " [318, 4, 29, 31, 355, 25, 650],\n",
              " [190, 164, 528, 4, 95, 13],\n",
              " [139,\n",
              "  139,\n",
              "  139,\n",
              "  139,\n",
              "  139,\n",
              "  139,\n",
              "  23,\n",
              "  11,\n",
              "  11,\n",
              "  11,\n",
              "  11,\n",
              "  11,\n",
              "  11,\n",
              "  11,\n",
              "  11,\n",
              "  11,\n",
              "  58,\n",
              "  112],\n",
              " [11, 11, 11, 11, 11, 11, 11, 11, 11, 58, 112],\n",
              " [11, 11, 11, 11, 11, 11, 11, 11, 11, 58, 112],\n",
              " [11, 11, 11, 11, 11, 11, 11, 11, 11, 58, 112],\n",
              " [11, 11, 11, 11, 11, 11, 11, 11, 11, 58, 112],\n",
              " [11, 11, 11, 11, 11, 11, 11, 11, 11, 58, 112],\n",
              " [11, 11, 11, 11, 11, 11, 11, 11, 11, 58, 112],\n",
              " [11, 11, 11, 11, 11, 11, 11, 11, 11, 58, 112],\n",
              " [11, 11, 11, 11, 11, 11, 11, 11, 11, 58, 112],\n",
              " [11, 11, 11, 11, 11, 11, 11, 11, 11, 58, 112],\n",
              " [11, 11, 11, 11, 11, 11, 11, 11, 11, 58, 112],\n",
              " [11, 11, 11, 11, 11, 11, 11, 11, 11, 58, 112],\n",
              " [11, 11, 11, 11, 11, 11, 11, 11, 11, 58, 112],\n",
              " [11, 11, 11, 11, 11, 11, 11, 11, 11, 58, 112],\n",
              " [11, 11, 11, 11, 11, 11, 11, 11, 11, 58, 112],\n",
              " [11, 11, 11, 11, 11, 11, 11, 11, 11, 58, 112, 44, 72, 456, 48, 318],\n",
              " [10, 12, 99, 217, 136, 82, 357],\n",
              " [136, 177, 83, 41, 139],\n",
              " [136, 82, 202, 5, 136, 652],\n",
              " [10, 165, 456, 82, 317, 653],\n",
              " [30, 457, 5, 122, 2, 87, 32, 654],\n",
              " [136, 72, 233, 5, 136, 72, 351],\n",
              " [9, 12, 99, 143, 288, 140, 10, 40, 17, 10, 165, 122, 5, 457],\n",
              " [44, 20, 46, 59, 655, 30, 1],\n",
              " [5, 165, 656, 358, 317, 657],\n",
              " [36, 2, 101, 17, 6, 91, 187, 320],\n",
              " [217, 2, 14, 48, 51, 358, 458],\n",
              " [41, 107, 5, 203, 16, 321, 163],\n",
              " [2, 14, 48, 459, 204, 5, 101, 193, 140],\n",
              " [9, 12, 99, 2, 6, 1, 144, 217, 2, 14, 48, 51, 358, 458],\n",
              " [41, 107, 5, 203, 16, 321, 163],\n",
              " [2, 14, 48, 459, 204, 5, 101, 193, 140],\n",
              " [9, 12, 99, 2, 6, 1, 144],\n",
              " [9, 12, 99, 2, 6, 1, 144, 322, 359, 9, 3, 233, 17, 134],\n",
              " [113, 165, 399, 658, 5, 360, 4, 289],\n",
              " [10, 25, 99],\n",
              " [1, 176, 102, 192, 41, 149, 407, 4, 460, 322, 359, 9, 3, 233, 17, 134],\n",
              " [113, 165, 956, 108, 5, 360, 4, 49],\n",
              " [10, 25, 99],\n",
              " [1, 176, 102, 192, 41, 149, 407, 4, 15, 408, 322, 289, 322, 289],\n",
              " [258, 3, 400, 17, 3, 361, 461, 134, 322, 289, 322, 289],\n",
              " [258, 3, 400, 17, 3, 361, 461, 134, 322, 359, 9, 3, 233, 17, 134],\n",
              " [113, 165, 399, 658, 5, 360, 4, 289],\n",
              " [10, 25, 99],\n",
              " [1, 176, 102, 192, 41, 149, 407, 4, 460],\n",
              " [1, 176, 102, 192, 41, 149, 407, 4, 460],\n",
              " [1, 176, 102, 192, 41, 149, 407, 4, 460, 79, 133, 3, 67, 462, 462, 462, 462],\n",
              " [79, 133, 3, 67, 5, 2, 21],\n",
              " [33, 10, 74, 75, 123, 33, 103, 7, 96, 659, 124, 957],\n",
              " [75, 123, 13, 531, 45, 234, 409, 33, 103, 79],\n",
              " [79, 133, 3, 67],\n",
              " [79, 133, 3, 67, 5, 2, 21],\n",
              " [33, 10, 74, 75, 123, 3, 410, 958, 4, 3, 959],\n",
              " [75, 123, 13, 290, 45, 234, 409, 33, 103, 79],\n",
              " [79, 133, 3, 67],\n",
              " [79, 133, 3, 67, 5, 2, 21],\n",
              " [33, 10, 74, 67, 67, 67, 79, 13, 133],\n",
              " [67, 67, 67, 79, 13, 133],\n",
              " [67, 67, 67, 79, 13, 133],\n",
              " [67, 67, 67, 79, 13, 133],\n",
              " [67, 67, 67, 79, 13, 133, 75, 123, 2, 135, 16, 960, 20, 532, 961],\n",
              " [75, 123, 13, 290, 45, 234, 409, 33, 103, 962],\n",
              " [79, 133, 3, 67],\n",
              " [79, 133, 3, 67, 5, 2, 21],\n",
              " [33, 10, 74, 79, 133, 3, 67],\n",
              " [79, 133, 3, 67, 5, 2, 21],\n",
              " [33, 10, 74],\n",
              " [33, 10, 74, 104, 44, 50, 7, 54],\n",
              " [4, 26, 28, 362],\n",
              " [104, 44, 50, 7, 54],\n",
              " [4, 26, 28, 69],\n",
              " [205, 166, 123, 34, 83, 206],\n",
              " [5, 2, 38, 115, 7, 261, 463, 533, 291, 25, 108],\n",
              " [410, 660, 1, 36, 1, 534],\n",
              " [205, 166, 123, 34, 83, 206],\n",
              " [5, 2, 38, 115, 7, 261, 104, 44, 50, 7, 54],\n",
              " [4, 26, 28, 362],\n",
              " [104, 44, 50, 7, 54],\n",
              " [4, 26, 28, 69],\n",
              " [205, 166, 123, 34, 83, 206],\n",
              " [5, 2, 38, 115, 7, 261, 125, 92, 81, 148, 16, 155],\n",
              " [148, 16, 155, 41, 7, 96, 94],\n",
              " [125, 92, 81, 148, 16, 155],\n",
              " [148, 16, 155, 41, 7, 96, 94, 2, 51, 116, 1, 12, 661],\n",
              " [2, 102, 235, 1, 12, 662],\n",
              " [5, 9, 3, 411, 17, 3, 663],\n",
              " [2, 412, 53, 125, 92, 81, 148, 16, 155],\n",
              " [148, 16, 155, 41, 7, 96, 94],\n",
              " [125, 92, 81, 148, 16, 155],\n",
              " [148, 16, 155, 41, 7, 96, 94, 23, 24, 10, 74],\n",
              " [72, 1, 81, 15, 9, 12, 413, 464, 6, 1, 6, 1, 6, 1, 6, 1, 6, 1, 6, 1],\n",
              " [6, 1, 6, 1, 6, 1, 6, 1, 6, 1, 6, 1],\n",
              " [6, 1, 6, 1, 6, 1, 6, 1, 6, 1, 6, 1],\n",
              " [6, 1, 6, 1, 6, 1, 6, 1, 6, 1, 6, 1],\n",
              " [6, 1, 6, 1, 6, 1, 6, 1, 6, 1, 6, 1, 5, 9, 3, 465],\n",
              " [3, 6, 1, 113],\n",
              " [20, 535, 4, 3, 6, 1, 95],\n",
              " [73, 6, 6, 6, 6, 6, 6, 6, 6, 6, 173, 126, 1, 32, 34, 16, 63, 15, 292],\n",
              " [126, 1, 32, 115, 16, 63, 15, 963],\n",
              " [126, 1, 32, 21, 40, 1, 32, 360],\n",
              " [88, 4, 228, 3, 521],\n",
              " [33, 256],\n",
              " [126, 1, 32, 95, 16, 63, 15, 319],\n",
              " [46, 59, 1, 32, 466, 16, 63, 15, 664],\n",
              " [126, 1, 32, 34, 40, 1, 32, 360],\n",
              " [88, 4, 15, 1, 9, 94],\n",
              " [33, 256, 10, 1, 43, 20, 6, 10, 1, 43, 20, 6],\n",
              " [10, 1, 43, 20, 6, 6, 6, 20, 10, 1, 43],\n",
              " [6, 6, 6, 6, 6, 6, 6, 6, 6],\n",
              " [10, 1, 43, 20, 6, 10, 1, 43, 20, 6],\n",
              " [10, 1, 43, 20, 6, 6, 6, 20, 10, 1, 43, 173, 126, 1, 32, 14, 16, 293, 467],\n",
              " [126, 1, 32, 49, 16, 293, 964],\n",
              " [173, 117, 1, 32, 15, 16, 293, 109],\n",
              " [92, 965, 4, 15],\n",
              " [33, 256, 10, 1, 43, 20, 6, 10, 1, 43, 20, 6],\n",
              " [10, 1, 43, 20, 6, 6, 6, 20, 10, 1, 43],\n",
              " [10, 1, 43, 20, 6, 10, 47, 22],\n",
              " [10, 1, 43, 20, 6, 536],\n",
              " [10, 1, 43, 20, 6, 6, 6, 20, 10, 1, 43],\n",
              " [6, 20, 10, 1, 43],\n",
              " [6, 20, 10, 1, 43, 200],\n",
              " [23, 24],\n",
              " [19, 6, 1, 24, 24, 24],\n",
              " [19, 6, 1, 24, 24, 24],\n",
              " [23, 200, 44, 72, 456, 2, 318, 10, 12, 99],\n",
              " [217, 136, 82, 357],\n",
              " [136, 177, 83, 41, 139],\n",
              " [136, 82, 202, 5, 136, 652, 10, 165, 456, 82, 317, 653],\n",
              " [17, 457, 5, 122, 2, 87, 32, 654],\n",
              " [136, 72, 233, 5, 136, 72, 351],\n",
              " [9, 12, 99, 2, 288, 140, 10, 5, 30, 10, 165, 122, 5, 457],\n",
              " [44, 20, 46, 59, 655, 30, 1],\n",
              " [5, 165, 966, 358, 317, 657],\n",
              " [36, 2, 101, 17, 6, 91, 187, 320, 5, 2, 14, 48, 51, 358, 458],\n",
              " [41, 107, 5, 203, 16, 321, 163],\n",
              " [2, 14, 48, 459, 204, 5, 101, 193, 140],\n",
              " [9, 12, 99, 2, 288, 1, 144, 5, 2, 14, 48, 51, 358, 458],\n",
              " [41, 107, 5, 203, 16, 321, 163],\n",
              " [2, 14, 48, 459, 204, 5, 101, 193, 140],\n",
              " [9, 12, 99, 2, 288, 1, 144],\n",
              " [9, 12, 99, 2, 288, 1, 144, 29, 8, 113, 1, 53],\n",
              " [194, 35, 85, 4, 236, 237],\n",
              " [126, 20, 294],\n",
              " [5, 126, 4, 26, 468, 193],\n",
              " [236, 237, 177, 351, 20, 256, 30, 108, 967],\n",
              " [968, 10, 1, 49],\n",
              " [33, 537, 207, 4, 15, 232],\n",
              " [40, 13, 10, 665, 57],\n",
              " [13, 414, 666, 295, 4, 8, 29, 8, 113, 1, 53],\n",
              " [194, 35, 85, 4, 236, 237],\n",
              " [126, 20, 294],\n",
              " [5, 126, 4, 26, 468, 193],\n",
              " [236, 237, 177, 46, 59, 2, 101, 20, 9, 12, 469],\n",
              " [2, 220, 13, 323, 15, 262, 238, 470],\n",
              " [16, 20, 1, 14, 1, 63, 667, 13],\n",
              " [40, 33, 10, 74],\n",
              " [16, 20, 2, 101, 33, 83, 89, 285, 29, 8, 113, 1, 53],\n",
              " [194, 35, 85, 4, 236, 237],\n",
              " [126, 20, 294],\n",
              " [5, 126, 4, 26, 468, 193],\n",
              " [236, 237, 177, 127, 14, 969, 33, 8],\n",
              " [40, 1, 14, 2, 14, 36, 33, 7, 363],\n",
              " [2, 101, 2, 14, 2, 220, 7, 97],\n",
              " [40, 33, 10, 350],\n",
              " [16, 20, 2, 101, 2, 970, 29, 8, 113, 1, 53],\n",
              " [194, 35, 85, 4, 236, 237],\n",
              " [126, 20, 294],\n",
              " [5, 126, 4, 26, 468, 193],\n",
              " [236, 237, 177],\n",
              " [236, 237, 177],\n",
              " [236, 237, 177, 324, 221, 7, 971, 9, 3, 972],\n",
              " [296, 20, 3, 668, 9, 7, 239],\n",
              " [324, 415, 4, 296, 64, 2, 45, 25, 263],\n",
              " [5, 296, 415, 149, 91, 19, 416, 264, 154, 3, 128, 471],\n",
              " [417, 150, 208, 417, 150, 538, 99, 472, 18, 669],\n",
              " [150, 150, 88, 3, 99, 472, 18],\n",
              " [417, 150, 208, 417, 150, 538, 99, 472, 18, 669],\n",
              " [150, 150, 88, 3, 99, 472, 18, 324, 416, 7, 973, 4, 3, 974, 975],\n",
              " [976, 7, 670, 977, 463, 473],\n",
              " [416, 13, 28, 4, 296, 192, 76, 3, 240],\n",
              " [5,\n",
              "  91,\n",
              "  39,\n",
              "  539,\n",
              "  13,\n",
              "  4,\n",
              "  31,\n",
              "  19,\n",
              "  671,\n",
              "  4,\n",
              "  115,\n",
              "  471,\n",
              "  9,\n",
              "  7,\n",
              "  474,\n",
              "  17,\n",
              "  234,\n",
              "  68,\n",
              "  82,\n",
              "  540],\n",
              " [7, 69, 325, 69],\n",
              " [30, 7, 474, 17, 672, 541, 9, 3, 673],\n",
              " [17, 324, 5, 296, 674, 241, 297, 475, 9, 3, 675, 229],\n",
              " [324, 676, 3, 195, 542, 7, 128],\n",
              " [296, 677, 76, 69, 5, 265, 31, 166, 263],\n",
              " [5,\n",
              "  9,\n",
              "  3,\n",
              "  543,\n",
              "  19,\n",
              "  87,\n",
              "  978,\n",
              "  13,\n",
              "  30,\n",
              "  3,\n",
              "  239,\n",
              "  471,\n",
              "  9,\n",
              "  7,\n",
              "  474,\n",
              "  17,\n",
              "  234,\n",
              "  68,\n",
              "  82,\n",
              "  540],\n",
              " [7, 69, 325, 69],\n",
              " [30, 7, 474, 17, 672, 541, 9, 3, 673],\n",
              " [17, 324, 5, 296, 674, 241, 297, 475, 9, 3, 675, 229],\n",
              " [296, 676, 3, 195, 542, 7, 128],\n",
              " [324, 677, 76, 69, 5, 265, 66, 166, 263],\n",
              " [5,\n",
              "  9,\n",
              "  3,\n",
              "  543,\n",
              "  209,\n",
              "  7,\n",
              "  668,\n",
              "  30,\n",
              "  3,\n",
              "  239,\n",
              "  471,\n",
              "  5,\n",
              "  55,\n",
              "  1,\n",
              "  56,\n",
              "  136,\n",
              "  979,\n",
              "  115,\n",
              "  417,\n",
              "  150,\n",
              "  208,\n",
              "  980,\n",
              "  538,\n",
              "  36,\n",
              "  2,\n",
              "  26,\n",
              "  476,\n",
              "  678,\n",
              "  12,\n",
              "  364,\n",
              "  298,\n",
              "  234,\n",
              "  77,\n",
              "  22],\n",
              " [38, 1, 87, 15, 544, 8, 7, 679, 167, 680, 681, 17, 477],\n",
              " [55, 168, 103, 57, 981, 682, 4, 169, 141, 1, 683, 3, 240],\n",
              " [38, 1, 87, 43, 8, 38, 1, 87, 365, 8, 36, 35, 366, 145, 164, 15, 476, 89],\n",
              " [73],\n",
              " [5,\n",
              "  55,\n",
              "  1,\n",
              "  21,\n",
              "  3,\n",
              "  684,\n",
              "  2,\n",
              "  137,\n",
              "  314,\n",
              "  30,\n",
              "  1,\n",
              "  2,\n",
              "  137,\n",
              "  15,\n",
              "  685,\n",
              "  686,\n",
              "  7,\n",
              "  687,\n",
              "  36,\n",
              "  25,\n",
              "  545,\n",
              "  82,\n",
              "  202],\n",
              " [1, 32, 688, 7, 689, 154, 3, 690, 546, 982, 61, 41, 7, 691],\n",
              " [367, 3, 242, 692, 3, 693, 191, 137, 266, 41, 144],\n",
              " [38,\n",
              "  1,\n",
              "  87,\n",
              "  43,\n",
              "  8,\n",
              "  38,\n",
              "  1,\n",
              "  87,\n",
              "  365,\n",
              "  8,\n",
              "  36,\n",
              "  35,\n",
              "  366,\n",
              "  145,\n",
              "  170,\n",
              "  547,\n",
              "  52,\n",
              "  32,\n",
              "  548,\n",
              "  7,\n",
              "  694],\n",
              " [9, 3, 695, 17, 696, 55, 33, 83, 89, 178],\n",
              " [52, 697, 698, 5, 466],\n",
              " [73],\n",
              " [699, 18, 25, 418],\n",
              " [700, 701, 5, 702, 235, 8, 7, 703, 549, 8, 7, 704, 705, 478, 17, 479],\n",
              " [480, 706, 86, 1, 220, 4, 21, 983, 707, 708, 121],\n",
              " [116, 8, 25, 257, 291, 9, 7, 709, 179, 177, 144],\n",
              " [38,\n",
              "  1,\n",
              "  87,\n",
              "  43,\n",
              "  8,\n",
              "  38,\n",
              "  1,\n",
              "  87,\n",
              "  365,\n",
              "  8,\n",
              "  36,\n",
              "  35,\n",
              "  366,\n",
              "  145,\n",
              "  23,\n",
              "  24,\n",
              "  2,\n",
              "  105,\n",
              "  1,\n",
              "  368],\n",
              " [2, 101, 164, 299],\n",
              " [36, 2, 21, 16, 368],\n",
              " [2, 56, 4, 118, 25, 128],\n",
              " [2, 56, 4, 118, 25, 128],\n",
              " [2, 56, 4, 118, 25, 128, 23, 90, 21, 4, 8],\n",
              " [164, 29, 8, 15, 25, 78],\n",
              " [5, 90, 21, 4, 8],\n",
              " [164, 29, 8, 118, 25, 128],\n",
              " [22, 29, 8, 118, 25, 128],\n",
              " [2, 56, 4, 118, 25, 128, 5, 36, 2, 550, 1],\n",
              " [2, 135, 241, 525],\n",
              " [33, 255, 7, 710, 16, 12, 6],\n",
              " [2, 63, 188],\n",
              " [2, 63, 188],\n",
              " [2, 63, 188, 24, 1, 60, 16, 368],\n",
              " [2, 101, 164, 299],\n",
              " [36, 2, 21, 16, 368],\n",
              " [2, 56, 4, 118, 25, 128],\n",
              " [2, 56, 4, 118, 25, 128],\n",
              " [2, 56, 4, 118, 25, 128, 5, 36, 2, 550, 1],\n",
              " [2, 135, 241, 525],\n",
              " [33, 255, 7, 710, 16, 12, 6],\n",
              " [2, 63, 188],\n",
              " [2, 63, 188],\n",
              " [2, 63, 188, 24, 1, 60, 16, 368],\n",
              " [2, 101, 164, 299],\n",
              " [36, 2, 135, 16, 368],\n",
              " [2, 56, 4, 118, 25, 128],\n",
              " [2, 56, 4, 118, 25, 128],\n",
              " [2, 56, 4, 118, 25, 128],\n",
              " [2, 56, 4, 118, 25, 128, 27, 29, 8, 53, 27, 29, 8, 53],\n",
              " [27, 29, 8, 53, 27, 29, 8, 53, 180, 297, 288, 8, 45, 19, 265],\n",
              " [23, 19, 265, 24, 19, 265],\n",
              " [5, 55, 267, 288, 8, 45, 19, 34, 8],\n",
              " [23, 19, 34, 8, 97, 19, 265, 27, 29, 8, 53, 27, 29, 8, 53],\n",
              " [27, 29, 8, 53, 27, 29, 8, 53, 35, 9, 6, 41, 3, 481, 94],\n",
              " [27, 1, 14, 33, 81, 326],\n",
              " [33, 7, 6, 16, 984, 177],\n",
              " [33, 7, 6, 16, 138, 46, 711, 27, 29, 8, 53, 27, 29, 8, 53],\n",
              " [27, 29, 8, 53, 27, 29, 8, 53, 5, 77, 3, 481, 94, 16, 19, 327, 292, 8],\n",
              " [23, 19, 292, 8, 19, 292, 8, 65],\n",
              " [2, 551, 180, 297, 327, 292, 8],\n",
              " [23, 19, 292, 8, 19, 292, 8, 65, 27, 29, 8, 53, 27, 29, 8, 53],\n",
              " [27, 29, 8, 53, 80, 2, 43, 267],\n",
              " [80, 83, 93, 243],\n",
              " [80, 1, 14, 2, 43, 232, 80, 36, 2, 50, 482, 42, 295, 482, 419, 244],\n",
              " [2, 51, 712, 713, 80, 9, 268, 54],\n",
              " [40, 22, 165, 210, 72, 202, 35, 83, 42, 714, 715],\n",
              " [22,\n",
              "  2,\n",
              "  230,\n",
              "  143,\n",
              "  357,\n",
              "  12,\n",
              "  147,\n",
              "  5,\n",
              "  453,\n",
              "  111,\n",
              "  3,\n",
              "  716,\n",
              "  80,\n",
              "  8,\n",
              "  55,\n",
              "  1,\n",
              "  32,\n",
              "  35,\n",
              "  269,\n",
              "  53],\n",
              " [5, 2, 34, 552, 1, 553, 181],\n",
              " [80, 8, 26, 12, 369, 28, 18, 3, 483],\n",
              " [245, 1, 90, 90, 80, 8, 5, 22, 12, 99, 221, 357, 9, 23, 42, 298, 717],\n",
              " [12, 985, 290, 4, 986, 9, 3, 987],\n",
              " [40, 170, 22, 5, 190, 2, 135, 42, 988],\n",
              " [2,\n",
              "  14,\n",
              "  16,\n",
              "  2,\n",
              "  93,\n",
              "  43,\n",
              "  1,\n",
              "  45,\n",
              "  143,\n",
              "  51,\n",
              "  292,\n",
              "  163,\n",
              "  80,\n",
              "  8,\n",
              "  55,\n",
              "  1,\n",
              "  32,\n",
              "  35,\n",
              "  269,\n",
              "  53],\n",
              " [5, 2, 34, 552, 1, 553, 181],\n",
              " [80, 8, 26, 12, 369, 28, 18, 3, 483],\n",
              " [245, 1, 90, 90, 80, 8, 36, 2, 50, 482, 42, 295, 482, 419, 244],\n",
              " [2, 51, 712, 713, 80, 9, 268, 54],\n",
              " [40, 22, 165, 210, 72, 202, 35, 83, 42, 714, 715],\n",
              " [22,\n",
              "  2,\n",
              "  230,\n",
              "  143,\n",
              "  357,\n",
              "  12,\n",
              "  147,\n",
              "  5,\n",
              "  453,\n",
              "  111,\n",
              "  3,\n",
              "  716,\n",
              "  80,\n",
              "  8,\n",
              "  55,\n",
              "  1,\n",
              "  32,\n",
              "  35,\n",
              "  269,\n",
              "  53],\n",
              " [5, 2, 34, 552, 1, 553, 181],\n",
              " [80, 8, 26, 12, 369, 28, 18, 3, 483],\n",
              " [245, 1, 90, 90, 80, 8, 80, 8, 80, 8, 23, 187, 9, 3, 54, 19, 989],\n",
              " [990, 8, 45, 46, 370, 554],\n",
              " [187, 9, 3, 54, 19, 991, 8],\n",
              " [2, 27, 56, 4, 182, 31, 22],\n",
              " [1, 14, 2, 160, 5, 88, 718, 9, 31, 328, 19, 270],\n",
              " [16, 2, 27, 43, 46, 370, 554],\n",
              " [187, 9, 31, 719, 16, 555, 8],\n",
              " [2, 27, 56, 4, 182, 31, 22],\n",
              " [1, 14, 2, 160, 5, 88, 92, 992, 8, 38, 12, 6, 556],\n",
              " [2, 27, 14, 2, 27, 14],\n",
              " [1, 993, 219, 5, 13, 231, 329],\n",
              " [2, 27, 14, 2, 27, 14, 187, 9, 3, 54, 19, 270],\n",
              " [5, 10, 2, 82, 4, 34, 20, 101, 17, 31],\n",
              " [187, 9, 3, 203, 19, 555, 8],\n",
              " [2, 27, 56, 4, 182, 31, 22],\n",
              " [1, 14, 2, 160, 5, 88, 79, 37, 371, 720, 994],\n",
              " [39, 37, 995, 111, 532],\n",
              " [39, 60, 721, 721, 996],\n",
              " [39, 59, 997, 722],\n",
              " [39, 60, 364, 53, 4, 66, 418],\n",
              " [60, 4, 15, 7, 723],\n",
              " [39, 93, 34, 86, 39, 90, 39, 998, 46, 999],\n",
              " [39, 60, 1000, 1001, 1002],\n",
              " [39, 60, 1003, 724],\n",
              " [39, 725, 1004, 1005],\n",
              " [39, 21, 2, 14, 1, 1, 14, 8],\n",
              " [59, 420, 2, 32, 105, 1, 20],\n",
              " [1, 60, 4, 15, 408],\n",
              " [37, 47, 74, 22],\n",
              " [397, 8, 39, 285, 1006],\n",
              " [39, 60, 421, 1007],\n",
              " [39, 60, 1008, 1009],\n",
              " [39, 59, 1010, 1011],\n",
              " [39, 60, 369, 53, 557, 66, 418],\n",
              " [118, 1, 9, 66, 1012],\n",
              " [1, 32, 135, 66, 1013],\n",
              " [37, 47, 74, 22],\n",
              " [397, 8, 39, 722, 1014],\n",
              " [39, 60, 726, 1015],\n",
              " [39, 60, 1016, 1017],\n",
              " [39, 59, 1018, 1019],\n",
              " [39, 21, 59, 5, 59, 5, 59, 20, 169],\n",
              " [60, 4, 15, 65, 372],\n",
              " [194, 209, 42, 207, 4, 49],\n",
              " [37, 47, 74, 22],\n",
              " [397, 8, 37, 47, 24],\n",
              " [37, 47, 24],\n",
              " [37, 47, 24],\n",
              " [37, 47, 24],\n",
              " [37, 47, 24],\n",
              " [37, 47, 24],\n",
              " [37, 47, 24],\n",
              " [37, 47, 24],\n",
              " [37, 47, 24, 44, 176, 1020, 18, 7, 373],\n",
              " [40, 2, 51, 374, 140, 526],\n",
              " [46, 2, 51, 374, 140, 76, 10],\n",
              " [222, 44, 50, 1, 44, 176, 727, 9, 3, 106],\n",
              " [40, 2, 51, 196, 140, 1021],\n",
              " [46, 2, 51, 196, 140, 76, 10],\n",
              " [222, 44, 50, 1, 190, 44, 50, 451, 5, 558, 728],\n",
              " [68, 105, 8, 9, 325, 729, 730],\n",
              " [17, 731, 5, 732, 44, 50, 6, 10, 219],\n",
              " [40, 2, 51, 374, 13, 359],\n",
              " [46, 2, 51, 374, 13, 76, 10],\n",
              " [222, 44, 50, 1, 190, 44, 50, 451, 5, 558, 728],\n",
              " [68, 105, 8, 9, 325, 729, 730],\n",
              " [17, 731, 5, 732, 44, 50, 6, 10, 219],\n",
              " [40, 2, 51, 374, 13, 359],\n",
              " [46, 2, 51, 374, 13, 76, 10],\n",
              " [222, 44, 50, 1],\n",
              " [222, 44, 50, 1, 1, 21, 1, 56, 7, 1022],\n",
              " [62, 1, 14],\n",
              " [52, 10, 56, 4, 153, 3, 84],\n",
              " [1, 105, 8, 16, 33, 1023],\n",
              " [62, 1, 14],\n",
              " [52, 10, 56, 4, 153, 3, 84, 40, 36, 1, 271, 193, 1024],\n",
              " [27, 1, 14, 16, 1, 32, 733, 8, 57],\n",
              " [27, 1, 14, 33, 81, 15],\n",
              " [10, 74, 10, 74, 10, 74, 1, 21, 1, 60, 7, 294, 1025],\n",
              " [62, 1, 14],\n",
              " [559, 10, 6, 4, 49, 3, 1026],\n",
              " [1, 266, 8, 41, 7, 1027],\n",
              " [62, 1, 14],\n",
              " [129, 367, 86, 52, 32, 40, 55, 1, 56, 183, 41, 107, 30, 1028, 16, 1029],\n",
              " [10, 2, 32, 105, 20, 734, 1, 82, 4, 735],\n",
              " [27, 1, 14, 33, 81, 15],\n",
              " [10, 74, 10, 74, 10, 74, 1, 21, 164, 153, 3, 1030],\n",
              " [62, 1, 14],\n",
              " [52, 10, 56, 4, 153, 25, 142],\n",
              " [1, 105, 8, 33, 3, 1031],\n",
              " [62, 1, 14],\n",
              " [1, 139, 408, 1, 147, 1032, 40, 55, 1, 61, 1033, 560, 17, 1034, 1035],\n",
              " [1, 422, 85, 4, 95, 13, 30, 1036, 1037],\n",
              " [27, 1, 14, 33, 81, 15],\n",
              " [10, 74, 10, 74, 10, 74],\n",
              " [10, 74, 10, 74, 10, 74],\n",
              " [10, 74, 10, 74, 10, 74],\n",
              " [10, 74, 10, 74, 9, 3, 736, 109, 2, 50, 1038],\n",
              " [561, 7, 78, 191, 737, 4, 300],\n",
              " [5, 39, 184, 156, 17, 66, 99],\n",
              " [9, 3, 562, 17, 1039],\n",
              " [42, 52, 737, 111, 4, 3, 67],\n",
              " [222, 52, 287, 7, 300, 17, 484],\n",
              " [5, 52, 561, 301, 3, 404],\n",
              " [9, 157, 98, 114, 52, 10, 246, 9, 7, 98, 114],\n",
              " [98, 114, 98, 114],\n",
              " [52, 10, 246, 9, 7, 98, 114],\n",
              " [98, 114, 98, 114, 5, 157, 122, 72, 10, 1040],\n",
              " [298, 144, 17, 140, 246, 738, 240],\n",
              " [5, 3, 239, 671, 4, 228, 52, 10, 246, 9, 7, 98, 114],\n",
              " [98, 114, 98, 114],\n",
              " [52, 10, 246, 9, 7, 98, 114],\n",
              " [98, 114, 98, 114, 563, 564, 485, 565, 1041, 563, 564, 485],\n",
              " [563, 564, 485, 13, 20, 1042],\n",
              " [739, 3, 740, 549, 3, 740],\n",
              " [741, 566, 741],\n",
              " [742, 742, 91, 52, 246, 7, 99, 17, 1043],\n",
              " [170, 59, 17, 156, 221, 10, 52, 43],\n",
              " [106, 17, 247, 5, 300, 17, 484],\n",
              " [9, 157, 98, 114, 52, 10, 246, 9, 7, 98, 114],\n",
              " [98, 114, 98, 114],\n",
              " [52, 10, 246, 9, 7, 98, 114],\n",
              " [98, 114, 98, 114],\n",
              " [52, 10, 246, 9, 7, 98, 114],\n",
              " [98, 114, 98, 114, 191, 270, 88, 96, 143, 288, 1],\n",
              " [1, 14, 2, 6, 1, 87],\n",
              " [38, 2, 735, 7, 124, 1044],\n",
              " [55, 1, 56, 8, 4, 2, 38, 5, 55, 2, 297, 196, 1],\n",
              " [2, 197, 1045, 25, 567],\n",
              " [40, 13, 51, 327, 1046],\n",
              " [2, 38, 127, 135, 3, 1047, 6, 1, 177, 5, 177],\n",
              " [6, 1, 30, 10, 12, 260],\n",
              " [6, 1, 743, 129, 47],\n",
              " [6, 1, 36, 129, 486, 5, 36, 76, 326, 2, 230, 1],\n",
              " [25, 354, 38, 291, 3, 744],\n",
              " [115, 13, 568, 42, 2, 32, 330, 1],\n",
              " [95, 13, 256, 4, 15, 423, 1],\n",
              " [41, 3, 203, 1, 34, 745, 1, 4, 8],\n",
              " [23, 1, 14, 2, 38, 6, 1, 177, 5, 177],\n",
              " [6, 1, 30, 10, 12, 260],\n",
              " [6, 1, 743, 129, 47],\n",
              " [6, 1, 36, 129, 486, 5, 36, 76, 326, 2, 287, 1],\n",
              " [25, 354, 38, 291, 3, 744],\n",
              " [115, 13, 568, 42, 2, 32, 330, 1],\n",
              " [95, 13, 256, 4, 15, 423, 1],\n",
              " [10, 3, 203, 1, 34, 745, 1, 4, 8],\n",
              " [23, 1, 14, 2, 38],\n",
              " [23, 1, 14, 2, 38],\n",
              " [23, 1, 14, 2, 38],\n",
              " [23, 1, 14, 2, 38, 86, 141, 1, 101, 55, 2, 1048, 57, 17, 667],\n",
              " [141, 1, 487, 111, 5, 569, 57, 18, 8],\n",
              " [542, 8, 25, 353, 5, 48, 115, 1, 7, 354],\n",
              " [5,\n",
              "  48,\n",
              "  198,\n",
              "  83,\n",
              "  4,\n",
              "  115,\n",
              "  57,\n",
              "  17,\n",
              "  1049,\n",
              "  23,\n",
              "  2,\n",
              "  26,\n",
              "  154,\n",
              "  30,\n",
              "  7,\n",
              "  75,\n",
              "  80,\n",
              "  77,\n",
              "  12,\n",
              "  122],\n",
              " [331, 2, 26, 262, 30, 7, 75, 80, 77, 12, 122],\n",
              " [331,\n",
              "  85,\n",
              "  4,\n",
              "  198,\n",
              "  30,\n",
              "  7,\n",
              "  75,\n",
              "  80,\n",
              "  77,\n",
              "  12,\n",
              "  122,\n",
              "  86,\n",
              "  34,\n",
              "  2,\n",
              "  34,\n",
              "  36,\n",
              "  12,\n",
              "  6,\n",
              "  20,\n",
              "  121],\n",
              " [265, 13, 746, 1, 4, 15, 211],\n",
              " [88, 34, 2, 135, 154, 3, 465, 17, 3, 71],\n",
              " [72,\n",
              "  1,\n",
              "  406,\n",
              "  212,\n",
              "  92,\n",
              "  18,\n",
              "  25,\n",
              "  747,\n",
              "  46,\n",
              "  2,\n",
              "  26,\n",
              "  154,\n",
              "  30,\n",
              "  7,\n",
              "  75,\n",
              "  80,\n",
              "  77,\n",
              "  12,\n",
              "  122],\n",
              " [331, 2, 26, 262, 30, 7, 75, 80, 77, 12, 122],\n",
              " [331, 85, 4, 198, 30, 7, 75, 80, 77, 12, 122, 34, 1, 43, 243],\n",
              " [2, 43, 267, 4, 6],\n",
              " [137, 13, 15, 243],\n",
              " [2, 56, 267, 4, 6, 141, 1, 160, 9, 7, 6, 76, 481, 748],\n",
              " [97, 35, 1050, 16, 13, 1051, 10, 3, 94],\n",
              " [86, 34, 1, 49, 36, 1, 424, 57, 3, 400],\n",
              " [2,\n",
              "  63,\n",
              "  105,\n",
              "  1,\n",
              "  40,\n",
              "  2,\n",
              "  14,\n",
              "  33,\n",
              "  179,\n",
              "  23,\n",
              "  2,\n",
              "  26,\n",
              "  154,\n",
              "  30,\n",
              "  7,\n",
              "  75,\n",
              "  80,\n",
              "  77,\n",
              "  12,\n",
              "  122],\n",
              " [331, 2, 26, 262, 30, 7, 75, 80, 77, 12, 122],\n",
              " [331, 85, 4, 198, 30, 7, 75, 80, 77, 12, 122, 34, 1, 43, 243],\n",
              " [2, 93, 43, 232, 4, 6],\n",
              " [137, 13, 15, 243],\n",
              " [2, 56, 267, 4, 6, 23, 2, 26, 154, 30, 7, 75, 80, 77, 12, 122],\n",
              " [331, 85, 4, 198, 30, 7, 75, 80, 77, 12, 122],\n",
              " [23, 2, 26, 262, 30, 7, 75, 80, 77, 12, 122],\n",
              " [97, 2, 26, 154, 30, 7, 75, 80, 77, 12, 122],\n",
              " [30, 7, 75, 80, 77, 12, 122, 2, 130, 39, 91, 1, 72, 39, 91, 1, 72, 8],\n",
              " [5, 52, 72, 10, 47],\n",
              " [49, 88, 68, 488, 45, 749, 77, 7, 750],\n",
              " [49, 88, 68, 289],\n",
              " [35, 332, 333, 18, 7, 1052],\n",
              " [192, 41, 3, 1053, 4, 37],\n",
              " [1054, 1055, 1056, 751, 1057, 1058],\n",
              " [78, 272, 103, 7, 752, 125],\n",
              " [1, 29, 25, 263, 556, 96, 2, 130, 3, 489],\n",
              " [68, 72, 3, 490],\n",
              " [2, 130, 3, 421],\n",
              " [131, 131, 302, 303, 565, 1059, 1060, 333],\n",
              " [166, 75, 1061, 9, 7, 570],\n",
              " [49, 88, 68, 289, 45, 158, 9, 3, 106],\n",
              " [49, 88, 68, 488],\n",
              " [35, 332],\n",
              " [35, 332, 35, 332, 35, 332, 98, 666, 1062],\n",
              " [1063, 77, 7, 233, 1064, 753],\n",
              " [1065, 1066],\n",
              " [1067, 1068],\n",
              " [125, 272, 103, 7, 752, 64],\n",
              " [1, 29, 25, 1069, 53, 2, 130, 3, 489],\n",
              " [68, 72, 3, 490],\n",
              " [2, 130, 3, 421],\n",
              " [131, 131, 302, 303, 333, 9, 161, 571, 242],\n",
              " [192, 41, 3, 67],\n",
              " [55, 3, 67, 27, 37, 1, 26, 7, 1070],\n",
              " [77, 189, 9, 3, 571, 316, 2, 130, 3, 489],\n",
              " [88, 34, 1, 34, 566],\n",
              " [68, 72, 3, 490],\n",
              " [3, 78, 1071, 7, 1072],\n",
              " [2, 130, 3, 421],\n",
              " [131, 131, 302, 303, 131, 131, 131, 302, 303, 1073, 1074, 1075, 1076],\n",
              " [27, 1, 101, 3, 723, 1077, 76, 1],\n",
              " [491, 491, 491, 572, 572, 572, 573, 573, 573],\n",
              " [49, 88, 68, 328, 45, 749, 9, 7, 1078],\n",
              " [49, 88, 68, 1079],\n",
              " [35, 332, 1080, 1081],\n",
              " [1082, 111, 3, 1083, 1084],\n",
              " [1085, 1086, 359, 1087, 1088],\n",
              " [78, 1, 132, 82, 425, 140, 1089],\n",
              " [1090, 1091, 1092, 2, 130, 3, 489],\n",
              " [68, 72, 3, 490],\n",
              " [2, 130, 3, 421],\n",
              " [131, 131, 302, 303],\n",
              " [131, 131, 131, 302, 303],\n",
              " [131, 131, 302, 303],\n",
              " [131, 131, 131, 302, 303],\n",
              " [131, 131],\n",
              " [223, 223, 223],\n",
              " [223, 223, 223],\n",
              " [223, 223, 223],\n",
              " [223, 223, 23, 35, 334, 1093, 1094],\n",
              " [754, 1, 53, 574, 1095, 1, 2, 119, 76, 1, 10, 49, 3, 6, 44, 335, 492],\n",
              " [248, 12, 375, 376, 377],\n",
              " [2, 119, 76, 3, 1096, 5, 2, 49, 13, 1097, 1098],\n",
              " [87, 12, 375, 376, 377, 2, 27, 14, 100, 180, 184, 1],\n",
              " [88, 4, 1099, 25, 6],\n",
              " [2, 27, 14, 88, 232, 1100, 1],\n",
              " [68, 1101, 5, 1102, 1, 2, 119, 76, 3, 84, 5, 2, 575, 33, 755],\n",
              " [248, 12, 375, 376, 377],\n",
              " [30, 170, 1103, 52, 323, 1104, 15, 1105],\n",
              " [87, 12, 375, 376, 377, 2, 27, 14, 88, 1, 176, 1106],\n",
              " [1, 176, 1107, 89],\n",
              " [2, 27, 14, 88, 1, 176, 1108],\n",
              " [46, 59, 1109, 1, 2, 119, 76, 1, 10, 49, 3, 6, 44, 335, 492],\n",
              " [248, 12, 375, 376, 377],\n",
              " [119, 76, 1, 10],\n",
              " [87, 12, 375, 376, 377, 23, 24, 10, 74],\n",
              " [72, 1, 81, 15, 9, 12, 413, 464, 6, 1, 6, 1],\n",
              " [6, 1, 6, 1],\n",
              " [6, 1, 6, 1],\n",
              " [6, 1, 6, 1],\n",
              " [6, 1, 6, 1],\n",
              " [6, 1, 6, 1],\n",
              " [6, 1, 6, 1],\n",
              " [6, 1, 6, 1],\n",
              " [6, 1, 6, 1],\n",
              " [6, 1, 6, 1],\n",
              " [6, 1, 6, 1],\n",
              " [6, 1, 6, 1, 5, 9, 3, 465, 3, 6, 1, 113],\n",
              " [20, 535, 4, 3, 6, 1, 95, 2, 493, 3, 494, 244, 23, 125],\n",
              " [193, 7, 426, 78, 191, 319, 3, 1110],\n",
              " [5, 217, 3, 494, 50, 756, 406],\n",
              " [62, 2, 93, 138, 4, 378, 2, 196, 3, 1111],\n",
              " [39, 1112, 66, 147, 57, 9, 7, 757],\n",
              " [39, 197, 575, 16, 3, 545, 138, 357],\n",
              " [7, 758, 17, 107, 1113, 5, 1114],\n",
              " [1115, 425, 66, 263, 163],\n",
              " [180, 50, 327, 427],\n",
              " [55, 39, 50, 77, 3, 576, 17, 1116, 2, 196, 7, 1117, 244, 23, 125],\n",
              " [3, 571, 1118, 138, 93, 1119, 3, 1120],\n",
              " [7, 758, 17, 107, 1121, 121],\n",
              " [40, 2, 93, 138, 4, 119],\n",
              " [1122, 493, 3, 759],\n",
              " [168, 6, 4, 424, 1, 18, 1123, 111, 379, 57, 17, 428],\n",
              " [1124, 7, 1125, 403, 12, 142],\n",
              " [287, 12, 54, 1126, 5, 1127, 7, 644],\n",
              " [5, 372, 111, 2, 760, 2, 50, 761],\n",
              " [287, 12, 1128, 5, 1129, 12, 1130],\n",
              " [319, 3, 1131, 9, 1132, 720],\n",
              " [287, 12, 54, 1133, 5, 138, 7, 1134],\n",
              " [267, 1135, 5, 2, 321, 258, 7, 363, 2, 493, 3, 494, 244, 23, 125],\n",
              " [145, 762, 577, 9, 1136, 1137],\n",
              " [5, 217, 3, 577, 176, 756, 578],\n",
              " [68, 138, 4, 733, 140, 10],\n",
              " [22, 68, 14, 88, 298, 577, 13, 416, 4, 291, 3, 1138, 1139],\n",
              " [168, 6, 4, 424, 1, 18, 380, 495, 496],\n",
              " [165, 72, 162, 16, 61, 47, 62],\n",
              " [12, 380],\n",
              " [380, 495, 496],\n",
              " [579, 580, 581, 582, 583, 381, 382, 383],\n",
              " [381, 382, 383],\n",
              " [2, 6, 1, 2, 6, 1, 2, 6, 1],\n",
              " [335, 10, 2, 56, 4, 21],\n",
              " [401, 2, 230, 7, 54],\n",
              " [2, 38, 21, 3, 102, 162, 2, 14, 16, 164, 299, 380, 495, 496],\n",
              " [579, 580, 581, 582, 583, 381, 382, 383],\n",
              " [381, 382, 383],\n",
              " [2, 43, 4, 2, 43, 4, 2, 43, 4],\n",
              " [2, 43, 4, 95, 1, 49],\n",
              " [23, 86, 1, 220, 4, 8],\n",
              " [401, 2, 34, 35, 584, 1, 38, 14, 86, 2, 220],\n",
              " [2, 6, 1, 2, 56, 1, 2, 56, 1, 2, 56, 1],\n",
              " [2, 101, 1, 14, 154, 22],\n",
              " [48, 26, 4, 1, 1140],\n",
              " [401, 2, 34, 35, 1141, 1, 42, 164, 299],\n",
              " [380, 495, 496],\n",
              " [579, 580, 581, 582, 583, 381, 382, 383],\n",
              " [381, 382, 383],\n",
              " [5, 2, 38, 21, 3, 102, 162, 2, 14, 16, 164, 299],\n",
              " [12, 380, 304, 305, 44, 20, 7, 585, 1142, 1143],\n",
              " [17, 170, 142, 209, 138, 3, 763, 4, 14],\n",
              " [5, 10, 3, 107, 16, 37, 5, 61],\n",
              " [204, 5, 21, 70, 18, 3, 764, 20, 7, 586, 30, 7, 1144],\n",
              " [5, 75, 195, 378, 76, 264, 336, 66, 28],\n",
              " [5, 3, 586, 51, 1145, 7, 1146],\n",
              " [9, 3, 765, 316, 429, 766, 304, 305, 20, 9, 12, 353, 5, 9, 12, 108],\n",
              " [44, 301, 3, 247, 587, 430],\n",
              " [2, 431, 5, 588, 28],\n",
              " [9, 304, 305, 44, 20, 7, 767, 30, 161, 1147],\n",
              " [5, 9, 66, 1148, 20, 7, 1149, 17, 3, 768],\n",
              " [39, 1150, 4, 589, 66, 769, 1151, 770],\n",
              " [33, 7, 770, 1152, 304, 305, 20, 9, 12, 353, 5, 9, 12, 108],\n",
              " [7, 145, 17, 1153, 5, 724, 771],\n",
              " [9, 547, 588, 28],\n",
              " [336, 3, 1154, 9, 3, 411, 17, 3, 1155],\n",
              " [3, 166, 1156, 20, 1157, 1158, 77, 7, 1159],\n",
              " [5, 217, 19, 531, 91, 55, 110, 9, 7, 228],\n",
              " [19, 20, 1160, 9, 304, 305, 3, 585, 772, 273, 1161],\n",
              " [52, 49, 3, 586, 333, 192, 41, 7, 1162],\n",
              " [5, 190, 3, 767, 1163, 9],\n",
              " [77, 3, 765, 316, 429, 766, 304, 305, 20, 9, 12, 353, 5, 9, 12, 108],\n",
              " [44, 301, 3, 247, 587, 430],\n",
              " [2, 431, 5, 588, 28],\n",
              " [304, 305, 20, 9, 12, 353, 5, 9, 12, 108],\n",
              " [44, 301, 3, 247, 587, 430],\n",
              " [304, 305, 590, 50, 7, 78, 191, 384, 39, 50, 7, 1164],\n",
              " [40, 39, 432, 13, 446, 326],\n",
              " [590, 433, 66, 69, 9, 1165, 1166],\n",
              " [41, 136, 1167, 1168, 26, 28, 26, 28],\n",
              " [26, 28, 4, 109, 1, 104, 274],\n",
              " [26, 28, 26, 28],\n",
              " [26, 28, 4, 109, 1, 104, 274],\n",
              " [26, 28, 590, 61, 69, 26, 28, 26, 28],\n",
              " [28, 4, 109, 1, 104, 274],\n",
              " [26, 28, 26, 28],\n",
              " [28, 4, 109, 1, 104, 274],\n",
              " [26, 28, 1169, 325, 773, 1170, 384, 19, 50, 7, 774],\n",
              " [40, 19, 50, 273, 78],\n",
              " [10, 3, 385, 219, 31, 21, 110, 60, 13, 775],\n",
              " [40, 19, 776, 13, 248, 19, 32, 26, 28, 26, 28],\n",
              " [26, 28, 4, 109, 1, 104, 274],\n",
              " [26, 28, 26, 28],\n",
              " [26, 28, 4, 109, 1, 104, 274],\n",
              " [26, 28, 773, 61, 69, 26, 28, 26, 28],\n",
              " [26, 28, 4, 109, 1, 104, 274],\n",
              " [26, 28, 26, 28],\n",
              " [26, 28, 4, 109, 1, 104, 274, 26, 28, 26, 28],\n",
              " [26, 28, 4, 109, 1, 104, 274],\n",
              " [26, 28, 26, 28, 26, 28, 104, 44, 50, 7, 54],\n",
              " [4, 26, 28, 362, 104, 44, 50, 7, 54],\n",
              " [4, 26, 28, 69, 205, 166, 123],\n",
              " [1171, 83, 206],\n",
              " [5, 2, 38, 115, 7, 261, 463, 533],\n",
              " [291, 25, 108],\n",
              " [410, 1172, 1, 36, 1, 534],\n",
              " [205, 166, 123],\n",
              " [34, 83, 206],\n",
              " [5, 2, 38, 115, 7, 261, 104, 44, 50, 7, 54],\n",
              " [4, 26, 28, 362, 104, 44, 50, 7, 54],\n",
              " [4, 26, 28, 69, 205, 166, 123],\n",
              " [34, 83, 206],\n",
              " [5, 2, 38, 115, 7, 261, 1, 21, 33, 25, 167],\n",
              " [33, 12, 167, 89, 24],\n",
              " [68, 21, 33, 25, 167],\n",
              " [129, 81, 82, 7, 65, 94],\n",
              " [35, 275, 33, 25, 167],\n",
              " [241, 167, 4, 1, 97, 129, 85, 4, 7, 386, 386],\n",
              " [97, 129, 85, 4, 7, 386, 386],\n",
              " [97, 129, 85, 4, 7, 386, 386, 2, 141, 45, 1, 4, 259, 167],\n",
              " [113, 7, 591, 591, 591, 449, 167],\n",
              " [2, 141, 45, 1, 4, 259, 167],\n",
              " [259, 1, 21, 33, 25, 167],\n",
              " [62, 33, 12, 167, 89, 24],\n",
              " [1, 21, 33, 25, 167],\n",
              " [129, 81, 82, 7, 65, 94],\n",
              " [35, 275, 33, 25, 167],\n",
              " [241, 167, 4, 1, 212, 3, 84, 20, 181, 13, 777, 8, 18],\n",
              " [212, 3, 84, 20, 181, 1173, 212, 3, 405, 20, 262, 13, 1174, 12, 147],\n",
              " [212, 3, 405, 20, 262, 1175, 6, 20, 371, 6, 20, 320],\n",
              " [6, 20, 10, 6, 20, 1, 212, 3, 106, 20, 247, 13, 434, 8, 206],\n",
              " [212, 3, 106, 20, 247, 1176, 1177, 778, 435, 9, 7, 592, 18, 7, 1178],\n",
              " [30, 1179, 1180, 5, 1181, 430],\n",
              " [267, 527, 1, 1, 257, 779, 532],\n",
              " [7, 64, 30, 780, 108, 1182, 781, 17, 98, 5, 484],\n",
              " [1183, 397, 25, 142],\n",
              " [119, 41, 3, 64, 30, 3, 67, 9, 31, 108],\n",
              " [5, 110, 202, 158, 9, 3, 106, 30, 171],\n",
              " [158, 9, 3, 106, 30, 171],\n",
              " [158, 9, 3, 106, 30, 171],\n",
              " [73, 1184, 31, 53, 4, 7, 1185, 154, 7, 1186],\n",
              " [109, 782, 1187, 107, 783, 1188, 771],\n",
              " [497, 410, 91, 1, 1189, 711, 3, 781],\n",
              " [16, 556, 42, 1190, 262, 1191, 1192, 784, 18, 3, 1193],\n",
              " [192, 4, 113, 1, 121],\n",
              " [1194, 9, 3, 28, 30, 25, 142, 9, 3, 785],\n",
              " [5, 92, 202, 158, 9, 3, 106, 30, 171],\n",
              " [158, 9, 3, 106, 30, 171],\n",
              " [158, 9, 3, 106, 30, 171],\n",
              " [73, 778, 435, 18, 7, 1195, 9, 7, 1196],\n",
              " [30, 1197, 1198, 30, 372, 1199, 1200],\n",
              " [520, 232, 20, 44, 76, 3, 1201],\n",
              " [3, 64, 30, 3, 780, 108, 158, 9, 3, 106, 30, 171],\n",
              " [158, 9, 3, 106, 30, 171],\n",
              " [158, 9, 3, 106, 30, 171],\n",
              " [73],\n",
              " [158, 9, 3, 106, 30, 171],\n",
              " [158, 9, 3, 106, 30, 171],\n",
              " [158, 9, 3, 106, 30, 171],\n",
              " [73],\n",
              " [158, 9, 3, 106, 30, 171],\n",
              " [158, 9, 3, 106, 30, 171],\n",
              " [158, 9, 3, 106, 30, 171, 7, 285, 75, 1202, 1203, 258, 12, 1204],\n",
              " [39, 245, 34, 126, 74, 93, 333, 53, 5, 119, 42, 65],\n",
              " [39, 27, 56, 4, 61, 4, 786, 5, 360, 4, 493, 5, 498],\n",
              " [93, 1205, 219, 3, 576, 5, 530, 3, 436, 5, 499, 451, 10, 134],\n",
              " [62, 39, 1206, 136, 1207, 18, 1208, 787],\n",
              " [788, 1209, 1210, 9, 75, 1211, 364],\n",
              " [78, 593, 594, 435, 146, 170, 436, 5, 499, 759, 18, 3, 1212, 487],\n",
              " [170, 1213, 16, 39, 26, 20, 595, 4, 3, 1214, 78],\n",
              " [62, 39, 1215, 66, 789, 222, 76, 134, 110, 790, 4, 1216],\n",
              " [77, 782, 5, 7, 1217, 437, 9, 7, 1218, 1219],\n",
              " [62, 149, 436, 5, 499, 221, 60, 4, 204],\n",
              " [791, 142, 20, 207, 91, 436],\n",
              " [22, 593, 594, 435, 85, 105, 25, 1220, 1, 139, 34, 86, 19, 174],\n",
              " [26, 4, 3, 585, 792, 5, 26, 16, 364, 739, 500, 25, 142],\n",
              " [39, 1221, 25, 1222, 5, 39, 1223, 13, 4, 3, 1224, 1225],\n",
              " [39, 1226, 3, 1227, 1228, 7, 793, 9, 1229, 1230],\n",
              " [62, 1231, 142, 221, 60, 4, 204],\n",
              " [791, 142, 20, 207, 91, 436],\n",
              " [22, 593, 594, 435, 2, 116, 31, 10, 12, 6],\n",
              " [335, 10, 2, 34],\n",
              " [5, 55, 1, 196, 12, 6],\n",
              " [596, 6, 31, 4],\n",
              " [2, 6, 31, 19, 539, 12, 151],\n",
              " [5, 1232],\n",
              " [3, 438, 12, 554, 794],\n",
              " [19, 794, 4, 8],\n",
              " [5, 2, 6, 31, 7, 6, 45, 1233],\n",
              " [137, 51, 439],\n",
              " [91, 96, 91, 2],\n",
              " [82, 1, 423, 8, 795, 72, 3, 796, 16, 523],\n",
              " [361, 20, 3, 106],\n",
              " [2, 14, 149, 6, 17, 179],\n",
              " [38, 51, 439],\n",
              " [5, 2, 6, 31, 795, 72, 3, 796, 16, 523],\n",
              " [361, 20, 3, 106],\n",
              " [2, 14, 149, 6, 17, 179],\n",
              " [38, 51, 439],\n",
              " [5, 2, 6, 31, 597, 1, 21, 97, 2, 21, 46],\n",
              " [1, 21, 204, 5, 2, 21, 61, 61, 61],\n",
              " [23, 46],\n",
              " [1, 21, 120, 5, 2, 21, 70, 70, 70],\n",
              " [2, 27, 14, 100, 1, 21, 120, 2, 21, 70, 70, 70],\n",
              " [2, 27, 14, 100, 1, 21, 120, 2, 21, 70, 2, 21, 262, 1, 21, 470],\n",
              " [1, 21, 100, 5, 2, 21, 2, 27, 14],\n",
              " [23, 46],\n",
              " [1, 21, 120, 5, 2, 21, 70, 70, 70],\n",
              " [2, 27, 14, 100, 1, 21, 120, 2, 21, 70, 70, 70],\n",
              " [70, 120, 70, 120, 70, 120],\n",
              " [2, 27, 14, 100, 1, 21, 120, 2, 21, 70, 70, 120, 70, 120, 70, 120, 70, 120],\n",
              " [100, 100, 100, 100, 100, 100, 34, 1],\n",
              " [21, 120, 120, 797, 797],\n",
              " [23, 46],\n",
              " [1, 21, 120, 5, 2, 21, 70, 70, 70],\n",
              " [2, 27, 14, 100, 1, 21, 120, 2, 21, 70, 70, 70],\n",
              " [2, 27, 14, 100, 1, 21, 120, 2, 21, 70, 1, 21, 97, 2, 21, 46],\n",
              " [2, 21, 97, 40, 2, 231, 220, 46],\n",
              " [1, 21, 204, 2, 21, 61, 61, 61],\n",
              " [2, 32, 314, 87, 33, 94, 4, 61],\n",
              " [23, 23, 46, 1, 21, 120, 5, 2, 21, 70, 70, 70],\n",
              " [2, 27, 14, 100, 1, 21, 120, 2, 21, 70, 70, 70],\n",
              " [2, 27, 14, 100, 1, 21, 120, 2, 21, 70, 70, 70],\n",
              " [2, 27, 14, 100, 1, 21, 120, 2, 21, 70, 798, 23, 70],\n",
              " [249, 276, 277, 249, 276, 277, 249, 276, 277],\n",
              " [249, 276, 277, 249, 249, 276, 277, 249, 276, 277],\n",
              " [249, 276, 277, 249, 276, 277, 249, 276, 277, 2, 104, 138, 7, 64],\n",
              " [238, 132, 2, 21, 19, 104, 138, 8],\n",
              " [19, 1234, 8, 31, 337],\n",
              " [293, 13, 65, 799, 800, 19, 1235, 8, 4, 314],\n",
              " [5, 19, 184, 8, 4, 431, 1236],\n",
              " [42, 2, 501, 219],\n",
              " [5, 2, 760, 44, 1237, 7, 787, 2, 1238, 18, 7, 1239, 1240, 12, 94],\n",
              " [1241, 31, 477],\n",
              " [52, 1242, 401, 152, 5, 190, 19, 174],\n",
              " [33, 94, 41, 428, 19, 184, 8, 19, 801],\n",
              " [9, 3, 598, 5, 1243, 4, 378],\n",
              " [2, 184, 31, 2, 197],\n",
              " [5, 1244, 500, 4, 205, 9, 3, 793, 5, 36, 2, 1245, 2, 50, 211],\n",
              " [149, 1246, 138, 1247],\n",
              " [42, 2, 1248, 7, 769],\n",
              " [293, 13, 65, 799, 800, 62, 224, 13, 111, 278, 22],\n",
              " [279, 5, 387],\n",
              " [37, 18, 37, 18, 37, 37, 18, 278, 22],\n",
              " [37, 18, 5, 185, 13, 18, 57],\n",
              " [62, 185, 13, 18, 57, 599],\n",
              " [1, 14, 1, 119, 42, 65],\n",
              " [1, 14, 1, 60, 8, 1249, 22],\n",
              " [93, 45, 2, 14, 1, 141, 62, 224, 13, 111, 278, 22],\n",
              " [279, 5, 387],\n",
              " [37, 18, 37, 18, 37, 37, 18, 278, 22],\n",
              " [37, 18, 5, 185, 13, 18, 57],\n",
              " [1, 14, 1, 279, 75, 64],\n",
              " [1, 14, 1, 279, 42, 600],\n",
              " [37, 18, 5, 279, 7, 75, 802, 22],\n",
              " [5, 29, 8, 14, 16, 92, 179, 601, 73, 73, 73, 73, 798],\n",
              " [278, 22],\n",
              " [279, 5, 387],\n",
              " [37, 18, 37, 18, 37, 37, 18, 278, 22],\n",
              " [37, 18, 5, 185, 13, 18, 57],\n",
              " [1, 14, 1, 279, 75, 64],\n",
              " [1, 14, 1, 279, 42, 600],\n",
              " [37, 18, 5, 279, 7, 75, 802, 22],\n",
              " [5, 29, 8, 14, 16, 92, 179],\n",
              " [62, 224, 13, 224, 13, 224, 13, 278, 22],\n",
              " [62, 224, 13, 224, 13, 224, 13, 278, 22],\n",
              " [62, 224, 13, 224, 13, 224, 13, 278, 22],\n",
              " [73, 73, 73, 73, 19, 199, 1, 24, 24, 24],\n",
              " [19, 199, 1, 24, 24, 24],\n",
              " [19, 199, 1, 24, 24, 24, 1, 101, 272, 595, 25, 6],\n",
              " [62, 2, 196, 31, 200, 803, 804],\n",
              " [33, 1, 110, 805, 17],\n",
              " [5, 19, 184, 8, 86, 4, 21, 803, 804, 19, 415, 19, 199, 1],\n",
              " [5, 1, 14, 16, 63, 15, 285],\n",
              " [97, 19, 199, 1],\n",
              " [5, 1, 14, 1, 132, 15, 275, 19, 174, 1, 602, 31, 42],\n",
              " [19, 1250, 595, 31, 147],\n",
              " [5, 22, 19, 415, 19, 270],\n",
              " [92, 83, 3, 1251, 280, 19, 415, 19, 199, 1],\n",
              " [5, 1, 14, 16, 63, 15, 285],\n",
              " [97, 19, 199, 1],\n",
              " [5, 1, 14, 1, 132, 15, 275, 440, 19, 199, 1, 24, 24, 24],\n",
              " [19, 199, 1, 24, 24, 24],\n",
              " [30, 7, 6, 45, 16],\n",
              " [1, 14, 1, 132, 15, 275, 1, 14, 33, 111, 4, 1],\n",
              " [2, 101, 33, 102, 1252],\n",
              " [806, 32, 602, 1, 89],\n",
              " [1253, 4, 31, 212, 19, 199, 1],\n",
              " [5, 1, 14, 16, 63, 15, 285],\n",
              " [97, 19, 199, 1],\n",
              " [5, 1, 14, 1, 132, 15, 275, 440, 19, 199, 1, 24, 24, 24],\n",
              " [19, 199, 1, 24, 24, 24],\n",
              " [30, 7, 6, 45, 16],\n",
              " [1, 14, 1, 132, 15, 275],\n",
              " [30, 7, 6, 45, 16],\n",
              " [1, 14, 1, 132, 15, 275],\n",
              " [30, 7, 6, 45, 16],\n",
              " [1, 14, 1, 132, 15, 275],\n",
              " [24, 24, 24],\n",
              " [24, 24, 24, 24, 73, 119, 76, 10, 3, 124, 107],\n",
              " [73, 119, 76, 10, 3, 124, 107, 807, 808, 1254, 111, 3, 1255],\n",
              " [9, 3, 809, 109, 7, 1256, 221, 103],\n",
              " [1257, 9, 7, 363],\n",
              " [810, 76, 3, 811, 812, 3, 263],\n",
              " [16, 19, 306, 9, 7, 1258, 154, 3, 240],\n",
              " [191, 20, 13, 41, 10, 3, 124, 107],\n",
              " [109, 34, 68, 10, 37, 77],\n",
              " [10, 3, 124, 107],\n",
              " [109, 34, 68, 10, 603, 574, 813, 604, 3, 162],\n",
              " [17, 7, 1259, 16, 46, 59, 38, 330],\n",
              " [46, 59, 133, 423],\n",
              " [119, 76, 264, 502, 1260, 66, 1261],\n",
              " [9, 3, 134, 36, 173, 180, 44],\n",
              " [86, 265, 39, 281, 10, 3, 124, 107],\n",
              " [109, 34, 68, 10, 37, 77],\n",
              " [10, 3, 124, 107],\n",
              " [109, 34, 68, 10, 603, 73, 119, 76, 10, 3, 124, 107],\n",
              " [73, 119, 76, 10, 3, 124, 107, 807, 808, 605, 9, 3, 809],\n",
              " [5, 50, 1262, 814, 30, 31, 567],\n",
              " [180, 218],\n",
              " [574, 813, 1263, 3, 1264],\n",
              " [77, 66, 503, 91, 39, 1265, 77, 3, 1266],\n",
              " [46, 59, 50, 664, 10, 3, 124, 107],\n",
              " [109, 34, 68, 10, 37, 77],\n",
              " [10, 3, 124, 107],\n",
              " [109, 34, 68, 10, 603, 62, 19, 50, 93, 1267],\n",
              " [1, 14, 86, 2, 220],\n",
              " [5, 3, 54, 19, 501],\n",
              " [50, 54, 1268, 1269],\n",
              " [42, 88, 137, 2, 259, 30, 273],\n",
              " [23, 36, 2, 196, 31, 189, 44, 62, 19, 501, 76, 8],\n",
              " [5, 2, 2, 137, 49],\n",
              " [16, 163, 89, 96],\n",
              " [168, 606, 9, 6, 30, 31],\n",
              " [19, 446, 259, 30, 273],\n",
              " [23, 36, 2, 196, 31, 189, 44, 62, 12, 260, 321, 815],\n",
              " [36, 2, 816, 16, 337],\n",
              " [5, 2, 504, 31, 128, 9, 179, 23, 52, 817, 352, 3, 134],\n",
              " [5, 52, 504, 388, 370, 389],\n",
              " [5, 163, 89, 96],\n",
              " [2, 379, 9, 6, 30, 31],\n",
              " [22, 48, 51, 259, 30, 273],\n",
              " [23, 36, 2, 196, 31, 189, 44, 62, 12, 260, 321, 815],\n",
              " [36, 2, 816, 16, 337],\n",
              " [5, 2, 504, 31, 128, 9, 179, 23, 52, 817, 352, 3, 134],\n",
              " [5, 52, 504, 388, 370, 389],\n",
              " [5, 163, 89, 96],\n",
              " [2, 379, 9, 6, 30, 31],\n",
              " [22, 48, 51, 259, 30, 273],\n",
              " [23, 36, 2, 196, 31, 189, 44],\n",
              " [23, 409, 2, 196, 31, 189, 44],\n",
              " [24, 62, 409, 2, 196, 31, 189, 44, 818, 25, 108, 5, 48, 438, 1],\n",
              " [450, 48, 819, 1],\n",
              " [318, 48, 127, 15, 172],\n",
              " [5, 190, 248, 35, 121],\n",
              " [48, 498, 69, 170, 71],\n",
              " [5, 48, 235, 10, 12, 225, 4, 1, 48, 1270, 16, 35, 1271],\n",
              " [3, 820, 2, 130, 607],\n",
              " [5, 338, 16, 12, 413, 38, 37, 172],\n",
              " [5, 190, 248, 35, 121],\n",
              " [48, 498, 69, 170, 71],\n",
              " [5, 48, 235, 10, 12, 225, 4, 1, 10, 12, 225, 2, 38, 235, 4, 1],\n",
              " [10, 12, 225, 123, 48, 15, 172, 818, 25, 108, 5, 48, 438, 1],\n",
              " [450, 48, 819, 1],\n",
              " [318, 48, 127, 15, 172],\n",
              " [5, 190, 248, 35, 121],\n",
              " [48, 498, 69, 170, 71],\n",
              " [5, 48, 235, 10, 12, 225, 4, 1, 10, 12, 225, 2, 38, 235, 4, 1],\n",
              " [10, 12, 225, 123, 48, 15, 172],\n",
              " [10, 12, 225, 10, 12, 225],\n",
              " [601,\n",
              "  10,\n",
              "  12,\n",
              "  225,\n",
              "  2,\n",
              "  38,\n",
              "  235,\n",
              "  4,\n",
              "  1,\n",
              "  33,\n",
              "  103,\n",
              "  7,\n",
              "  207,\n",
              "  505,\n",
              "  134,\n",
              "  5,\n",
              "  2,\n",
              "  103,\n",
              "  502,\n",
              "  45,\n",
              "  7,\n",
              "  608],\n",
              " [33, 103, 7, 207, 505, 134, 2, 132, 15, 492, 45, 7, 821],\n",
              " [40, 36, 2, 26, 69, 4, 1, 48, 230, 3, 203, 16, 1, 34],\n",
              " [38, 95, 8, 135, 339, 1, 14, 2, 185, 10, 71, 4, 26, 1, 183, 4, 146, 1, 203],\n",
              " [5, 33, 1272, 13, 93, 4, 330, 1, 21, 92, 85, 4, 116, 8, 151],\n",
              " [42, 100, 18, 609, 132, 2, 822, 194, 36, 2, 26, 1, 211],\n",
              " [1, 14, 2, 135, 610, 36, 35, 69, 151, 290, 4, 15, 74],\n",
              " [36, 35, 69, 269, 1, 611, 8, 389, 389, 823],\n",
              " [42, 100, 18, 609, 132, 2, 822, 194, 36, 2, 26, 1, 211],\n",
              " [1, 14, 2, 135, 610, 36, 35, 69, 151, 290, 4, 15, 74],\n",
              " [36,\n",
              "  35,\n",
              "  69,\n",
              "  269,\n",
              "  1,\n",
              "  611,\n",
              "  8,\n",
              "  389,\n",
              "  389,\n",
              "  24,\n",
              "  33,\n",
              "  103,\n",
              "  7,\n",
              "  207,\n",
              "  505,\n",
              "  134,\n",
              "  5,\n",
              "  2,\n",
              "  103,\n",
              "  502,\n",
              "  45,\n",
              "  7,\n",
              "  608],\n",
              " [33, 103, 7, 207, 505, 134, 2, 132, 15, 492, 45, 7, 821],\n",
              " [40, 36, 2, 26, 69, 4, 1, 48, 230, 3, 203, 16, 1, 34],\n",
              " [38, 95, 8, 135, 339],\n",
              " [1, 14, 2, 135, 339],\n",
              " [1, 14, 2, 135, 339, 6, 6, 8, 34],\n",
              " [1, 14, 2, 6, 1],\n",
              " [48, 127, 15, 172],\n",
              " [42, 90, 6, 8, 34],\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_context_size+1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b48R11MMZ9SR",
        "outputId": "43bf7503-c228-4858-c69f-2111a43dcf66"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_context_size_2+1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4ky_2_pXFiW",
        "outputId": "160baaeb-6974-4743-d5e1-19af3c8d1019"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Organizando y estructurando el dataset"
      ],
      "metadata": {
        "id": "pfpYcaypKcI9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este punto tenemos en la variable `tokenized_sentences` los versos tokenizados. Vamos a quedarnos con un conjunto de validación que utilizaremos para medir la calidad de la generación de secuencias con la métrica de Perplejidad."
      ],
      "metadata": {
        "id": "l3iPTx-UJl6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sentences_train, tokenized_sentences_val, _, _ = train_test_split(tokenized_sentences, tokenized_sentences, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "cSeqVGyV_wz5"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a splitear las oraciones que tienen tamaño mayor al contexto máximo, para generarnos más secuencias de entrenamiento. Este paso puede obviarse si el tamaño de contexto máximo es muy grande."
      ],
      "metadata": {
        "id": "gmsoPbV6LxcW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Token Sentences original**"
      ],
      "metadata": {
        "id": "RzTFdCO_6XDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tok_sent = []\n",
        "\n",
        "for sent in tokenized_sentences_train:\n",
        "\n",
        "  # si la secuencia tiene más términos que el tamaño de contexto máximo,\n",
        "  # armo varias sub-secuencias de tamaño máximo\n",
        "  if len(sent) > (max_context_size+1):\n",
        "    extra = len(sent)-(max_context_size+1) + 1\n",
        "    for i in range(extra):\n",
        "      tok_sent.append(sent[i:i+max_context_size+1])\n",
        "  else: # si la secuencia tiene menos términos el tamaño de contexto máximo, dejo la secuencia como está\n",
        "    tok_sent.append(sent)\n"
      ],
      "metadata": {
        "id": "E5BPO4qPPnNR"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tok_sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiEt0AAz_64v",
        "outputId": "b6e80a28-84d5-427c-9acc-2c396fe951c0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1957"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Token Sentences Nuevo size**"
      ],
      "metadata": {
        "id": "_lrBJk3Q6bpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generamos las sentencias con este nuevo contexto\n",
        "tok_sent_2 = []\n",
        "\n",
        "for sent in tokenized_sentences_train:\n",
        "\n",
        "  # si la secuencia tiene más términos que el tamaño de contexto máximo,\n",
        "  # armo varias sub-secuencias de tamaño máximo\n",
        "  if len(sent) > (max_context_size_2+1):\n",
        "    extra = len(sent)-(max_context_size_2+1) + 1\n",
        "    for i in range(extra):\n",
        "      tok_sent_2.append(sent[i:i+max_context_size_2+1])\n",
        "  else: # si la secuencia tiene menos términos el tamaño de contexto máximo, dejo la secuencia como está\n",
        "    tok_sent_2.append(sent)"
      ],
      "metadata": {
        "id": "TOQUirO_XM4G"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tok_sent_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsYoNbfnXXge",
        "outputId": "7cd50bd8-8928-4045-9789-10d294917ed7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2718"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora aumentamos los datos aprovechando que de una secuencia grande se pueden generar varias más pequeñas:\n",
        "\n",
        "- *La hermosa casa en el prado*\n",
        "- *La hermosa*\n",
        "- *La hermosa casa*\n",
        "- *La hermosa casa en*\n",
        "- *La hermosa casa en el*\n",
        "- *La hermosa casa en el prado*"
      ],
      "metadata": {
        "id": "QnwSC7A_LWfd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Con data augmentation ambos token sentences**"
      ],
      "metadata": {
        "id": "zKbh1ATh6iRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tok_sent_augm = []\n",
        "\n",
        "for sent in tok_sent:\n",
        "\n",
        "  # generamos todas las sub-secuencias\n",
        "  subseq = [sent[:i+2] for i in range(len(sent)-1)]\n",
        "  # en esta línea paddeamos al tamaño de contexto máximo\n",
        "  tok_sent_augm.append(pad_sequences(subseq, maxlen=max_context_size+1, padding='pre'))\n"
      ],
      "metadata": {
        "id": "lWdhVV04htki"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizamos el augmentation\n",
        "tok_sent_augm_2 = []\n",
        "\n",
        "for sent in tok_sent_2:\n",
        "\n",
        "  # generamos todas las sub-secuencias\n",
        "  subseq = [sent[:i+2] for i in range(len(sent)-1)]\n",
        "  # en esta línea paddeamos al tamaño de contexto máximo\n",
        "  tok_sent_augm_2.append(pad_sequences(subseq, maxlen=max_context_size_2+1, padding='pre'))"
      ],
      "metadata": {
        "id": "wBq6ekevXe7-"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Concatenamos las secuencias**"
      ],
      "metadata": {
        "id": "DoScvtPQ64S8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# finalmente concatenamos todas las secuencias en un único array de numpy\n",
        "train_seqs = np.concatenate(tok_sent_augm, axis=0)"
      ],
      "metadata": {
        "id": "THXXBya1tnZ8"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finalmente concatenamos todas las secuencias en un único array de numpy\n",
        "train_seqs_2 = np.concatenate(tok_sent_augm_2, axis=0)"
      ],
      "metadata": {
        "id": "zEoIqZDWXtpm"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_seqs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5Uiflnwt10J",
        "outputId": "fab951a3-5a16-4c14-924c-b31c1e1b9224"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15325, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_seqs_2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbAoOxRtXx3e",
        "outputId": "a77de690-2431-4446-e7d9-f0bb999e0796"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19970, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizamos un chequeo de dimensiones\n",
        "train_seqs_2[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wh4HxXhdNlZc",
        "outputId": "ea959c36-1e77-4cbc-b5d0-f5949ee0f693"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   5, 217],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   5, 217,  19],\n",
              "       [  0,   0,   0,   0,   0,   0,   5, 217,  19, 384],\n",
              "       [  0,   0,   0,   0,   0,   5, 217,  19, 384,   2],\n",
              "       [  0,   0,   0,   0,   5, 217,  19, 384,   2, 432],\n",
              "       [  0,   0,   0,   5, 217,  19, 384,   2, 432,   3],\n",
              "       [  0,   0,   5, 217,  19, 384,   2, 432,   3, 257],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0, 248,  12],\n",
              "       [  0,   0,   0,   0,   0,   0,   0, 248,  12, 375],\n",
              "       [  0,   0,   0,   0,   0,   0, 248,  12, 375, 376]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generamos ambos sets de datos**"
      ],
      "metadata": {
        "id": "16Tvd6h17GdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# y de aquí sacamos las entradas y los targets que consumirá nuestro sistema en\n",
        "# tiempo de entrenamiento\n",
        "X = train_seqs[:,:-1]\n",
        "y = train_seqs[:,-1]"
      ],
      "metadata": {
        "id": "yprwJHiMBQIS"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y de aquí sacamos las entradas y los targets que consumirá nuestro sistema en\n",
        "# tiempo de entrenamiento\n",
        "X2 = train_seqs_2[:,:-1]\n",
        "y2 = train_seqs_2[:,-1]"
      ],
      "metadata": {
        "id": "pbsCPxFyX_Iv"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Palabras del vocabulario\n",
        "tok.index_word"
      ],
      "metadata": {
        "id": "1D9ESMGyB_QD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5e0f0d8-5494-4e9a-ca3b-8556d23aadc4"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'you',\n",
              " 2: 'i',\n",
              " 3: 'the',\n",
              " 4: 'to',\n",
              " 5: 'and',\n",
              " 6: 'love',\n",
              " 7: 'a',\n",
              " 8: 'me',\n",
              " 9: 'in',\n",
              " 10: 'all',\n",
              " 11: 'nah',\n",
              " 12: 'my',\n",
              " 13: 'it',\n",
              " 14: 'know',\n",
              " 15: 'be',\n",
              " 16: 'that',\n",
              " 17: 'of',\n",
              " 18: 'on',\n",
              " 19: 'she',\n",
              " 20: 'is',\n",
              " 21: 'say',\n",
              " 22: 'now',\n",
              " 23: 'oh',\n",
              " 24: 'yeah',\n",
              " 25: 'your',\n",
              " 26: 'get',\n",
              " 27: \"don't\",\n",
              " 28: 'back',\n",
              " 29: 'let',\n",
              " 30: 'with',\n",
              " 31: 'her',\n",
              " 32: 'can',\n",
              " 33: \"it's\",\n",
              " 34: 'do',\n",
              " 35: \"i'm\",\n",
              " 36: 'when',\n",
              " 37: 'come',\n",
              " 38: 'will',\n",
              " 39: 'he',\n",
              " 40: 'but',\n",
              " 41: 'for',\n",
              " 42: 'so',\n",
              " 43: 'need',\n",
              " 44: 'there',\n",
              " 45: 'like',\n",
              " 46: 'no',\n",
              " 47: 'together',\n",
              " 48: \"i'll\",\n",
              " 49: 'see',\n",
              " 50: 'was',\n",
              " 51: 'never',\n",
              " 52: 'we',\n",
              " 53: 'down',\n",
              " 54: 'way',\n",
              " 55: 'if',\n",
              " 56: 'want',\n",
              " 57: 'out',\n",
              " 58: 'hey',\n",
              " 59: 'one',\n",
              " 60: 'got',\n",
              " 61: 'go',\n",
              " 62: 'well',\n",
              " 63: \"can't\",\n",
              " 64: 'girl',\n",
              " 65: 'good',\n",
              " 66: 'his',\n",
              " 67: 'sun',\n",
              " 68: 'they',\n",
              " 69: 'home',\n",
              " 70: 'hello',\n",
              " 71: 'day',\n",
              " 72: 'are',\n",
              " 73: 'ah',\n",
              " 74: 'right',\n",
              " 75: 'little',\n",
              " 76: 'at',\n",
              " 77: 'from',\n",
              " 78: 'man',\n",
              " 79: 'here',\n",
              " 80: 'help',\n",
              " 81: 'gonna',\n",
              " 82: 'have',\n",
              " 83: 'not',\n",
              " 84: 'world',\n",
              " 85: 'going',\n",
              " 86: 'what',\n",
              " 87: 'still',\n",
              " 88: 'how',\n",
              " 89: 'too',\n",
              " 90: 'please',\n",
              " 91: 'as',\n",
              " 92: \"you're\",\n",
              " 93: 'just',\n",
              " 94: 'time',\n",
              " 95: 'make',\n",
              " 96: 'long',\n",
              " 97: 'yes',\n",
              " 98: 'yellow',\n",
              " 99: 'life',\n",
              " 100: 'why',\n",
              " 101: 'think',\n",
              " 102: 'only',\n",
              " 103: 'been',\n",
              " 104: 'once',\n",
              " 105: 'tell',\n",
              " 106: 'sky',\n",
              " 107: 'people',\n",
              " 108: 'eyes',\n",
              " 109: 'where',\n",
              " 110: \"she's\",\n",
              " 111: 'up',\n",
              " 112: 'jude',\n",
              " 113: 'take',\n",
              " 114: 'submarine',\n",
              " 115: 'sing',\n",
              " 116: 'give',\n",
              " 117: 'nowhere',\n",
              " 118: 'hold',\n",
              " 119: 'look',\n",
              " 120: 'goodbye',\n",
              " 121: 'away',\n",
              " 122: 'friends',\n",
              " 123: 'darling',\n",
              " 124: 'lonely',\n",
              " 125: 'boy',\n",
              " 126: 'nothing',\n",
              " 127: 'always',\n",
              " 128: 'hand',\n",
              " 129: \"we're\",\n",
              " 130: 'am',\n",
              " 131: 'goo',\n",
              " 132: 'should',\n",
              " 133: 'comes',\n",
              " 134: 'night',\n",
              " 135: 'feel',\n",
              " 136: 'some',\n",
              " 137: 'could',\n",
              " 138: 'had',\n",
              " 139: 'better',\n",
              " 140: 'them',\n",
              " 141: 'would',\n",
              " 142: 'head',\n",
              " 143: \"i've\",\n",
              " 144: 'more',\n",
              " 145: 'four',\n",
              " 146: 'buy',\n",
              " 147: 'mind',\n",
              " 148: 'carry',\n",
              " 149: 'this',\n",
              " 150: 'la',\n",
              " 151: 'everything',\n",
              " 152: 'two',\n",
              " 153: 'change',\n",
              " 154: 'by',\n",
              " 155: 'weight',\n",
              " 156: 'us',\n",
              " 157: 'our',\n",
              " 158: 'lucy',\n",
              " 159: 'sunshine',\n",
              " 160: 'believe',\n",
              " 161: 'an',\n",
              " 162: 'words',\n",
              " 163: 'before',\n",
              " 164: \"you'll\",\n",
              " 165: 'these',\n",
              " 166: 'pretty',\n",
              " 167: 'birthday',\n",
              " 168: \"i'd\",\n",
              " 169: 'three',\n",
              " 170: 'every',\n",
              " 171: 'diamonds',\n",
              " 172: 'true',\n",
              " 173: \"there's\",\n",
              " 174: 'said',\n",
              " 175: 'mm',\n",
              " 176: 'were',\n",
              " 177: 'forever',\n",
              " 178: 'dear',\n",
              " 179: 'mine',\n",
              " 180: 'nobody',\n",
              " 181: 'round',\n",
              " 182: 'leave',\n",
              " 183: 'money',\n",
              " 184: 'told',\n",
              " 185: 'work',\n",
              " 186: 'bom',\n",
              " 187: 'something',\n",
              " 188: 'hide',\n",
              " 189: 'standing',\n",
              " 190: 'then',\n",
              " 191: 'who',\n",
              " 192: 'waiting',\n",
              " 193: 'about',\n",
              " 194: \"'cause\",\n",
              " 195: 'children',\n",
              " 196: 'saw',\n",
              " 197: \"didn't\",\n",
              " 198: 'try',\n",
              " 199: 'loves',\n",
              " 200: 'yesterday',\n",
              " 201: \"nothing's\",\n",
              " 202: 'gone',\n",
              " 203: 'things',\n",
              " 204: 'stop',\n",
              " 205: 'sleep',\n",
              " 206: 'cry',\n",
              " 207: 'hard',\n",
              " 208: 'di',\n",
              " 209: \"he's\",\n",
              " 210: 'days',\n",
              " 211: 'alone',\n",
              " 212: 'because',\n",
              " 213: 'falling',\n",
              " 214: 'again',\n",
              " 215: 'prudence',\n",
              " 216: 'bang',\n",
              " 217: 'though',\n",
              " 218: 'came',\n",
              " 219: 'around',\n",
              " 220: 'mean',\n",
              " 221: 'has',\n",
              " 222: 'till',\n",
              " 223: 'juba',\n",
              " 224: 'shake',\n",
              " 225: 'loving',\n",
              " 226: 'eight',\n",
              " 227: 'five',\n",
              " 228: 'play',\n",
              " 229: 'place',\n",
              " 230: 'find',\n",
              " 231: 'may',\n",
              " 232: 'someone',\n",
              " 233: 'dead',\n",
              " 234: 'years',\n",
              " 235: 'send',\n",
              " 236: 'strawberry',\n",
              " 237: 'fields',\n",
              " 238: 'or',\n",
              " 239: 'band',\n",
              " 240: 'door',\n",
              " 241: 'happy',\n",
              " 242: 'garden',\n",
              " 243: 'anybody',\n",
              " 244: 'today',\n",
              " 245: \"won't\",\n",
              " 246: 'live',\n",
              " 247: 'blue',\n",
              " 248: 'while',\n",
              " 249: 'hela',\n",
              " 250: 'heaven',\n",
              " 251: 'week',\n",
              " 252: 'six',\n",
              " 253: 'seven',\n",
              " 254: 'rocky',\n",
              " 255: 'such',\n",
              " 256: 'easy',\n",
              " 257: 'answer',\n",
              " 258: 'into',\n",
              " 259: 'dance',\n",
              " 260: 'heart',\n",
              " 261: 'lullaby',\n",
              " 262: 'high',\n",
              " 263: 'face',\n",
              " 264: 'him',\n",
              " 265: 'does',\n",
              " 266: 'ask',\n",
              " 267: 'somebody',\n",
              " 268: 'any',\n",
              " 269: 'feeling',\n",
              " 270: 'knows',\n",
              " 271: 'talk',\n",
              " 272: \"you've\",\n",
              " 273: 'another',\n",
              " 274: 'belonged',\n",
              " 275: 'glad',\n",
              " 276: 'heba',\n",
              " 277: 'helloa',\n",
              " 278: 'baby',\n",
              " 279: 'twist',\n",
              " 280: 'kind',\n",
              " 281: 'care',\n",
              " 282: 'jai',\n",
              " 283: 'guru',\n",
              " 284: 'deva',\n",
              " 285: 'bad',\n",
              " 286: 'fool',\n",
              " 287: 'found',\n",
              " 288: 'loved',\n",
              " 289: 'fly',\n",
              " 290: 'seems',\n",
              " 291: 'fill',\n",
              " 292: 'done',\n",
              " 293: \"isn't\",\n",
              " 294: 'real',\n",
              " 295: 'much',\n",
              " 296: 'molly',\n",
              " 297: 'ever',\n",
              " 298: 'many',\n",
              " 299: 'understand',\n",
              " 300: 'sea',\n",
              " 301: 'beneath',\n",
              " 302: \"g'\",\n",
              " 303: 'joob',\n",
              " 304: 'penny',\n",
              " 305: 'lane',\n",
              " 306: 'keeps',\n",
              " 307: 'whoa',\n",
              " 308: 'sgt',\n",
              " 309: 'bompa',\n",
              " 310: 'ussr',\n",
              " 311: 'silver',\n",
              " 312: 'hoo',\n",
              " 313: 'taxman',\n",
              " 314: 'stay',\n",
              " 315: 'wisdom',\n",
              " 316: 'rain',\n",
              " 317: 'their',\n",
              " 318: 'remember',\n",
              " 319: 'made',\n",
              " 320: 'new',\n",
              " 321: 'went',\n",
              " 322: 'blackbird',\n",
              " 323: 'must',\n",
              " 324: 'desmond',\n",
              " 325: 'sweet',\n",
              " 326: 'last',\n",
              " 327: 'really',\n",
              " 328: 'smile',\n",
              " 329: 'show',\n",
              " 330: 'hear',\n",
              " 331: 'hmm',\n",
              " 332: 'crying',\n",
              " 333: 'sitting',\n",
              " 334: 'tired',\n",
              " 335: \"that's\",\n",
              " 336: 'behind',\n",
              " 337: 'room',\n",
              " 338: 'hope',\n",
              " 339: 'alright',\n",
              " 340: \"pepper's\",\n",
              " 341: 'lead',\n",
              " 342: 'everywhere',\n",
              " 343: 'road',\n",
              " 344: 'babe',\n",
              " 345: \"octopus'\",\n",
              " 346: 'bulldog',\n",
              " 347: 'woah',\n",
              " 348: 'hammer',\n",
              " 349: \"they're\",\n",
              " 350: 'wrong',\n",
              " 351: 'living',\n",
              " 352: 'through',\n",
              " 353: 'ears',\n",
              " 354: 'song',\n",
              " 355: 'under',\n",
              " 356: 'making',\n",
              " 357: 'changed',\n",
              " 358: 'lose',\n",
              " 359: 'singing',\n",
              " 360: 'learn',\n",
              " 361: 'dark',\n",
              " 362: 'homeward',\n",
              " 363: 'dream',\n",
              " 364: 'hair',\n",
              " 365: 'feed',\n",
              " 366: 'sixty',\n",
              " 367: 'doing',\n",
              " 368: \"somethin'\",\n",
              " 369: 'feet',\n",
              " 370: 'other',\n",
              " 371: 'old',\n",
              " 372: 'looking',\n",
              " 373: 'hill',\n",
              " 374: 'heard',\n",
              " 375: 'guitar',\n",
              " 376: 'gently',\n",
              " 377: 'weeps',\n",
              " 378: 'laugh',\n",
              " 379: 'fell',\n",
              " 380: 'michelle',\n",
              " 381: 'tres',\n",
              " 382: 'bien',\n",
              " 383: 'ensemble',\n",
              " 384: 'thought',\n",
              " 385: 'girls',\n",
              " 386: 'party',\n",
              " 387: 'shout',\n",
              " 388: 'each',\n",
              " 389: 'tight',\n",
              " 390: 'friend',\n",
              " 391: 'calling',\n",
              " 392: 'imagine',\n",
              " 393: 'harm',\n",
              " 394: 'phone',\n",
              " 395: \"maxwell's\",\n",
              " 396: 'o',\n",
              " 397: 'over',\n",
              " 398: 'times',\n",
              " 399: 'broken',\n",
              " 400: 'light',\n",
              " 401: 'until',\n",
              " 402: 'paper',\n",
              " 403: 'across',\n",
              " 404: 'waves',\n",
              " 405: 'wind',\n",
              " 406: 'sad',\n",
              " 407: 'moment',\n",
              " 408: 'free',\n",
              " 409: 'since',\n",
              " 410: 'smiles',\n",
              " 411: 'middle',\n",
              " 412: 'break',\n",
              " 413: 'dreams',\n",
              " 414: \"doesn't\",\n",
              " 415: 'says',\n",
              " 416: 'takes',\n",
              " 417: 'ob',\n",
              " 418: 'knee',\n",
              " 419: 'than',\n",
              " 420: 'thing',\n",
              " 421: 'walrus',\n",
              " 422: \"ain't\",\n",
              " 423: 'near',\n",
              " 424: 'turn',\n",
              " 425: 'seen',\n",
              " 426: 'lucky',\n",
              " 427: 'sure',\n",
              " 428: 'bed',\n",
              " 429: 'very',\n",
              " 430: 'skies',\n",
              " 431: 'sit',\n",
              " 432: 'knew',\n",
              " 433: 'left',\n",
              " 434: 'makes',\n",
              " 435: 'yourself',\n",
              " 436: 'rock',\n",
              " 437: 'spinning',\n",
              " 438: 'kiss',\n",
              " 439: 'die',\n",
              " 440: 'oo',\n",
              " 441: 'hearts',\n",
              " 442: 'club',\n",
              " 443: 'met',\n",
              " 444: 'peace',\n",
              " 445: 'sees',\n",
              " 446: \"wouldn't\",\n",
              " 447: 'speaking',\n",
              " 448: 'whisper',\n",
              " 449: 'chance',\n",
              " 450: 'tomorrow',\n",
              " 451: 'music',\n",
              " 452: 'universe',\n",
              " 453: 'opened',\n",
              " 454: 'start',\n",
              " 455: 'upon',\n",
              " 456: 'places',\n",
              " 457: 'lovers',\n",
              " 458: 'affection',\n",
              " 459: 'often',\n",
              " 460: 'arise',\n",
              " 461: 'black',\n",
              " 462: 'doo',\n",
              " 463: 'golden',\n",
              " 464: 'tonight',\n",
              " 465: 'end',\n",
              " 466: 'save',\n",
              " 467: 'known',\n",
              " 468: 'hung',\n",
              " 469: 'tree',\n",
              " 470: 'low',\n",
              " 471: 'chorus',\n",
              " 472: 'goes',\n",
              " 473: 'ring',\n",
              " 474: 'couple',\n",
              " 475: 'after',\n",
              " 476: 'older',\n",
              " 477: 'wine',\n",
              " 478: 'point',\n",
              " 479: 'view',\n",
              " 480: 'indicate',\n",
              " 481: 'first',\n",
              " 482: 'younger',\n",
              " 483: 'ground',\n",
              " 484: 'green',\n",
              " 485: 'ahead',\n",
              " 486: 'apart',\n",
              " 487: 'stand',\n",
              " 488: 'run',\n",
              " 489: 'eggman',\n",
              " 490: 'eggmen',\n",
              " 491: 'ho',\n",
              " 492: 'sleeping',\n",
              " 493: 'read',\n",
              " 494: 'news',\n",
              " 495: 'ma',\n",
              " 496: 'belle',\n",
              " 497: 'everyone',\n",
              " 498: 'write',\n",
              " 499: 'roll',\n",
              " 500: 'off',\n",
              " 501: 'looked',\n",
              " 502: 'working',\n",
              " 503: 'hands',\n",
              " 504: 'held',\n",
              " 505: \"day's\",\n",
              " 506: 'lot',\n",
              " 507: 'tells',\n",
              " 508: 'wants',\n",
              " 509: 'knowing',\n",
              " 510: 'someday',\n",
              " 511: 'listen',\n",
              " 512: 'shade',\n",
              " 513: 'anymore',\n",
              " 514: 'nearly',\n",
              " 515: 'broke',\n",
              " 516: 'ha',\n",
              " 517: 'plans',\n",
              " 518: 'maxwell',\n",
              " 519: 'tax',\n",
              " 520: 'suddenly',\n",
              " 521: 'game',\n",
              " 522: 'myself',\n",
              " 523: 'shine',\n",
              " 524: 'om',\n",
              " 525: 'inside',\n",
              " 526: 'ringing',\n",
              " 527: 'calls',\n",
              " 528: 'begin',\n",
              " 529: 'pain',\n",
              " 530: 'plays',\n",
              " 531: 'feels',\n",
              " 532: 'slowly',\n",
              " 533: 'slumbers',\n",
              " 534: 'rise',\n",
              " 535: 'equal',\n",
              " 536: 'everybody',\n",
              " 537: 'getting',\n",
              " 538: 'da',\n",
              " 539: 'gives',\n",
              " 540: 'built',\n",
              " 541: 'running',\n",
              " 542: 'lend',\n",
              " 543: 'evening',\n",
              " 544: 'sending',\n",
              " 545: 'lights',\n",
              " 546: 'sunday',\n",
              " 547: 'summer',\n",
              " 548: 'rent',\n",
              " 549: 'drop',\n",
              " 550: 'touch',\n",
              " 551: 'guess',\n",
              " 552: 'appreciate',\n",
              " 553: 'being',\n",
              " 554: 'lover',\n",
              " 555: 'shows',\n",
              " 556: 'grow',\n",
              " 557: 'below',\n",
              " 558: 'wonderful',\n",
              " 559: \"we'd\",\n",
              " 560: 'pictures',\n",
              " 561: 'lived',\n",
              " 562: 'land',\n",
              " 563: 'full',\n",
              " 564: 'speed',\n",
              " 565: 'mr',\n",
              " 566: 'sir',\n",
              " 567: 'name',\n",
              " 568: 'loud',\n",
              " 569: 'walk',\n",
              " 570: 'row',\n",
              " 571: 'english',\n",
              " 572: 'hee',\n",
              " 573: 'hah',\n",
              " 574: 'father',\n",
              " 575: 'notice',\n",
              " 576: 'house',\n",
              " 577: 'holes',\n",
              " 578: 'small',\n",
              " 579: 'sont',\n",
              " 580: 'les',\n",
              " 581: 'mots',\n",
              " 582: 'qui',\n",
              " 583: 'vont',\n",
              " 584: 'hoping',\n",
              " 585: 'barber',\n",
              " 586: 'banker',\n",
              " 587: 'suburban',\n",
              " 588: 'meanwhile',\n",
              " 589: 'keep',\n",
              " 590: 'jojo',\n",
              " 591: 'cha',\n",
              " 592: 'boat',\n",
              " 593: 'junior',\n",
              " 594: 'behave',\n",
              " 595: 'lost',\n",
              " 596: \"you'd\",\n",
              " 597: 'ooh',\n",
              " 598: 'morning',\n",
              " 599: 'honey',\n",
              " 600: 'fine',\n",
              " 601: 'woo',\n",
              " 602: 'hurt',\n",
              " 603: 'belong',\n",
              " 604: 'writing',\n",
              " 605: 'died',\n",
              " 606: 'fall',\n",
              " 607: 'missing',\n",
              " 608: 'dog',\n",
              " 609: 'earth',\n",
              " 610: 'ok',\n",
              " 611: 'holding',\n",
              " 612: 'diamond',\n",
              " 613: 'anything',\n",
              " 614: 'ago',\n",
              " 615: \"we've\",\n",
              " 616: 'wonder',\n",
              " 617: 'winding',\n",
              " 618: 'cried',\n",
              " 619: 'tried',\n",
              " 620: 'young',\n",
              " 621: 'ten',\n",
              " 622: 'e',\n",
              " 623: 'measured',\n",
              " 624: 'quiet',\n",
              " 625: 'knock',\n",
              " 626: 'pay',\n",
              " 627: 'monday',\n",
              " 628: 'soon',\n",
              " 629: 'king',\n",
              " 630: 'pam',\n",
              " 631: 'dirty',\n",
              " 632: 'polythene',\n",
              " 633: \"majesty's\",\n",
              " 634: 'nice',\n",
              " 635: 'realized',\n",
              " 636: 'raccoon',\n",
              " 637: 'even',\n",
              " 638: 'looks',\n",
              " 639: 'mother',\n",
              " 640: 'mary',\n",
              " 641: 'agree',\n",
              " 642: 'shines',\n",
              " 643: 'sound',\n",
              " 644: 'cup',\n",
              " 645: 'joy',\n",
              " 646: 'which',\n",
              " 647: 'million',\n",
              " 648: 'call',\n",
              " 649: 'sounds',\n",
              " 650: 'skin',\n",
              " 651: 'cool',\n",
              " 652: 'remain',\n",
              " 653: 'moments',\n",
              " 654: 'recall',\n",
              " 655: 'compares',\n",
              " 656: 'memories',\n",
              " 657: 'meaning',\n",
              " 658: 'wings',\n",
              " 659: 'cold',\n",
              " 660: 'awake',\n",
              " 661: 'pillow',\n",
              " 662: 'invitations',\n",
              " 663: 'celebrations',\n",
              " 664: 'saved',\n",
              " 665: 'works',\n",
              " 666: 'matter',\n",
              " 667: 'tune',\n",
              " 668: 'singer',\n",
              " 669: 'bra',\n",
              " 670: 'twenty',\n",
              " 671: 'begins',\n",
              " 672: 'kids',\n",
              " 673: 'yard',\n",
              " 674: 'jones',\n",
              " 675: 'market',\n",
              " 676: 'lets',\n",
              " 677: 'stays',\n",
              " 678: 'losing',\n",
              " 679: 'valentine',\n",
              " 680: 'greetings',\n",
              " 681: 'bottle',\n",
              " 682: 'quarter',\n",
              " 683: 'lock',\n",
              " 684: 'word',\n",
              " 685: 'handy',\n",
              " 686: 'mending',\n",
              " 687: 'fuse',\n",
              " 688: 'knit',\n",
              " 689: 'sweater',\n",
              " 690: 'fireside',\n",
              " 691: 'ride',\n",
              " 692: 'digging',\n",
              " 693: 'weeds',\n",
              " 694: 'cottage',\n",
              " 695: 'isle',\n",
              " 696: 'wight',\n",
              " 697: 'shall',\n",
              " 698: 'scrimp',\n",
              " 699: 'grandchildren',\n",
              " 700: 'vera',\n",
              " 701: 'chuck',\n",
              " 702: 'dave',\n",
              " 703: 'postcard',\n",
              " 704: 'line',\n",
              " 705: 'stating',\n",
              " 706: 'precisely',\n",
              " 707: 'sincerely',\n",
              " 708: 'wasting',\n",
              " 709: 'form',\n",
              " 710: \"feelin'\",\n",
              " 711: 'past',\n",
              " 712: 'needed',\n",
              " 713: \"anybody's\",\n",
              " 714: 'self',\n",
              " 715: 'assured',\n",
              " 716: 'doors',\n",
              " 717: 'ways',\n",
              " 718: 'somewhere',\n",
              " 719: 'style',\n",
              " 720: 'flat',\n",
              " 721: 'joo',\n",
              " 722: 'roller',\n",
              " 723: 'joker',\n",
              " 724: 'finger',\n",
              " 725: 'shoot',\n",
              " 726: 'early',\n",
              " 727: 'birds',\n",
              " 728: 'roses',\n",
              " 729: 'fragrant',\n",
              " 730: 'meadows',\n",
              " 731: 'dawn',\n",
              " 732: 'dew',\n",
              " 733: 'count',\n",
              " 734: 'brother',\n",
              " 735: 'wait',\n",
              " 736: 'town',\n",
              " 737: 'sailed',\n",
              " 738: 'next',\n",
              " 739: 'cut',\n",
              " 740: 'cable',\n",
              " 741: 'aye',\n",
              " 742: 'captain',\n",
              " 743: 'whenever',\n",
              " 744: 'air',\n",
              " 745: 'endear',\n",
              " 746: 'worry',\n",
              " 747: 'own',\n",
              " 748: 'sight',\n",
              " 749: 'pigs',\n",
              " 750: 'gun',\n",
              " 751: 'stupid',\n",
              " 752: 'naughty',\n",
              " 753: 'eye',\n",
              " 754: 'set',\n",
              " 755: 'turning',\n",
              " 756: 'rather',\n",
              " 757: 'car',\n",
              " 758: 'crowd',\n",
              " 759: 'book',\n",
              " 760: 'noticed',\n",
              " 761: 'late',\n",
              " 762: 'thousand',\n",
              " 763: 'pleasure',\n",
              " 764: 'corner',\n",
              " 765: 'pouring',\n",
              " 766: 'strange',\n",
              " 767: 'fireman',\n",
              " 768: 'queen',\n",
              " 769: 'fire',\n",
              " 770: 'clean',\n",
              " 771: 'pies',\n",
              " 772: 'shaves',\n",
              " 773: 'loretta',\n",
              " 774: 'woman',\n",
              " 775: 'coming',\n",
              " 776: 'gets',\n",
              " 777: 'turns',\n",
              " 778: 'picture',\n",
              " 779: 'quite',\n",
              " 780: 'kaleidoscope',\n",
              " 781: 'flowers',\n",
              " 782: 'rocking',\n",
              " 783: 'eat',\n",
              " 784: 'appear',\n",
              " 785: 'clouds',\n",
              " 786: 'school',\n",
              " 787: 'chair',\n",
              " 788: 'puts',\n",
              " 789: 'teacher',\n",
              " 790: 'ready',\n",
              " 791: \"junior's\",\n",
              " 792: 'shop',\n",
              " 793: 'bath',\n",
              " 794: 'brings',\n",
              " 795: 'bright',\n",
              " 796: 'stars',\n",
              " 797: 'bye',\n",
              " 798: 'wow',\n",
              " 799: 'norwegian',\n",
              " 800: 'wood',\n",
              " 801: 'worked',\n",
              " 802: 'closer',\n",
              " 803: 'yi',\n",
              " 804: 'yay',\n",
              " 805: 'thinking',\n",
              " 806: 'pride',\n",
              " 807: 'eleanor',\n",
              " 808: 'rigby',\n",
              " 809: 'church',\n",
              " 810: 'waits',\n",
              " 811: 'window',\n",
              " 812: 'wearing',\n",
              " 813: 'mckenzie',\n",
              " 814: 'along',\n",
              " 815: 'boom',\n",
              " 816: 'crossed',\n",
              " 817: 'danced',\n",
              " 818: 'close',\n",
              " 819: 'miss',\n",
              " 820: 'lips',\n",
              " 821: 'log',\n",
              " 822: 'moan',\n",
              " 823: 'owww',\n",
              " 824: 'special',\n",
              " 825: 'sunny',\n",
              " 826: 'lie',\n",
              " 827: 'satisfied',\n",
              " 828: 'introduce',\n",
              " 829: 'might',\n",
              " 830: 'beside',\n",
              " 831: 'share',\n",
              " 832: 'believing',\n",
              " 833: 'dies',\n",
              " 834: 'watching',\n",
              " 835: 'forget',\n",
              " 836: \"di'n'di\",\n",
              " 837: 'bup',\n",
              " 838: 'dreamer',\n",
              " 839: 'join',\n",
              " 840: 'leads',\n",
              " 841: 'enough',\n",
              " 842: 'did',\n",
              " 843: 'warm',\n",
              " 844: 'lies',\n",
              " 845: 'safe',\n",
              " 846: 'c',\n",
              " 847: 'sail',\n",
              " 848: 'ship',\n",
              " 849: 'chop',\n",
              " 850: 'skip',\n",
              " 851: 'rope',\n",
              " 852: 'celebrate',\n",
              " 853: 'penetrate',\n",
              " 854: 'pick',\n",
              " 855: 'radiate',\n",
              " 856: 'imitate',\n",
              " 857: 'lorry',\n",
              " 858: 'syndicate',\n",
              " 859: \"haven't\",\n",
              " 860: 'putting',\n",
              " 861: 'joke',\n",
              " 862: 'brain',\n",
              " 863: 'weeks',\n",
              " 864: 'insane',\n",
              " 865: 'park',\n",
              " 866: 'roof',\n",
              " 867: 'bag',\n",
              " 868: 'ukraine',\n",
              " 869: 'west',\n",
              " 870: 'moscow',\n",
              " 871: \"georgia's\",\n",
              " 872: 'hu',\n",
              " 873: 'mountain',\n",
              " 874: 'grin',\n",
              " 875: 'perfectly',\n",
              " 876: 'talking',\n",
              " 877: 'magic',\n",
              " 878: 'na',\n",
              " 879: \"everybody's\",\n",
              " 880: 'mi',\n",
              " 881: 'amore',\n",
              " 882: 'sleeps',\n",
              " 883: 'dressed',\n",
              " 884: \"sunday's\",\n",
              " 885: \"tuesday's\",\n",
              " 886: 'wall',\n",
              " 887: 'greet',\n",
              " 888: 'brand',\n",
              " 889: 'beautiful',\n",
              " 890: 'open',\n",
              " 891: 'happen',\n",
              " 892: 'bit',\n",
              " 893: 'command',\n",
              " 894: 'himself',\n",
              " 895: 'checked',\n",
              " 896: \"gideon's\",\n",
              " 897: 'bible',\n",
              " 898: 'rival',\n",
              " 899: 'called',\n",
              " 900: 'doc',\n",
              " 901: 'saying',\n",
              " 902: 'short',\n",
              " 903: 'fussing',\n",
              " 904: 'fighting',\n",
              " 905: 'crime',\n",
              " 906: 'oa',\n",
              " 907: 'troubles',\n",
              " 908: 'seemed',\n",
              " 909: 'far',\n",
              " 910: 'half',\n",
              " 911: 'used',\n",
              " 912: 'shadow',\n",
              " 913: 'hanging',\n",
              " 914: 'trouble',\n",
              " 915: 'hour',\n",
              " 916: 'darkness',\n",
              " 917: 'front',\n",
              " 918: 'hearted',\n",
              " 919: 'parted',\n",
              " 920: 'cloudy',\n",
              " 921: 'wake',\n",
              " 922: 'flowing',\n",
              " 923: 'endless',\n",
              " 924: 'slither',\n",
              " 925: 'wildly',\n",
              " 926: 'slip',\n",
              " 927: 'pools',\n",
              " 928: 'sorrow',\n",
              " 929: 'drifting',\n",
              " 930: 'possessing',\n",
              " 931: 'caressing',\n",
              " 932: 'images',\n",
              " 933: 'thoughts',\n",
              " 934: 'meander',\n",
              " 935: 'restless',\n",
              " 936: 'letter',\n",
              " 937: 'box',\n",
              " 938: 'tumble',\n",
              " 939: 'blindly',\n",
              " 940: 'laughter',\n",
              " 941: 'shades',\n",
              " 942: 'inciting',\n",
              " 943: 'inviting',\n",
              " 944: 'limitless',\n",
              " 945: 'undying',\n",
              " 946: 'suns',\n",
              " 947: 'afraid',\n",
              " 948: 'minute',\n",
              " 949: 'anytime',\n",
              " 950: 'refrain',\n",
              " 951: 'shoulders',\n",
              " 952: 'colder',\n",
              " 953: 'perform',\n",
              " 954: 'movement',\n",
              " 955: 'shoulder',\n",
              " 956: 'sunken',\n",
              " 957: 'winter',\n",
              " 958: 'returning',\n",
              " 959: 'faces',\n",
              " 960: 'ice',\n",
              " 961: 'melting',\n",
              " 962: 'clear',\n",
              " 963: 'sung',\n",
              " 964: 'shown',\n",
              " 965: 'meant',\n",
              " 966: \"mem'ries\",\n",
              " 967: 'closed',\n",
              " 968: 'misunderstanding',\n",
              " 969: 'sometimes',\n",
              " 970: 'disagree',\n",
              " 971: 'barrow',\n",
              " 972: 'marketplace',\n",
              " 973: 'trolley',\n",
              " 974: \"jeweler's\",\n",
              " 975: 'store',\n",
              " 976: 'buys',\n",
              " 977: 'carat',\n",
              " 978: 'sings',\n",
              " 979: 'fun',\n",
              " 980: 'bla',\n",
              " 981: \"'til\",\n",
              " 982: 'mornings',\n",
              " 983: 'yours',\n",
              " 984: 'lasts',\n",
              " 985: 'independence',\n",
              " 986: 'vanish',\n",
              " 987: 'haze',\n",
              " 988: 'insecure',\n",
              " 989: 'moves',\n",
              " 990: 'attracts',\n",
              " 991: 'woos',\n",
              " 992: 'asking',\n",
              " 993: 'stick',\n",
              " 994: 'top',\n",
              " 995: \"groovin'\",\n",
              " 996: 'eyeballs',\n",
              " 997: 'holy',\n",
              " 998: 'wear',\n",
              " 999: 'shoeshine',\n",
              " 1000: 'toe',\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cantidad de palabras en el vocabulario\n",
        "vocab_size = len(tok.word_counts)\n",
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtzINYjWCMf1",
        "outputId": "e7e1c13e-7c4f-4a20-ba28-39cb2af3aec1"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1628"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "spTBxmFQc6h8",
        "outputId": "2dbc682e-15cc-435d-9016-fce2c4d78eda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'you': 1, 'i': 2, 'the': 3, 'to': 4, 'and': 5, 'love': 6, 'a': 7, 'me': 8, 'in': 9, 'all': 10, 'nah': 11, 'my': 12, 'it': 13, 'know': 14, 'be': 15, 'that': 16, 'of': 17, 'on': 18, 'she': 19, 'is': 20, 'say': 21, 'now': 22, 'oh': 23, 'yeah': 24, 'your': 25, 'get': 26, \"don't\": 27, 'back': 28, 'let': 29, 'with': 30, 'her': 31, 'can': 32, \"it's\": 33, 'do': 34, \"i'm\": 35, 'when': 36, 'come': 37, 'will': 38, 'he': 39, 'but': 40, 'for': 41, 'so': 42, 'need': 43, 'there': 44, 'like': 45, 'no': 46, 'together': 47, \"i'll\": 48, 'see': 49, 'was': 50, 'never': 51, 'we': 52, 'down': 53, 'way': 54, 'if': 55, 'want': 56, 'out': 57, 'hey': 58, 'one': 59, 'got': 60, 'go': 61, 'well': 62, \"can't\": 63, 'girl': 64, 'good': 65, 'his': 66, 'sun': 67, 'they': 68, 'home': 69, 'hello': 70, 'day': 71, 'are': 72, 'ah': 73, 'right': 74, 'little': 75, 'at': 76, 'from': 77, 'man': 78, 'here': 79, 'help': 80, 'gonna': 81, 'have': 82, 'not': 83, 'world': 84, 'going': 85, 'what': 86, 'still': 87, 'how': 88, 'too': 89, 'please': 90, 'as': 91, \"you're\": 92, 'just': 93, 'time': 94, 'make': 95, 'long': 96, 'yes': 97, 'yellow': 98, 'life': 99, 'why': 100, 'think': 101, 'only': 102, 'been': 103, 'once': 104, 'tell': 105, 'sky': 106, 'people': 107, 'eyes': 108, 'where': 109, \"she's\": 110, 'up': 111, 'jude': 112, 'take': 113, 'submarine': 114, 'sing': 115, 'give': 116, 'nowhere': 117, 'hold': 118, 'look': 119, 'goodbye': 120, 'away': 121, 'friends': 122, 'darling': 123, 'lonely': 124, 'boy': 125, 'nothing': 126, 'always': 127, 'hand': 128, \"we're\": 129, 'am': 130, 'goo': 131, 'should': 132, 'comes': 133, 'night': 134, 'feel': 135, 'some': 136, 'could': 137, 'had': 138, 'better': 139, 'them': 140, 'would': 141, 'head': 142, \"i've\": 143, 'more': 144, 'four': 145, 'buy': 146, 'mind': 147, 'carry': 148, 'this': 149, 'la': 150, 'everything': 151, 'two': 152, 'change': 153, 'by': 154, 'weight': 155, 'us': 156, 'our': 157, 'lucy': 158, 'sunshine': 159, 'believe': 160, 'an': 161, 'words': 162, 'before': 163, \"you'll\": 164, 'these': 165, 'pretty': 166, 'birthday': 167, \"i'd\": 168, 'three': 169, 'every': 170, 'diamonds': 171, 'true': 172, \"there's\": 173, 'said': 174, 'mm': 175, 'were': 176, 'forever': 177, 'dear': 178, 'mine': 179, 'nobody': 180, 'round': 181, 'leave': 182, 'money': 183, 'told': 184, 'work': 185, 'bom': 186, 'something': 187, 'hide': 188, 'standing': 189, 'then': 190, 'who': 191, 'waiting': 192, 'about': 193, \"'cause\": 194, 'children': 195, 'saw': 196, \"didn't\": 197, 'try': 198, 'loves': 199, 'yesterday': 200, \"nothing's\": 201, 'gone': 202, 'things': 203, 'stop': 204, 'sleep': 205, 'cry': 206, 'hard': 207, 'di': 208, \"he's\": 209, 'days': 210, 'alone': 211, 'because': 212, 'falling': 213, 'again': 214, 'prudence': 215, 'bang': 216, 'though': 217, 'came': 218, 'around': 219, 'mean': 220, 'has': 221, 'till': 222, 'juba': 223, 'shake': 224, 'loving': 225, 'eight': 226, 'five': 227, 'play': 228, 'place': 229, 'find': 230, 'may': 231, 'someone': 232, 'dead': 233, 'years': 234, 'send': 235, 'strawberry': 236, 'fields': 237, 'or': 238, 'band': 239, 'door': 240, 'happy': 241, 'garden': 242, 'anybody': 243, 'today': 244, \"won't\": 245, 'live': 246, 'blue': 247, 'while': 248, 'hela': 249, 'heaven': 250, 'week': 251, 'six': 252, 'seven': 253, 'rocky': 254, 'such': 255, 'easy': 256, 'answer': 257, 'into': 258, 'dance': 259, 'heart': 260, 'lullaby': 261, 'high': 262, 'face': 263, 'him': 264, 'does': 265, 'ask': 266, 'somebody': 267, 'any': 268, 'feeling': 269, 'knows': 270, 'talk': 271, \"you've\": 272, 'another': 273, 'belonged': 274, 'glad': 275, 'heba': 276, 'helloa': 277, 'baby': 278, 'twist': 279, 'kind': 280, 'care': 281, 'jai': 282, 'guru': 283, 'deva': 284, 'bad': 285, 'fool': 286, 'found': 287, 'loved': 288, 'fly': 289, 'seems': 290, 'fill': 291, 'done': 292, \"isn't\": 293, 'real': 294, 'much': 295, 'molly': 296, 'ever': 297, 'many': 298, 'understand': 299, 'sea': 300, 'beneath': 301, \"g'\": 302, 'joob': 303, 'penny': 304, 'lane': 305, 'keeps': 306, 'whoa': 307, 'sgt': 308, 'bompa': 309, 'ussr': 310, 'silver': 311, 'hoo': 312, 'taxman': 313, 'stay': 314, 'wisdom': 315, 'rain': 316, 'their': 317, 'remember': 318, 'made': 319, 'new': 320, 'went': 321, 'blackbird': 322, 'must': 323, 'desmond': 324, 'sweet': 325, 'last': 326, 'really': 327, 'smile': 328, 'show': 329, 'hear': 330, 'hmm': 331, 'crying': 332, 'sitting': 333, 'tired': 334, \"that's\": 335, 'behind': 336, 'room': 337, 'hope': 338, 'alright': 339, \"pepper's\": 340, 'lead': 341, 'everywhere': 342, 'road': 343, 'babe': 344, \"octopus'\": 345, 'bulldog': 346, 'woah': 347, 'hammer': 348, \"they're\": 349, 'wrong': 350, 'living': 351, 'through': 352, 'ears': 353, 'song': 354, 'under': 355, 'making': 356, 'changed': 357, 'lose': 358, 'singing': 359, 'learn': 360, 'dark': 361, 'homeward': 362, 'dream': 363, 'hair': 364, 'feed': 365, 'sixty': 366, 'doing': 367, \"somethin'\": 368, 'feet': 369, 'other': 370, 'old': 371, 'looking': 372, 'hill': 373, 'heard': 374, 'guitar': 375, 'gently': 376, 'weeps': 377, 'laugh': 378, 'fell': 379, 'michelle': 380, 'tres': 381, 'bien': 382, 'ensemble': 383, 'thought': 384, 'girls': 385, 'party': 386, 'shout': 387, 'each': 388, 'tight': 389, 'friend': 390, 'calling': 391, 'imagine': 392, 'harm': 393, 'phone': 394, \"maxwell's\": 395, 'o': 396, 'over': 397, 'times': 398, 'broken': 399, 'light': 400, 'until': 401, 'paper': 402, 'across': 403, 'waves': 404, 'wind': 405, 'sad': 406, 'moment': 407, 'free': 408, 'since': 409, 'smiles': 410, 'middle': 411, 'break': 412, 'dreams': 413, \"doesn't\": 414, 'says': 415, 'takes': 416, 'ob': 417, 'knee': 418, 'than': 419, 'thing': 420, 'walrus': 421, \"ain't\": 422, 'near': 423, 'turn': 424, 'seen': 425, 'lucky': 426, 'sure': 427, 'bed': 428, 'very': 429, 'skies': 430, 'sit': 431, 'knew': 432, 'left': 433, 'makes': 434, 'yourself': 435, 'rock': 436, 'spinning': 437, 'kiss': 438, 'die': 439, 'oo': 440, 'hearts': 441, 'club': 442, 'met': 443, 'peace': 444, 'sees': 445, \"wouldn't\": 446, 'speaking': 447, 'whisper': 448, 'chance': 449, 'tomorrow': 450, 'music': 451, 'universe': 452, 'opened': 453, 'start': 454, 'upon': 455, 'places': 456, 'lovers': 457, 'affection': 458, 'often': 459, 'arise': 460, 'black': 461, 'doo': 462, 'golden': 463, 'tonight': 464, 'end': 465, 'save': 466, 'known': 467, 'hung': 468, 'tree': 469, 'low': 470, 'chorus': 471, 'goes': 472, 'ring': 473, 'couple': 474, 'after': 475, 'older': 476, 'wine': 477, 'point': 478, 'view': 479, 'indicate': 480, 'first': 481, 'younger': 482, 'ground': 483, 'green': 484, 'ahead': 485, 'apart': 486, 'stand': 487, 'run': 488, 'eggman': 489, 'eggmen': 490, 'ho': 491, 'sleeping': 492, 'read': 493, 'news': 494, 'ma': 495, 'belle': 496, 'everyone': 497, 'write': 498, 'roll': 499, 'off': 500, 'looked': 501, 'working': 502, 'hands': 503, 'held': 504, \"day's\": 505, 'lot': 506, 'tells': 507, 'wants': 508, 'knowing': 509, 'someday': 510, 'listen': 511, 'shade': 512, 'anymore': 513, 'nearly': 514, 'broke': 515, 'ha': 516, 'plans': 517, 'maxwell': 518, 'tax': 519, 'suddenly': 520, 'game': 521, 'myself': 522, 'shine': 523, 'om': 524, 'inside': 525, 'ringing': 526, 'calls': 527, 'begin': 528, 'pain': 529, 'plays': 530, 'feels': 531, 'slowly': 532, 'slumbers': 533, 'rise': 534, 'equal': 535, 'everybody': 536, 'getting': 537, 'da': 538, 'gives': 539, 'built': 540, 'running': 541, 'lend': 542, 'evening': 543, 'sending': 544, 'lights': 545, 'sunday': 546, 'summer': 547, 'rent': 548, 'drop': 549, 'touch': 550, 'guess': 551, 'appreciate': 552, 'being': 553, 'lover': 554, 'shows': 555, 'grow': 556, 'below': 557, 'wonderful': 558, \"we'd\": 559, 'pictures': 560, 'lived': 561, 'land': 562, 'full': 563, 'speed': 564, 'mr': 565, 'sir': 566, 'name': 567, 'loud': 568, 'walk': 569, 'row': 570, 'english': 571, 'hee': 572, 'hah': 573, 'father': 574, 'notice': 575, 'house': 576, 'holes': 577, 'small': 578, 'sont': 579, 'les': 580, 'mots': 581, 'qui': 582, 'vont': 583, 'hoping': 584, 'barber': 585, 'banker': 586, 'suburban': 587, 'meanwhile': 588, 'keep': 589, 'jojo': 590, 'cha': 591, 'boat': 592, 'junior': 593, 'behave': 594, 'lost': 595, \"you'd\": 596, 'ooh': 597, 'morning': 598, 'honey': 599, 'fine': 600, 'woo': 601, 'hurt': 602, 'belong': 603, 'writing': 604, 'died': 605, 'fall': 606, 'missing': 607, 'dog': 608, 'earth': 609, 'ok': 610, 'holding': 611, 'diamond': 612, 'anything': 613, 'ago': 614, \"we've\": 615, 'wonder': 616, 'winding': 617, 'cried': 618, 'tried': 619, 'young': 620, 'ten': 621, 'e': 622, 'measured': 623, 'quiet': 624, 'knock': 625, 'pay': 626, 'monday': 627, 'soon': 628, 'king': 629, 'pam': 630, 'dirty': 631, 'polythene': 632, \"majesty's\": 633, 'nice': 634, 'realized': 635, 'raccoon': 636, 'even': 637, 'looks': 638, 'mother': 639, 'mary': 640, 'agree': 641, 'shines': 642, 'sound': 643, 'cup': 644, 'joy': 645, 'which': 646, 'million': 647, 'call': 648, 'sounds': 649, 'skin': 650, 'cool': 651, 'remain': 652, 'moments': 653, 'recall': 654, 'compares': 655, 'memories': 656, 'meaning': 657, 'wings': 658, 'cold': 659, 'awake': 660, 'pillow': 661, 'invitations': 662, 'celebrations': 663, 'saved': 664, 'works': 665, 'matter': 666, 'tune': 667, 'singer': 668, 'bra': 669, 'twenty': 670, 'begins': 671, 'kids': 672, 'yard': 673, 'jones': 674, 'market': 675, 'lets': 676, 'stays': 677, 'losing': 678, 'valentine': 679, 'greetings': 680, 'bottle': 681, 'quarter': 682, 'lock': 683, 'word': 684, 'handy': 685, 'mending': 686, 'fuse': 687, 'knit': 688, 'sweater': 689, 'fireside': 690, 'ride': 691, 'digging': 692, 'weeds': 693, 'cottage': 694, 'isle': 695, 'wight': 696, 'shall': 697, 'scrimp': 698, 'grandchildren': 699, 'vera': 700, 'chuck': 701, 'dave': 702, 'postcard': 703, 'line': 704, 'stating': 705, 'precisely': 706, 'sincerely': 707, 'wasting': 708, 'form': 709, \"feelin'\": 710, 'past': 711, 'needed': 712, \"anybody's\": 713, 'self': 714, 'assured': 715, 'doors': 716, 'ways': 717, 'somewhere': 718, 'style': 719, 'flat': 720, 'joo': 721, 'roller': 722, 'joker': 723, 'finger': 724, 'shoot': 725, 'early': 726, 'birds': 727, 'roses': 728, 'fragrant': 729, 'meadows': 730, 'dawn': 731, 'dew': 732, 'count': 733, 'brother': 734, 'wait': 735, 'town': 736, 'sailed': 737, 'next': 738, 'cut': 739, 'cable': 740, 'aye': 741, 'captain': 742, 'whenever': 743, 'air': 744, 'endear': 745, 'worry': 746, 'own': 747, 'sight': 748, 'pigs': 749, 'gun': 750, 'stupid': 751, 'naughty': 752, 'eye': 753, 'set': 754, 'turning': 755, 'rather': 756, 'car': 757, 'crowd': 758, 'book': 759, 'noticed': 760, 'late': 761, 'thousand': 762, 'pleasure': 763, 'corner': 764, 'pouring': 765, 'strange': 766, 'fireman': 767, 'queen': 768, 'fire': 769, 'clean': 770, 'pies': 771, 'shaves': 772, 'loretta': 773, 'woman': 774, 'coming': 775, 'gets': 776, 'turns': 777, 'picture': 778, 'quite': 779, 'kaleidoscope': 780, 'flowers': 781, 'rocking': 782, 'eat': 783, 'appear': 784, 'clouds': 785, 'school': 786, 'chair': 787, 'puts': 788, 'teacher': 789, 'ready': 790, \"junior's\": 791, 'shop': 792, 'bath': 793, 'brings': 794, 'bright': 795, 'stars': 796, 'bye': 797, 'wow': 798, 'norwegian': 799, 'wood': 800, 'worked': 801, 'closer': 802, 'yi': 803, 'yay': 804, 'thinking': 805, 'pride': 806, 'eleanor': 807, 'rigby': 808, 'church': 809, 'waits': 810, 'window': 811, 'wearing': 812, 'mckenzie': 813, 'along': 814, 'boom': 815, 'crossed': 816, 'danced': 817, 'close': 818, 'miss': 819, 'lips': 820, 'log': 821, 'moan': 822, 'owww': 823, 'special': 824, 'sunny': 825, 'lie': 826, 'satisfied': 827, 'introduce': 828, 'might': 829, 'beside': 830, 'share': 831, 'believing': 832, 'dies': 833, 'watching': 834, 'forget': 835, \"di'n'di\": 836, 'bup': 837, 'dreamer': 838, 'join': 839, 'leads': 840, 'enough': 841, 'did': 842, 'warm': 843, 'lies': 844, 'safe': 845, 'c': 846, 'sail': 847, 'ship': 848, 'chop': 849, 'skip': 850, 'rope': 851, 'celebrate': 852, 'penetrate': 853, 'pick': 854, 'radiate': 855, 'imitate': 856, 'lorry': 857, 'syndicate': 858, \"haven't\": 859, 'putting': 860, 'joke': 861, 'brain': 862, 'weeks': 863, 'insane': 864, 'park': 865, 'roof': 866, 'bag': 867, 'ukraine': 868, 'west': 869, 'moscow': 870, \"georgia's\": 871, 'hu': 872, 'mountain': 873, 'grin': 874, 'perfectly': 875, 'talking': 876, 'magic': 877, 'na': 878, \"everybody's\": 879, 'mi': 880, 'amore': 881, 'sleeps': 882, 'dressed': 883, \"sunday's\": 884, \"tuesday's\": 885, 'wall': 886, 'greet': 887, 'brand': 888, 'beautiful': 889, 'open': 890, 'happen': 891, 'bit': 892, 'command': 893, 'himself': 894, 'checked': 895, \"gideon's\": 896, 'bible': 897, 'rival': 898, 'called': 899, 'doc': 900, 'saying': 901, 'short': 902, 'fussing': 903, 'fighting': 904, 'crime': 905, 'oa': 906, 'troubles': 907, 'seemed': 908, 'far': 909, 'half': 910, 'used': 911, 'shadow': 912, 'hanging': 913, 'trouble': 914, 'hour': 915, 'darkness': 916, 'front': 917, 'hearted': 918, 'parted': 919, 'cloudy': 920, 'wake': 921, 'flowing': 922, 'endless': 923, 'slither': 924, 'wildly': 925, 'slip': 926, 'pools': 927, 'sorrow': 928, 'drifting': 929, 'possessing': 930, 'caressing': 931, 'images': 932, 'thoughts': 933, 'meander': 934, 'restless': 935, 'letter': 936, 'box': 937, 'tumble': 938, 'blindly': 939, 'laughter': 940, 'shades': 941, 'inciting': 942, 'inviting': 943, 'limitless': 944, 'undying': 945, 'suns': 946, 'afraid': 947, 'minute': 948, 'anytime': 949, 'refrain': 950, 'shoulders': 951, 'colder': 952, 'perform': 953, 'movement': 954, 'shoulder': 955, 'sunken': 956, 'winter': 957, 'returning': 958, 'faces': 959, 'ice': 960, 'melting': 961, 'clear': 962, 'sung': 963, 'shown': 964, 'meant': 965, \"mem'ries\": 966, 'closed': 967, 'misunderstanding': 968, 'sometimes': 969, 'disagree': 970, 'barrow': 971, 'marketplace': 972, 'trolley': 973, \"jeweler's\": 974, 'store': 975, 'buys': 976, 'carat': 977, 'sings': 978, 'fun': 979, 'bla': 980, \"'til\": 981, 'mornings': 982, 'yours': 983, 'lasts': 984, 'independence': 985, 'vanish': 986, 'haze': 987, 'insecure': 988, 'moves': 989, 'attracts': 990, 'woos': 991, 'asking': 992, 'stick': 993, 'top': 994, \"groovin'\": 995, 'eyeballs': 996, 'holy': 997, 'wear': 998, 'shoeshine': 999, 'toe': 1000, 'jam': 1001, 'football': 1002, 'monkey': 1003, 'coca': 1004, 'cola': 1005, 'production': 1006, 'gumboot': 1007, 'ono': 1008, 'sideboard': 1009, 'spinal': 1010, 'cracker': 1011, 'armchair': 1012, 'disease': 1013, 'coaster': 1014, 'warning': 1015, 'muddy': 1016, 'water': 1017, 'mojo': 1018, 'filter': 1019, 'bells': 1020, 'winging': 1021, 'revolution': 1022, 'evolution': 1023, 'destruction': 1024, 'solution': 1025, 'plan': 1026, 'contribution': 1027, 'minds': 1028, 'hate': 1029, 'constitution': 1030, 'institution': 1031, 'instead': 1032, 'carrying': 1033, 'chairman': 1034, 'mao': 1035, 'anyone': 1036, 'anyhow': 1037, 'born': 1038, 'submarines': 1039, 'aboard': 1040, 'boatswain': 1041, 'sergeant': 1042, 'ease': 1043, 'lifetime': 1044, 'catch': 1045, 'mattered': 1046, 'same': 1047, 'sang': 1048, 'key': 1049, 'certain': 1050, 'happens': 1051, 'cornflake': 1052, 'van': 1053, 'corporation': 1054, 't': 1055, 'shirt': 1056, 'bloody': 1057, 'tuesday': 1058, 'city': 1059, 'policeman': 1060, 'policemen': 1061, 'custard': 1062, 'dripping': 1063, \"dog's\": 1064, 'crabalocker': 1065, 'fishwife': 1066, 'pornographic': 1067, 'priestess': 1068, 'knickers': 1069, 'tan': 1070, 'maintains': 1071, 'fortune': 1072, 'expert': 1073, 'texpert': 1074, 'choking': 1075, 'smokers': 1076, 'laughs': 1077, 'sty': 1078, 'snide': 1079, 'semolina': 1080, 'pilchard': 1081, 'climbing': 1082, 'eiffel': 1083, 'tower': 1084, 'elementary': 1085, 'penguin': 1086, 'hare': 1087, 'krishna': 1088, 'kicking': 1089, 'edgar': 1090, 'allen': 1091, 'poe': 1092, 'servicible': 1093, 'villain': 1094, 'rest': 1095, 'floor': 1096, 'needs': 1097, 'sweeping': 1098, 'unfold': 1099, 'controlled': 1100, 'bought': 1101, 'sold': 1102, 'mistake': 1103, 'surely': 1104, 'learning': 1105, 'diverted': 1106, 'perverted': 1107, 'inverted': 1108, 'alerted': 1109, 'grade': 1110, 'photograph': 1111, 'blew': 1112, 'stood': 1113, 'stared': 1114, \"they'd\": 1115, 'lords': 1116, 'film': 1117, 'army': 1118, 'won': 1119, 'war': 1120, 'turned': 1121, 'having': 1122, 'woke': 1123, 'dragged': 1124, 'comb': 1125, 'downstairs': 1126, 'drank': 1127, 'coat': 1128, 'grabbed': 1129, 'hat': 1130, 'bus': 1131, 'seconds': 1132, 'upstairs': 1133, 'smoke': 1134, 'spoke': 1135, 'blackburn': 1136, 'lancashire': 1137, 'albert': 1138, 'hall': 1139, 'somehow': 1140, 'telling': 1141, 'showing': 1142, 'photographs': 1143, 'motorcar': 1144, 'wears': 1145, 'mac': 1146, 'hourglass': 1147, 'pocket': 1148, 'portrait': 1149, 'likes': 1150, 'engine': 1151, 'machine': 1152, 'fish': 1153, 'shelter': 1154, 'roundabout': 1155, 'nurse': 1156, 'selling': 1157, 'poppies': 1158, 'tray': 1159, 'anyway': 1160, 'customer': 1161, 'trim': 1162, 'rushes': 1163, 'loner': 1164, 'tucson': 1165, 'arizona': 1166, 'california': 1167, 'grass': 1168, 'jo': 1169, 'martin': 1170, 'dot': 1171, 'await': 1172, 'aaaaaahhhhhh': 1173, 'blows': 1174, 'aaaaaaaahhhh': 1175, 'aaaaaaahhhh': 1176, 'aaaaahhhhhhhhhh': 1177, 'river': 1178, 'tangerine': 1179, 'trees': 1180, 'marmalade': 1181, 'cellophane': 1182, 'towering': 1183, 'follow': 1184, 'bridge': 1185, 'fountain': 1186, 'horse': 1187, 'marshmallow': 1188, 'drift': 1189, 'incredibly': 1190, 'newspaper': 1191, 'taxis': 1192, 'shore': 1193, 'climb': 1194, 'train': 1195, 'station': 1196, 'plasticine': 1197, 'porters': 1198, 'glass': 1199, 'ties': 1200, 'turnstile': 1201, 'kid': 1202, 'moved': 1203, 'neighborhood': 1204, 'sits': 1205, 'put': 1206, 'tacks': 1207, 'teachers': 1208, 'chewing': 1209, 'gum': 1210, \"girl's\": 1211, 'magazine': 1212, 'dime': 1213, 'jukebox': 1214, 'worries': 1215, 'poop': 1216, 'rolling': 1217, 'hula': 1218, 'hoop': 1219, 'mama': 1220, 'took': 1221, 'canary': 1222, 'fed': 1223, 'neighbors': 1224, 'cat': 1225, 'gave': 1226, 'cocker': 1227, 'spaniel': 1228, \"mother's\": 1229, 'laundromat': 1230, \"mama's\": 1231, 'tenderly': 1232, 'ours': 1233, 'showed': 1234, 'asked': 1235, 'anywhere': 1236, \"wasn't\": 1237, 'sat': 1238, 'rug': 1239, 'biding': 1240, 'drinking': 1241, 'talked': 1242, 'started': 1243, 'crawled': 1244, 'awoke': 1245, 'bird': 1246, 'flown': 1247, 'lit': 1248, \"goin'\": 1249, 'almost': 1250, 'hurting': 1251, 'fair': 1252, 'apologize': 1253, 'picks': 1254, 'rice': 1255, 'wedding': 1256, 'lives': 1257, 'jar': 1258, 'sermon': 1259, 'darning': 1260, 'socks': 1261, 'buried': 1262, 'wiping': 1263, 'dirt': 1264, 'walks': 1265, 'grave': 1266, 'seventeen': 1267, 'beyond': 1268, 'compare': 1269, 'pretend': 1270, 'kissing': 1271, 'worth': 1272, 'shining': 1273, 'burns': 1274, 'shady': 1275, 'proud': 1276, 'cos': 1277, \"your's\": 1278, 'evermore': 1279, 'pepper': 1280, 'taught': 1281, \"they've\": 1282, 'guaranteed': 1283, 'raise': 1284, 'act': 1285, 'enjoy': 1286, 'certainly': 1287, 'thrill': 1288, 'lovely': 1289, 'audience': 1290, \"singer's\": 1291, 'billy': 1292, 'shears': 1293, 'year': 1294, 'changing': 1295, 'wave': 1296, 'deny': 1297, 'both': 1298, \"m'mm\": 1299, 'aware': 1300, 'missed': 1301, 'kept': 1302, 'lup': 1303, 'hell': 1304, 'above': 1305, 'countries': 1306, 'kill': 1307, 'religion': 1308, 'possessions': 1309, 'greed': 1310, 'hunger': 1311, 'brotherhood': 1312, 'sharing': 1313, 'disappear': 1314, 'wild': 1315, 'windy': 1316, 'washed': 1317, 'pool': 1318, 'tears': 1319, 'story': 1320, 'sorry': 1321, 'regret': 1322, 'single': 1323, 'promises': 1324, 'acts': 1325, 'understood': 1326, 'earn': 1327, 'leisure': 1328, \"he'd\": 1329, 'storm': 1330, 'hideaway': 1331, 'resting': 1332, 'cave': 1333, 'swim': 1334, 'coral': 1335, 'ocean': 1336, 'nine': 1337, 'b': 1338, 'd': 1339, 'bring': 1340, 'tea': 1341, 'f': 1342, 'g': 1343, 'h': 1344, 'j': 1345, 'white': 1346, 'red': 1347, 'pink': 1348, 'brown': 1349, 'orange': 1350, 'dig': 1351, 'pony': 1352, 'hog': 1353, 'moon': 1354, 'stoney': 1355, 'blow': 1356, 'load': 1357, 'beg': 1358, 'promise': 1359, 'trust': 1360, \"couldn't\": 1361, 'vain': 1362, 'learns': 1363, 'slept': 1364, 'wink': 1365, 'blink': 1366, 'fix': 1367, 'drink': 1368, 'upset': 1369, 'although': 1370, 'cigarette': 1371, 'curse': 1372, 'walter': 1373, 'raleigh': 1374, 'sheepdog': 1375, 'bullfrog': 1376, 'happiness': 1377, 'miles': 1378, 'childlike': 1379, 'understands': 1380, 'jackknife': 1381, 'sweaty': 1382, 'innocence': 1383, 'fears': 1384, 'big': 1385, 'walking': 1386, 'wigwam': 1387, 'frightened': 1388, 'solitude': 1389, 'clue': 1390, 'roar': 1391, 'woof': 1392, 'whats': 1393, 'ya': 1394, 'wo': 1395, 'flew': 1396, 'miami': 1397, 'beach': 1398, 'boac': 1399, 'dreadful': 1400, 'flight': 1401, 'gee': 1402, 'unpack': 1403, 'case': 1404, 'disconnect': 1405, 'boys': 1406, 'snow': 1407, 'peaked': 1408, 'south': 1409, \"daddy's\": 1410, 'farm': 1411, \"balalaika's\": 1412, 'comrade': 1413, 'foolish': 1414, 'keeping': 1415, 'cloud': 1416, 'voices': 1417, 'hears': 1418, 'appears': 1419, 'feelings': 1420, 'listens': 1421, 'fools': 1422, 'funny': 1423, 'negotiations': 1424, 'number': 1425, 'situation': 1426, 'investigation': 1427, 'college': 1428, 'spent': 1429, 'future': 1430, \"money's\": 1431, 'jobber': 1432, 'sack': 1433, 'slow': 1434, 'bags': 1435, 'limousine': 1436, \"we'll\": 1437, 'step': 1438, 'gas': 1439, 'wipe': 1440, 'tear': 1441, 'laughing': 1442, 'quando': 1443, 'paramucho': 1444, 'defelice': 1445, 'corazon': 1446, 'mundo': 1447, 'pararazzi': 1448, 'chicka': 1449, 'ferdy': 1450, 'parasol': 1451, 'cuesto': 1452, 'obrigado': 1453, 'tanta': 1454, 'mucho': 1455, 'cake': 1456, 'carousel': 1457, 'mustard': 1458, 'tryin': 1459, 'hole': 1460, 'saving': 1461, 'clothes': 1462, 'bob': 1463, 'note': 1464, 'nose': 1465, 'sister': 1466, 'stops': 1467, 'getter': 1468, 'shouts': 1469, 'obscene': 1470, 'drag': 1471, 'dose': 1472, 'jackboots': 1473, 'kilt': 1474, 'killer': 1475, 'diller': 1476, 'hilt': 1477, 'attractively': 1478, 'john': 1479, 'paul': 1480, 'bathroom': 1481, 'protected': 1482, 'spoon': 1483, 'sucks': 1484, 'thumb': 1485, 'wonders': 1486, 'banks': 1487, 'lagoon': 1488, \"she'd\": 1489, 'dancer': 1490, 'fifteen': 1491, 'clubs': 1492, 'quit': 1493, 'police': 1494, 'department': 1495, 'steady': 1496, 'job': 1497, 'best': 1498, 'steal': 1499, 'rob': 1500, 'changes': 1501, 'bellyful': 1502, 'riding': 1503, 'spending': 1504, \"someone's\": 1505, 'earned': 1506, 'driving': 1507, 'arriving': 1508, 'postcards': 1509, 'letters': 1510, 'burning': 1511, 'matches': 1512, 'lifting': 1513, 'latches': 1514, 'longer': 1515, 'stretches': 1516, 'raincoats': 1517, 'chasing': 1518, 'part': 1519, 'child': 1520, 'daisy': 1521, 'chain': 1522, 'blind': 1523, 'hurry': 1524, 'else': 1525, 'lends': 1526, 'hills': 1527, 'dakota': 1528, 'named': 1529, 'ran': 1530, 'guy': 1531, 'hit': 1532, 'walked': 1533, 'booked': 1534, 'local': 1535, 'saloon': 1536, 'equipped': 1537, 'legs': 1538, 'stealing': 1539, 'fancy': 1540, 'magill': 1541, 'herself': 1542, 'lil': 1543, 'nancy': 1544, 'dan': 1545, 'hoe': 1546, 'burst': 1547, 'grinning': 1548, 'danny': 1549, 'showdown': 1550, 'daniel': 1551, 'hot': 1552, 'drew': 1553, 'shot': 1554, 'collapsed': 1555, 'doctor': 1556, 'stinking': 1557, 'gin': 1558, 'proceeded': 1559, 'table': 1560, 'match': 1561, 'scratch': 1562, 'able': 1563, 'gideon': 1564, 'doubt': 1565, \"rocky's\": 1566, 'revival': 1567, 'risk': 1568, 'straight': 1569, 'joan': 1570, 'quizzical': 1571, 'studied': 1572, 'pataphysical': 1573, 'science': 1574, 'nights': 1575, 'test': 1576, 'tube': 1577, 'edison': 1578, 'majoring': 1579, 'medicine': 1580, 'joa': 1581, 'oan': 1582, 'annoyed': 1583, 'wishing': 1584, 'avoid': 1585, 'unpleasant': 1586, 'sce': 1587, 'ene': 1588, 'max': 1589, 'class': 1590, 'fifty': 1591, 'creeps': 1592, 'p': 1593, 'thirty': 1594, 'caught': 1595, 'stands': 1596, 'painting': 1597, 'testimonial': 1598, 'rose': 1599, 'valerie': 1600, 'screaming': 1601, 'gallery': 1602, 'judge': 1603, 'leaving': 1604, 'noise': 1605, 'foot': 1606, 'stare': 1607, 'win': 1608, 'hearing': 1609, 'seeing': 1610, 'state': 1611, 'gather': 1612, 'clowns': 1613, 'complaining': 1614, 'pleasing': 1615, 'reason': 1616, 'nineteen': 1617, 'per': 1618, 'cent': 1619, 'thankful': 1620, 'drive': 1621, 'street': 1622, 'seat': 1623, 'heat': 1624, 'advice': 1625, 'those': 1626, 'declare': 1627, 'pennies': 1628}\n"
          ]
        }
      ],
      "source": [
        "# El índice para cada palabra\n",
        "# El sistema las ordena de las más populares a las menos populares\n",
        "print(tok.word_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "nUDkjy80c77h",
        "outputId": "11caa51a-b166-452b-eac9-13466d9c67bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(<class 'int'>, {'yesterday': 10, 'so': 61, 'seemed': 1, 'all': 177, 'my': 134, 'away': 21, 'far': 1, 'troubles': 1, 'looks': 2, 'here': 33, 'to': 307, 'though': 11, 'stay': 7, 'now': 90, \"they're\": 5, 'it': 125, 'as': 25, 'half': 1, \"i'm\": 66, 'oh': 77, 'be': 108, 'i': 400, 'used': 1, 'man': 34, 'in': 186, 'suddenly': 3, 'believe': 15, 'not': 32, 'the': 376, 'shadow': 1, 'hanging': 1, \"there's\": 14, 'me': 219, 'over': 5, 'a': 270, 'came': 11, 'say': 76, \"wouldn't\": 4, 'why': 20, \"don't\": 74, 'she': 90, 'had': 19, 'go': 38, 'know': 132, 'long': 25, 'something': 13, 'was': 48, 'for': 62, 'game': 3, 'play': 10, 'an': 15, 'easy': 9, 'love': 181, 'said': 14, 'wrong': 6, 'such': 9, 'need': 51, 'hide': 13, 'place': 10, 'when': 71, 'myself': 3, 'mm': 3, 'find': 10, 'mary': 2, 'comes': 20, 'mother': 2, 'of': 109, 'times': 5, 'trouble': 1, 'speaking': 4, 'words': 14, 'wisdom': 7, 'let': 55, 'front': 1, 'standing': 13, 'is': 89, 'right': 25, 'and': 311, 'hour': 1, 'darkness': 1, 'broken': 5, 'whisper': 4, 'hearted': 1, 'world': 32, 'living': 6, 'agree': 2, 'people': 24, 'answer': 9, 'will': 63, 'there': 56, 'may': 10, 'chance': 4, 'they': 37, 'parted': 1, 'that': 126, 'see': 51, 'still': 24, 'light': 5, 'on': 80, 'shines': 2, 'night': 19, 'cloudy': 1, 'tomorrow': 4, 'shine': 3, 'until': 5, 'wake': 1, 'sound': 2, 'up': 23, 'music': 4, 'yeah': 56, 'are': 35, 'flowing': 1, 'out': 46, 'like': 57, 'paper': 5, 'endless': 1, 'rain': 7, 'cup': 2, 'into': 9, 'across': 5, 'wildly': 1, 'slip': 1, 'universe': 4, 'slither': 1, 'sorrow': 1, 'waves': 5, 'joy': 2, 'pools': 1, 'through': 6, 'mind': 17, 'opened': 4, 'drifting': 1, 'deva': 8, 'guru': 8, 'caressing': 1, 'om': 3, 'jai': 8, 'possessing': 1, \"nothing's\": 12, 'change': 16, 'gonna': 33, 'which': 2, 'images': 1, 'before': 15, 'million': 2, 'eyes': 24, 'dance': 9, 'call': 2, 'thoughts': 1, 'meander': 1, 'inside': 3, 'letter': 1, 'box': 1, 'wind': 5, 'restless': 1, 'tumble': 1, 'way': 47, 'make': 28, 'their': 7, 'blindly': 1, 'laughter': 1, 'sounds': 2, 'shades': 1, 'life': 26, 'ears': 6, 'ringing': 3, 'inviting': 1, 'inciting': 1, 'limitless': 1, 'undying': 1, 'suns': 1, 'around': 11, 'calls': 3, 'jude': 23, 'hey': 35, 'bad': 8, 'song': 6, 'take': 23, 'sad': 5, 'better': 13, 'heart': 8, 'remember': 7, 'her': 75, 'your': 84, 'then': 13, 'start': 4, 'afraid': 1, 'you': 484, 'can': 77, 'were': 14, 'made': 7, 'get': 69, 'skin': 2, 'under': 6, 'minute': 1, 'begin': 3, 'refrain': 1, 'feel': 20, 'anytime': 1, 'pain': 3, 'shoulders': 1, 'carry': 17, 'upon': 4, 'who': 13, 'fool': 8, 'plays': 3, 'cool': 2, \"it's\": 73, 'well': 42, 'his': 40, 'making': 6, 'colder': 1, 'little': 36, 'by': 16, 'down': 42, 'nah': 18, 'have': 32, 'found': 8, 'someone': 10, \"you're\": 29, 'with': 79, 'perform': 1, 'waiting': 13, 'just': 29, \"you'll\": 15, 'do': 69, 'shoulder': 1, 'movement': 1, 'places': 4, \"i'll\": 53, 'changed': 6, 'some': 16, 'forever': 12, 'gone': 12, 'remain': 2, 'these': 15, 'moments': 2, 'recall': 2, 'lovers': 4, 'friends': 21, 'dead': 10, 'them': 18, 'but': 65, \"i've\": 18, 'loved': 8, 'one': 42, 'no': 46, 'compares': 2, 'lose': 6, 'meaning': 2, 'memories': 2, 'think': 25, 'new': 7, 'never': 52, 'affection': 4, 'went': 7, 'things': 12, 'often': 4, 'stop': 12, 'about': 13, 'more': 17, 'singing': 6, 'blackbird': 5, 'wings': 2, 'fly': 6, 'learn': 6, 'only': 25, 'moment': 5, 'this': 17, 'arise': 4, 'sunken': 1, 'free': 5, 'dark': 6, 'black': 4, 'sun': 31, 'doo': 1, 'lonely': 19, 'cold': 2, 'winter': 1, 'been': 23, 'darling': 21, 'feels': 3, 'since': 5, 'years': 10, 'faces': 1, 'returning': 1, 'smiles': 5, 'seems': 8, 'ice': 1, 'slowly': 3, 'melting': 1, 'clear': 1, 'once': 25, 'back': 68, 'homeward': 6, 'home': 38, 'cry': 12, 'sleep': 12, 'pretty': 15, 'lullaby': 9, 'golden': 4, 'sing': 22, 'fill': 8, 'slumbers': 3, 'awake': 2, 'rise': 3, 'boy': 21, 'weight': 16, 'time': 29, 'give': 19, 'pillow': 2, 'invitations': 2, 'send': 8, 'middle': 5, 'celebrations': 2, 'break': 5, 'tonight': 4, 'dreams': 5, 'end': 4, 'equal': 3, 'nothing': 21, 'ah': 23, \"can't\": 36, 'done': 6, 'sung': 1, 'how': 30, 'saved': 2, 'save': 4, \"isn't\": 8, 'known': 4, 'shown': 1, 'where': 24, 'nowhere': 22, 'meant': 1, 'together': 57, 'everybody': 3, \"mem'ries\": 1, 'strawberry': 10, 'fields': 10, 'going': 31, \"'cause\": 13, 'real': 8, 'hung': 4, 'closed': 1, 'misunderstanding': 1, 'getting': 3, 'hard': 12, 'works': 2, \"doesn't\": 5, 'matter': 2, 'much': 8, 'tree': 4, 'mean': 11, 'high': 9, 'must': 7, 'low': 4, 'or': 10, 'tune': 2, 'too': 27, 'always': 21, 'sometimes': 1, 'dream': 6, 'yes': 27, 'disagree': 1, 'marketplace': 1, 'has': 11, 'barrow': 1, 'desmond': 7, 'molly': 8, 'singer': 2, 'band': 9, 'face': 9, 'girl': 33, 'says': 5, 'takes': 5, 'chorus': 4, 'him': 9, 'hand': 21, 'bra': 2, 'la': 7, 'di': 6, 'ob': 3, 'da': 3, 'goes': 4, 'store': 1, \"jeweler's\": 1, 'trolley': 1, 'carat': 1, 'twenty': 2, 'ring': 4, 'buys': 1, 'at': 36, 'door': 10, 'gives': 3, 'he': 62, 'couple': 4, 'begins': 2, 'built': 3, 'sweet': 7, 'yard': 2, 'kids': 2, 'running': 3, 'market': 2, 'happy': 9, 'jones': 2, 'after': 4, 'ever': 8, 'children': 13, 'lets': 2, 'lend': 3, 'stays': 2, 'does': 8, 'sings': 1, 'evening': 3, 'older': 4, 'want': 45, 'losing': 2, 'hair': 6, 'fun': 1, 'if': 46, 'from': 35, \"he's\": 12, 'bla': 1, 'many': 8, 'wine': 4, 'greetings': 2, 'sending': 3, 'birthday': 15, 'valentine': 2, 'bottle': 2, \"i'd\": 15, 'quarter': 2, 'lock': 2, 'would': 19, 'three': 15, \"'til\": 1, 'four': 18, 'feed': 6, 'sixty': 6, 'handy': 2, 'word': 2, 'lights': 3, 'mending': 2, 'could': 18, 'fuse': 2, 'mornings': 1, 'ride': 2, 'knit': 2, 'sweater': 2, 'fireside': 2, 'sunday': 3, 'doing': 6, 'weeds': 2, 'ask': 9, 'digging': 2, 'garden': 10, 'summer': 3, 'rent': 3, 'every': 15, 'cottage': 2, 'we': 51, 'wight': 2, 'dear': 12, 'isle': 2, 'shall': 2, 'scrimp': 2, 'grandchildren': 2, 'knee': 5, 'dave': 2, 'view': 4, 'vera': 2, 'line': 2, 'point': 4, 'postcard': 2, 'chuck': 2, 'drop': 3, 'stating': 2, 'indicate': 4, 'wasting': 2, 'sincerely': 2, 'precisely': 2, 'what': 31, 'yours': 1, 'form': 2, 'mine': 14, 'tell': 25, \"somethin'\": 6, 'understand': 8, 'hold': 18, 'please': 21, 'touch': 3, \"feelin'\": 2, 'got': 44, 'nobody': 14, 'somebody': 9, 'first': 4, 'last': 7, 'lasts': 1, 'past': 2, 'really': 7, 'good': 42, 'guess': 3, 'help': 31, 'anybody': 10, 'than': 5, 'younger': 2, 'today': 10, \"anybody's\": 2, 'needed': 2, 'any': 9, 'self': 2, 'days': 10, 'assured': 2, 'feeling': 9, 'doors': 2, 'being': 3, 'round': 13, 'appreciate': 3, 'ground': 4, 'feet': 6, 'ways': 2, \"won't\": 9, 'independence': 1, 'vanish': 1, 'haze': 1, 'insecure': 1, 'moves': 1, 'attracts': 1, 'other': 6, 'lover': 3, 'woos': 1, 'leave': 14, 'knows': 9, 'somewhere': 2, 'smile': 7, 'shows': 3, 'style': 2, 'grow': 3, 'asking': 1, 'stick': 1, 'show': 7, 'flat': 2, 'top': 1, 'come': 43, 'old': 6, \"groovin'\": 1, 'joo': 1, 'eyeballs': 1, 'holy': 1, 'roller': 2, 'joker': 2, 'wear': 1, 'shoeshine': 1, 'football': 1, 'jam': 1, 'toe': 1, 'finger': 2, 'monkey': 1, 'shoot': 2, 'cola': 1, 'coca': 1, 'thing': 5, 'production': 1, 'walrus': 5, 'gumboot': 1, 'sideboard': 1, 'ono': 1, 'spinal': 1, 'cracker': 1, 'below': 3, 'armchair': 1, 'disease': 1, 'coaster': 1, 'early': 2, 'warning': 1, 'muddy': 1, 'water': 1, 'mojo': 1, 'filter': 1, 'looking': 6, 'hill': 6, 'bells': 1, 'heard': 6, 'till': 11, 'sky': 25, 'birds': 2, 'winging': 1, 'saw': 13, 'wonderful': 3, 'roses': 2, 'meadows': 2, 'fragrant': 2, 'dawn': 2, 'dew': 2, 'revolution': 1, 'evolution': 1, 'talk': 9, 'destruction': 1, 'count': 2, 'solution': 1, 'plan': 1, \"we'd\": 3, 'contribution': 1, \"we're\": 21, 'money': 10, 'minds': 1, 'hate': 1, 'wait': 2, 'brother': 2, 'constitution': 1, 'head': 19, 'institution': 1, 'instead': 1, 'chairman': 1, 'pictures': 3, 'carrying': 1, 'mao': 1, \"ain't\": 5, 'anyone': 1, 'anyhow': 1, 'born': 1, 'town': 2, 'lived': 3, 'sea': 8, 'sailed': 2, 'told': 14, 'us': 16, 'land': 3, 'submarines': 1, 'green': 4, 'beneath': 8, 'our': 16, 'submarine': 14, 'yellow': 18, 'live': 10, 'aboard': 1, 'next': 2, 'boatswain': 1, 'speed': 2, 'full': 2, 'mr': 3, 'ahead': 3, 'sergeant': 1, 'cable': 1, 'cut': 2, 'sir': 3, 'aye': 1, 'ease': 1, 'captain': 1, 'blue': 10, 'lifetime': 1, 'catch': 1, \"didn't\": 13, 'name': 3, 'mattered': 1, 'same': 1, 'whenever': 2, 'apart': 4, 'air': 2, 'loud': 3, 'hear': 7, 'near': 5, 'endear': 2, 'sang': 1, 'stand': 4, 'walk': 3, 'key': 1, 'try': 13, 'hmm': 7, 'worry': 2, 'alone': 12, 'day': 36, 'own': 2, 'because': 11, 'sight': 2, 'happens': 1, 'certain': 1, 'turn': 5, 'am': 19, 'gun': 2, 'pigs': 2, 'run': 4, 'crying': 5, 'cornflake': 1, 'sitting': 7, 'van': 1, 'bloody': 1, 'shirt': 1, 'corporation': 1, 't': 1, 'stupid': 2, 'tuesday': 1, 'naughty': 2, \"you've\": 9, 'eggman': 4, 'eggmen': 4, 'goo': 8, \"g'\": 7, 'city': 1, 'policeman': 1, 'joob': 7, 'policemen': 1, 'row': 3, 'lucy': 16, 'custard': 1, 'dripping': 1, \"dog's\": 1, 'eye': 2, 'fishwife': 1, 'crabalocker': 1, 'priestess': 1, 'pornographic': 1, 'knickers': 1, 'english': 3, 'tan': 1, 'fortune': 1, 'maintains': 1, 'choking': 1, 'smokers': 1, 'expert': 1, 'texpert': 1, 'laughs': 1, 'hee': 1, 'ho': 2, 'hah': 1, 'sty': 1, 'snide': 1, 'pilchard': 1, 'semolina': 1, 'climbing': 1, 'eiffel': 1, 'tower': 1, 'elementary': 1, 'krishna': 1, 'penguin': 1, 'hare': 1, 'seen': 5, 'should': 21, 'kicking': 1, 'allen': 1, 'poe': 1, 'edgar': 1, 'juba': 4, 'tired': 7, 'servicible': 1, 'villain': 1, 'set': 2, 'sleeping': 4, 'rest': 1, 'father': 3, \"that's\": 6, 'look': 22, 'while': 10, 'weeps': 6, 'guitar': 6, 'gently': 6, 'floor': 1, 'sweeping': 1, 'needs': 1, 'unfold': 1, 'controlled': 1, 'turning': 2, 'sold': 1, 'notice': 3, 'bought': 1, 'surely': 1, 'mistake': 1, 'learning': 1, 'diverted': 1, 'perverted': 1, 'inverted': 1, 'alerted': 1, 'news': 4, 'read': 4, 'grade': 1, 'lucky': 5, 'rather': 2, 'laugh': 6, 'photograph': 1, 'blew': 1, 'car': 2, 'stared': 1, 'crowd': 2, 'stood': 1, \"they'd\": 1, 'sure': 5, 'house': 3, 'lords': 1, 'film': 1, 'won': 1, 'army': 1, 'war': 1, 'turned': 1, 'book': 2, 'having': 1, 'bed': 5, 'woke': 1, 'fell': 6, 'comb': 1, 'dragged': 1, 'drank': 1, 'downstairs': 1, 'late': 2, 'noticed': 2, 'hat': 1, 'coat': 1, 'grabbed': 1, 'seconds': 1, 'bus': 1, 'smoke': 1, 'upstairs': 1, 'spoke': 1, 'thousand': 2, 'lancashire': 1, 'holes': 3, 'blackburn': 1, 'small': 3, 'hall': 1, 'albert': 1, 'belle': 4, 'ma': 4, 'michelle': 6, 'mots': 3, 'sont': 3, 'vont': 3, 'tres': 6, 'ensemble': 6, 'bien': 6, 'les': 3, 'qui': 3, 'hoping': 3, 'somehow': 1, 'telling': 1, 'photographs': 1, 'penny': 8, 'showing': 1, 'lane': 8, 'barber': 3, 'pleasure': 2, 'motorcar': 1, 'banker': 3, 'corner': 2, 'hello': 15, 'behind': 7, 'mac': 1, 'wears': 1, 'strange': 2, 'pouring': 2, 'very': 5, 'skies': 5, 'suburban': 3, 'sit': 5, 'meanwhile': 3, 'fireman': 2, 'hourglass': 1, 'portrait': 1, 'pocket': 1, 'queen': 2, 'fire': 2, 'clean': 2, 'engine': 1, 'keep': 3, 'likes': 1, 'machine': 1, 'pies': 2, 'fish': 1, 'shelter': 1, 'roundabout': 1, 'selling': 1, 'poppies': 1, 'tray': 1, 'nurse': 1, \"she's\": 23, 'shaves': 2, 'customer': 1, 'anyway': 1, 'another': 9, 'trim': 1, 'rushes': 1, 'jojo': 3, 'loner': 1, 'thought': 6, 'knew': 5, 'left': 5, 'arizona': 1, 'tucson': 1, 'grass': 1, 'california': 1, 'belonged': 9, 'jo': 1, 'loretta': 2, 'woman': 2, 'martin': 1, 'girls': 6, 'coming': 2, 'gets': 2, 'dot': 1, 'await': 1, 'glad': 9, 'party': 3, 'cha': 1, 'turns': 2, 'blows': 1, 'aaaaaahhhhhh': 1, 'aaaaaaaahhhh': 1, 'makes': 5, 'boat': 3, 'river': 1, 'aaaaaaahhhh': 1, 'picture': 2, 'yourself': 5, 'aaaaahhhhhhhhhh': 1, 'tangerine': 1, 'trees': 1, 'marmalade': 1, 'quite': 2, 'flowers': 2, 'cellophane': 1, 'kaleidoscope': 2, 'towering': 1, 'diamonds': 15, 'follow': 1, 'fountain': 1, 'bridge': 1, 'horse': 1, 'eat': 2, 'rocking': 2, 'marshmallow': 1, 'everyone': 4, 'drift': 1, 'newspaper': 1, 'taxis': 1, 'incredibly': 1, 'shore': 1, 'appear': 2, 'clouds': 2, 'climb': 1, 'station': 1, 'train': 1, 'ties': 1, 'porters': 1, 'plasticine': 1, 'glass': 1, 'turnstile': 1, 'kid': 1, 'neighborhood': 1, 'moved': 1, 'write': 4, 'school': 2, 'rock': 5, 'sits': 1, 'roll': 4, 'chair': 2, 'teachers': 1, 'put': 1, 'tacks': 1, 'puts': 2, \"girl's\": 1, 'gum': 1, 'chewing': 1, 'buy': 15, 'behave': 3, 'junior': 3, 'magazine': 1, 'jukebox': 1, 'lost': 3, 'dime': 1, 'worries': 1, 'poop': 1, 'teacher': 2, 'ready': 2, 'hoop': 1, 'rolling': 1, 'spinning': 5, 'hula': 1, \"junior's\": 2, 'mama': 1, 'shop': 2, 'off': 4, 'neighbors': 1, 'canary': 1, 'took': 1, 'cat': 1, 'fed': 1, 'bath': 2, 'laundromat': 1, 'gave': 1, \"mother's\": 1, 'spaniel': 1, 'cocker': 1, \"mama's\": 1, \"you'd\": 3, 'everything': 17, 'tenderly': 1, 'kiss': 5, 'brings': 2, 'ours': 1, 'die': 5, 'bright': 2, 'stars': 2, 'ooh': 3, 'goodbye': 15, 'bye': 1, 'wow': 2, 'hela': 3, 'heba': 3, 'helloa': 3, 'showed': 1, 'room': 6, 'asked': 1, 'wood': 2, 'norwegian': 2, 'anywhere': 1, 'looked': 4, 'biding': 1, \"wasn't\": 1, 'sat': 1, 'rug': 1, 'drinking': 1, 'talked': 1, 'two': 17, 'worked': 2, 'morning': 3, 'started': 1, 'awoke': 1, 'crawled': 1, 'bird': 1, 'flown': 1, 'lit': 1, 'baby': 9, 'shake': 5, 'shout': 6, 'twist': 9, 'work': 14, 'honey': 3, \"goin'\": 1, 'fine': 3, 'closer': 2, 'woo': 3, 'loves': 13, 'yi': 2, 'yay': 2, 'thinking': 2, 'hurt': 3, 'almost': 1, 'kind': 9, 'hurting': 1, 'oo': 3, 'fair': 1, 'pride': 2, 'apologize': 1, 'picks': 1, 'rice': 1, 'rigby': 2, 'eleanor': 2, 'church': 2, 'wedding': 1, 'lives': 1, 'window': 2, 'waits': 2, 'wearing': 2, 'keeps': 8, 'jar': 1, 'writing': 3, 'mckenzie': 2, 'belong': 3, 'sermon': 1, 'working': 4, 'darning': 1, 'socks': 1, 'care': 9, 'died': 3, 'along': 2, 'buried': 1, 'wiping': 1, 'dirt': 1, 'walks': 1, 'grave': 1, 'hands': 4, 'seventeen': 1, 'beyond': 1, 'compare': 1, 'fall': 3, 'boom': 2, 'crossed': 2, 'danced': 2, 'held': 4, 'tight': 4, 'each': 6, 'close': 2, 'miss': 2, 'true': 15, 'loving': 8, 'pretend': 1, 'kissing': 1, 'lips': 2, 'missing': 3, 'hope': 7, \"day's\": 4, 'dog': 3, 'log': 2, 'alright': 7, 'worth': 1, 'earth': 3, 'moan': 2, 'ok': 3, 'holding': 3, 'owww': 2, 'whoa': 8, 'sunshine': 16, 'special': 2, 'sunny': 2, 'shining': 1, 'burns': 1, 'lie': 2, 'shady': 1, 'proud': 1, 'friend': 6, 'diamond': 3, 'anything': 3, 'cos': 1, 'lot': 4, 'tells': 4, 'satisfied': 2, \"your's\": 1, 'evermore': 1, 'ago': 3, 'sgt': 6, 'pepper': 1, 'taught': 1, \"they've\": 1, 'introduce': 2, 'raise': 1, 'guaranteed': 1, 'act': 1, 'hearts': 4, \"pepper's\": 5, 'club': 4, 'enjoy': 1, 'certainly': 1, 'thrill': 1, 'audience': 1, 'lovely': 1, 'might': 2, \"singer's\": 1, 'wants': 4, 'billy': 1, 'shears': 1, 'lead': 6, 'year': 1, 'changing': 1, 'wave': 1, 'deny': 1, 'both': 1, 'everywhere': 7, 'beside': 2, 'share': 2, 'knowing': 4, 'believing': 2, 'dies': 2, 'watching': 2, 'forget': 2, 'met': 5, \"we've\": 3, \"m'mm\": 1, 'aware': 1, 'falling': 6, \"di'n'di\": 2, 'calling': 6, 'again': 11, 'missed': 1, 'kept': 1, 'bup': 1, 'lup': 1, 'imagine': 6, 'heaven': 10, 'hell': 1, 'above': 1, 'countries': 1, 'kill': 1, 'religion': 1, 'dreamer': 2, 'peace': 5, 'someday': 4, 'join': 2, 'possessions': 1, 'wonder': 3, 'greed': 1, 'hunger': 1, 'brotherhood': 1, 'sharing': 1, 'road': 7, 'winding': 3, 'leads': 2, 'disappear': 1, 'wild': 1, 'windy': 1, 'washed': 1, 'tears': 1, 'pool': 1, 'cried': 3, 'tried': 3, 'babe': 7, 'eight': 9, 'week': 8, 'enough': 2, 'listen': 4, 'story': 1, 'sorry': 1, 'regret': 1, 'single': 1, 'promises': 1, 'acts': 1, 'understood': 1, 'young': 3, 'did': 2, 'earn': 1, 'leisure': 1, \"octopus'\": 7, 'shade': 4, \"he'd\": 1, 'warm': 2, 'storm': 1, 'hideaway': 1, 'resting': 1, 'cave': 1, 'swim': 1, 'coral': 1, 'lies': 2, 'ocean': 1, 'safe': 2, 'ten': 3, 'nine': 1, 'seven': 10, 'five': 11, 'six': 10, 'b': 1, 'd': 1, 'c': 2, 'bring': 1, 'tea': 1, 'h': 1, 'g': 1, 'f': 1, 'e': 2, 'j': 1, 'bompa': 8, 'bom': 8, 'sail': 2, 'ship': 2, 'chop': 2, 'skip': 2, 'rope': 2, 'red': 1, 'white': 1, 'brown': 1, 'orange': 1, 'pink': 1, 'dig': 1, 'pony': 1, 'celebrate': 2, 'hog': 1, 'penetrate': 2, 'moon': 1, 'pick': 2, 'radiate': 2, 'stoney': 1, 'imitate': 2, 'blow': 1, 'lorry': 2, 'load': 1, 'syndicate': 2, 'harm': 6, 'beg': 1, 'anymore': 4, 'broke': 4, 'nearly': 4, 'promise': 1, 'trust': 1, \"couldn't\": 1, 'vain': 1, 'learns': 1, 'wink': 1, \"haven't\": 2, 'slept': 1, 'blink': 1, 'fix': 1, 'drink': 1, 'putting': 2, 'joke': 2, 'brain': 2, 'insane': 2, 'weeks': 2, 'upset': 1, 'although': 1, 'cigarette': 1, 'raleigh': 1, 'curse': 1, 'walter': 1, 'sheepdog': 1, 'bullfrog': 1, 'happiness': 1, 'measured': 3, 'miles': 1, 'understands': 1, 'childlike': 1, 'sweaty': 1, 'jackknife': 1, 'innocence': 1, 'fears': 1, 'park': 2, 'big': 1, 'walking': 1, 'frightened': 1, 'wigwam': 1, 'solitude': 1, 'clue': 1, 'roar': 1, 'bulldog': 4, 'woof': 1, 'roof': 1, 'whats': 1, 'ya': 1, 'woah': 7, 'ha': 1, 'wo': 1, 'quiet': 2, 'beach': 1, 'boac': 1, 'flew': 1, 'miami': 1, 'bag': 2, 'flight': 1, 'dreadful': 1, 'ussr': 8, 'gee': 1, 'unpack': 1, 'case': 1, 'phone': 6, 'disconnect': 1, 'knock': 3, 'ukraine': 2, 'west': 2, 'moscow': 2, \"georgia's\": 2, 'hu': 1, 'boys': 1, 'snow': 1, 'peaked': 1, 'mountain': 2, 'south': 1, \"daddy's\": 1, 'farm': 1, \"balalaika's\": 1, 'comrade': 1, 'grin': 2, 'foolish': 1, 'perfectly': 2, 'keeping': 1, 'sees': 5, 'cloud': 1, 'voices': 1, 'hears': 1, 'talking': 2, 'appears': 1, 'feelings': 1, 'listens': 1, 'fools': 1, 'funny': 1, 'negotiations': 1, 'number': 1, 'situation': 1, 'investigation': 1, 'college': 1, 'spent': 1, 'future': 1, 'pay': 3, \"money's\": 1, 'sack': 1, 'jobber': 1, 'monday': 3, 'slow': 1, 'magic': 2, 'limousine': 1, 'bags': 1, \"we'll\": 1, 'soon': 3, 'step': 1, 'gas': 1, 'wipe': 1, 'tear': 1, 'na': 1, 'king': 3, \"everybody's\": 2, 'laughing': 1, 'corazon': 1, 'paramucho': 1, 'quando': 1, 'amore': 2, 'mi': 2, 'defelice': 1, 'parasol': 1, 'mundo': 1, 'pararazzi': 1, 'ferdy': 1, 'chicka': 1, 'obrigado': 1, 'cake': 1, 'cuesto': 1, 'carousel': 1, 'mucho': 1, 'tanta': 1, 'mustard': 1, 'sleeps': 2, 'tryin': 1, 'hole': 1, 'saving': 1, 'clothes': 1, 'bob': 1, 'nose': 1, 'note': 1, 'sister': 1, 'pam': 3, 'stops': 1, 'getter': 1, 'shouts': 1, 'obscene': 1, 'dirty': 3, 'polythene': 3, 'drag': 1, 'dressed': 2, 'dose': 1, 'jackboots': 1, 'kilt': 1, 'killer': 1, 'hilt': 1, 'diller': 1, 'attractively': 1, 'john': 1, 'paul': 1, 'bathroom': 1, 'protected': 1, 'spoon': 1, 'silver': 8, 'wonders': 1, 'sucks': 1, 'thumb': 1, 'lagoon': 1, 'banks': 1, \"sunday's\": 2, \"tuesday's\": 2, 'dancer': 1, \"she'd\": 1, 'fifteen': 1, 'clubs': 1, 'quit': 1, 'police': 1, 'department': 1, 'job': 1, 'steady': 1, 'best': 1, 'rob': 1, 'steal': 1, \"majesty's\": 3, 'nice': 3, 'changes': 1, 'bellyful': 1, 'riding': 1, 'spending': 1, \"someone's\": 1, 'earned': 1, 'driving': 1, 'arriving': 1, 'postcards': 1, 'letters': 1, 'wall': 2, 'matches': 1, 'burning': 1, 'lifting': 1, 'latches': 1, 'stretches': 1, 'raincoats': 1, 'longer': 1, 'chasing': 1, 'prudence': 10, 'brand': 2, 'greet': 2, 'beautiful': 2, 'open': 2, 'part': 1, 'child': 1, 'chain': 1, 'daisy': 1, 'realized': 3, 'happen': 2, 'hoo': 2, 'plans': 4, 'bit': 2, 'command': 2, 'blind': 1, 'hurry': 1, 'else': 1, 'lends': 1, 'hills': 1, 'dakota': 1, 'named': 1, 'rocky': 10, 'raccoon': 3, 'ran': 1, 'guy': 1, 'hit': 1, 'walked': 1, 'local': 1, 'checked': 2, 'himself': 2, 'saloon': 1, 'booked': 1, \"gideon's\": 2, 'bible': 2, 'equipped': 1, 'rival': 2, 'legs': 1, 'stealing': 1, 'fancy': 1, 'magill': 1, 'herself': 1, 'called': 2, 'lil': 1, 'nancy': 1, 'dan': 1, 'hoe': 1, 'grinning': 1, 'burst': 1, 'danny': 1, 'showdown': 1, 'hot': 1, 'shot': 1, 'drew': 1, 'daniel': 1, 'doctor': 1, 'collapsed': 1, 'stinking': 1, 'gin': 1, 'table': 1, 'proceeded': 1, 'match': 1, 'doc': 2, 'scratch': 1, 'able': 1, 'doubt': 1, 'gideon': 1, \"rocky's\": 1, 'revival': 1, 'risk': 1, 'saying': 2, 'straight': 1, 'short': 2, 'fussing': 2, 'fighting': 2, 'crime': 2, 'studied': 1, 'quizzical': 1, 'joan': 1, 'pataphysical': 1, 'science': 1, 'test': 1, 'nights': 1, 'tube': 1, 'majoring': 1, 'medicine': 1, 'maxwell': 4, 'edison': 1, 'joa': 1, 'oan': 1, 'oa': 1, 'bang': 6, \"maxwell's\": 6, 'hammer': 7, 'annoyed': 1, 'avoid': 1, 'wishing': 1, 'unpleasant': 1, 'max': 1, 'class': 1, 'sce': 1, 'ene': 1, 'fifty': 1, 'o': 2, 'creeps': 1, 'caught': 1, 'thirty': 1, 'p': 1, 'stands': 1, 'testimonial': 1, 'painting': 1, 'screaming': 1, 'rose': 1, 'valerie': 1, 'gallery': 1, 'judge': 1, 'leaving': 1, 'noise': 1, 'foot': 1, 'stare': 1, 'even': 3, 'win': 1, 'hearing': 1, 'seeing': 1, 'state': 1, 'clowns': 1, 'gather': 1, 'complaining': 1, 'pleasing': 1, 'reason': 1, 'nineteen': 1, 'taxman': 4, 'cent': 1, 'per': 1, 'thankful': 1, 'drive': 1, 'tax': 4, 'street': 1, 'seat': 1, 'heat': 1, 'advice': 1, 'those': 1, 'pennies': 1, 'declare': 1})\n"
          ]
        }
      ],
      "source": [
        "# Cantidad de veces quea aparece cada palabra en cada \"documento\"\n",
        "# (1 documento = 1 caso de entrada)\n",
        "print(tok.word_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmJWNyxQwfCE"
      },
      "source": [
        "\n",
        "### Definir el modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modelo original**"
      ],
      "metadata": {
        "id": "U8gXvATT7Nsw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "jzTZRXrrwrvi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb126250-054b-46a6-de90-4240efdf86d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 12, 5)             8145      \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 12, 64)            17920     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 12, 64)            0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                33024     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1629)              53757     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114926 (448.93 KB)\n",
            "Trainable params: 114926 (448.93 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Embedding:\n",
        "# input_seq_len = 3 --> ingreso 3 palabras\n",
        "# input_dim = vocab_size --> 1628 palabras distintas\n",
        "# output_dim = 5 --> crear embeddings de tamaño 3 (tamaño variable y ajustable)\n",
        "model.add(Embedding(input_dim=vocab_size+1, output_dim=5, input_shape=(max_context_size,)))\n",
        "\n",
        "model.add(LSTM(64, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(64)) # La última capa LSTM no lleva return_sequences\n",
        "model.add(Dense(32, activation='relu'))\n",
        "\n",
        "# Predicción de clasificación con softmax\n",
        "# La salida vuelve al espacio de 1628 palabras posibles\n",
        "model.add(Dense(vocab_size+1, activation='softmax'))\n",
        "\n",
        "# Clasificación multiple categórica --> loss = categorical_crossentropy\n",
        "# notar que usamos la versión Sparse para utilizar sólo índices en lugar de OHE\n",
        "model.compile(loss=SparseCategoricalCrossentropy(), optimizer='adam')\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modelo 2: más capas convolucionales y bidireccionales**"
      ],
      "metadata": {
        "id": "ozVOyRIG7SAT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Segundo modelo\n",
        "model_2 = Sequential()\n",
        "\n",
        "# Embedding:\n",
        "# input_seq_len = 3 --> ingreso 3 palabras\n",
        "# input_dim = vocab_size --> 1628 palabras distintas\n",
        "# output_dim = 5 --> crear embeddings de tamaño 3 (tamaño variable y ajustable)\n",
        "model_2.add(Embedding(input_dim=vocab_size+1, output_dim=5, input_shape=(max_context_size,)))\n",
        "\n",
        "# Capas convolucionales:\n",
        "model_2.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
        "model_2.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "# Capas recurrentes bidireccionales (BRNN):\n",
        "model_2.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model_2.add(Dropout(0.2))\n",
        "\n",
        "# Capa LSTM adicional:\n",
        "model_2.add(Bidirectional(LSTM(64)))\n",
        "\n",
        "# Capa densa con ReLU:\n",
        "model_2.add(Dense(32, activation='relu'))\n",
        "\n",
        "# Predicción de clasificación con softmax:\n",
        "# La salida vuelve al espacio de 1628 palabras posibles\n",
        "model_2.add(Dense(vocab_size+1, activation='softmax'))\n",
        "\n",
        "# Clasificación multiple categórica --> loss = categorical_crossentropy\n",
        "# notar que usamos la versión Sparse para utilizar sólo índices en lugar de OHE\n",
        "model_2.compile(loss=SparseCategoricalCrossentropy(), optimizer='adam')\n",
        "\n",
        "model_2.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q244wnyOSuVE",
        "outputId": "f7508c5f-4bfc-4762-bc73-fbd287816457"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 12, 5)             8145      \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 10, 32)            512       \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1  (None, 5, 32)             0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 5, 128)            49664     \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 5, 128)            0         \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 128)               98816     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 32)                4128      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1629)              53757     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 215022 (839.93 KB)\n",
            "Trainable params: 215022 (839.93 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modelo 3: añadimos aún más capas convolucionales y bidireccionales**"
      ],
      "metadata": {
        "id": "OEL7iBOR7dfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizamos un tercer modelo\n",
        "model_3 = Sequential()\n",
        "\n",
        "# Embedding:\n",
        "# input_seq_len = 3 --> ingreso 3 palabras\n",
        "# input_dim = vocab_size --> 1628 palabras distintas\n",
        "# output_dim = 5 --> crear embeddings de tamaño 3 (tamaño variable y ajustable)\n",
        "model_3.add(Embedding(input_dim=vocab_size+1, output_dim=5, input_shape=(max_context_size,)))\n",
        "\n",
        "# Capas convolucionales:\n",
        "model_3.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
        "model_3.add(MaxPooling1D(pool_size=2))\n",
        "model_3.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "model_3.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "# Capas recurrentes bidireccionales (BRNN):\n",
        "model_3.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model_3.add(Dropout(0.2))\n",
        "model_3.add(Bidirectional(LSTM(128)))\n",
        "\n",
        "# Capa densa con ReLU:\n",
        "model_3.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Predicción de clasificación con softmax:\n",
        "# La salida vuelve al espacio de 1628 palabras posibles\n",
        "model_3.add(Dense(vocab_size+1, activation='softmax'))\n",
        "\n",
        "# Clasificación multiple categórica --> loss = categorical_crossentropy\n",
        "# notar que usamos la versión Sparse para utilizar sólo índices en lugar de OHE\n",
        "model_3.compile(loss=SparseCategoricalCrossentropy(), optimizer='adam')\n",
        "\n",
        "model_3.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC5mr4lmUUr9",
        "outputId": "2fb7ebca-c4aa-4e14-860f-5ed5c8d2120e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 12, 5)             8145      \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 10, 32)            512       \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPoolin  (None, 5, 32)             0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 3, 64)             6208      \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPoolin  (None, 1, 64)             0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirecti  (None, 1, 128)            66048     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 1, 128)            0         \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirecti  (None, 256)               263168    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                16448     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1629)              105885    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 466414 (1.78 MB)\n",
            "Trainable params: 466414 (1.78 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dado que por el momento no hay implementaciones adecuadas de la perplejidad que puedan operar en tiempo de entrenamiento, armaremos un Callback *ad-hoc* que la calcule en cada epoch.\n",
        "\n",
        "**Nota**: un Callback es una rutina gatillada por algún evento, son muy útiles para relevar datos en diferentes momentos del desarrollo del modelo. En este caso queremos hacer un cálculo cada vez que termina una epoch de entrenamiento."
      ],
      "metadata": {
        "id": "YWK3z85sQfUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PplCallback(keras.callbacks.Callback):\n",
        "\n",
        "    '''\n",
        "    Este callback es una solución ad-hoc para calcular al final de cada epoch de\n",
        "    entrenamiento la métrica de Perplejidad sobre un conjunto de datos de validación.\n",
        "    La perplejidad es una métrica cuantitativa para evaluar la calidad de la generación de secuencias.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, val_data):\n",
        "      # El callback lo inicializamos con secuencias de validación sobre las cuales\n",
        "      # mediremos la perplejidad\n",
        "      self.val_data = val_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "\n",
        "        # en `scores` iremos guardando la perplejidad de cada secuencia\n",
        "        scores = []\n",
        "\n",
        "        # nos movemos en todas las secuencias de los datos de validación\n",
        "        for seq in self.val_data:\n",
        "\n",
        "          # armamos todas las subsecuencias\n",
        "          subseq = [seq[:i] for i in range(len(seq))]\n",
        "          target = [seq[i] for i in range(len(seq))]\n",
        "          bb = pad_sequences(subseq, maxlen=max_context_size, padding='pre')\n",
        "\n",
        "          # utilizamos el modelo para que haga su predicción en cada subsecuencia\n",
        "          # (son las probabilidades condicionadas)\n",
        "          predictions = self.model.predict(bb,verbose=0)\n",
        "\n",
        "          # en `probs`iremos guardando las probabilidades de los términos target\n",
        "          probs = []\n",
        "\n",
        "          for idx_seq, idx_vocab in enumerate(target):\n",
        "              probs.append(predictions[idx_seq,idx_vocab])\n",
        "\n",
        "          # calculamos la perplejidad por medio de logaritmos\n",
        "          scores.append(np.exp(-np.sum(np.log(probs))/len(target)))\n",
        "\n",
        "        # promediamos todos los scores e imprimimos el valor promedio\n",
        "        print(f'\\n mean perplexity: {np.mean(scores)} \\n')"
      ],
      "metadata": {
        "id": "zUHX3r5JD-MG"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenamiento"
      ],
      "metadata": {
        "id": "8HBZIwR0gruA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "oQq1PHDkxDvN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "outputId": "a60d613c-432b-4eec-94e8-3f0e65d371fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "478/479 [============================>.] - ETA: 0s - loss: 5.9917\n",
            " mean perplexity: 2211.7509153774054 \n",
            "\n",
            "479/479 [==============================] - 45s 83ms/step - loss: 5.9907\n",
            "Epoch 2/50\n",
            "479/479 [==============================] - ETA: 0s - loss: 5.6623\n",
            " mean perplexity: 3532.978758492655 \n",
            "\n",
            "479/479 [==============================] - 41s 85ms/step - loss: 5.6623\n",
            "Epoch 3/50\n",
            "476/479 [============================>.] - ETA: 0s - loss: 5.4756\n",
            " mean perplexity: 16434.440287067107 \n",
            "\n",
            "479/479 [==============================] - 47s 98ms/step - loss: 5.4757\n",
            "Epoch 4/50\n",
            "177/479 [==========>...................] - ETA: 5s - loss: 5.2794"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-f719ff38b692>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# fiteamos, nótese el agregado del callback con su inicialización. El batch_size lo podemos seleccionar a mano\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# en general, mientras más grande mejor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPplCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_sentences_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# fiteamos, nótese el agregado del callback con su inicialización. El batch_size lo podemos seleccionar a mano\n",
        "# en general, mientras más grande mejor.\n",
        "hist = model.fit(X, y, epochs=50, callbacks=[PplCallback(tokenized_sentences_val)], batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Luego de 3 épocas vemos que el valor de perplexity sube.\n",
        "- Se decide cortar el entrenamiento."
      ],
      "metadata": {
        "id": "WJ5khhuI94Qf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entreno el segundo modelo\n",
        "hist_2 = model_2.fit(X, y, epochs=50, callbacks=[PplCallback(tokenized_sentences_val)], batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "dBzfxXEtTann",
        "outputId": "c4efe750-c6dc-4d7a-e8d7-07f256951248"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "479/479 [==============================] - ETA: 0s - loss: 5.9639\n",
            " mean perplexity: 1451.455668328834 \n",
            "\n",
            "479/479 [==============================] - 61s 110ms/step - loss: 5.9639\n",
            "Epoch 2/50\n",
            "477/479 [============================>.] - ETA: 0s - loss: 5.5918\n",
            " mean perplexity: 5702.713409936117 \n",
            "\n",
            "479/479 [==============================] - 39s 81ms/step - loss: 5.5905\n",
            "Epoch 3/50\n",
            "479/479 [==============================] - ETA: 0s - loss: 5.3796\n",
            " mean perplexity: 17672.251499921756 \n",
            "\n",
            "479/479 [==============================] - 38s 79ms/step - loss: 5.3796\n",
            "Epoch 4/50\n",
            "163/479 [=========>....................] - ETA: 6s - loss: 5.1890"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-09fbfb4e4825>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Entreno el segundo modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhist_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPplCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_sentences_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Comparando con el modelo original, el perplexity sigue subiendo.\n",
        "- Se decide cortar el entrenamiento."
      ],
      "metadata": {
        "id": "vEIeetpT-F91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entreno el tercer modelo\n",
        "hist_3 = model_3.fit(X, y, epochs=50, callbacks=[PplCallback(tokenized_sentences_val)], batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "fmEb4SzXUj2c",
        "outputId": "82a9cb0a-8a34-4b4d-915e-8a82b9f8a638"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "477/479 [============================>.] - ETA: 0s - loss: 6.0004\n",
            " mean perplexity: 2154.548415534993 \n",
            "\n",
            "479/479 [==============================] - 65s 78ms/step - loss: 6.0000\n",
            "Epoch 2/50\n",
            "477/479 [============================>.] - ETA: 0s - loss: 5.7158\n",
            " mean perplexity: 2437.479786938389 \n",
            "\n",
            "479/479 [==============================] - 36s 76ms/step - loss: 5.7152\n",
            "Epoch 3/50\n",
            "476/479 [============================>.] - ETA: 0s - loss: 5.6668\n",
            " mean perplexity: 5478.08256252218 \n",
            "\n",
            "479/479 [==============================] - 36s 75ms/step - loss: 5.6672\n",
            "Epoch 4/50\n",
            "168/479 [=========>....................] - ETA: 5s - loss: 5.6123"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-039b191b0af3>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Entreno el tercer modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhist_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPplCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_sentences_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Con este tercer modelo, podemos ver que exite una gran mejora, pero la perplexity sigue subiendo así que no podemos resolver de la mejora manera.\n",
        "- Se decide cortar el entrenamiento."
      ],
      "metadata": {
        "id": "Mrdr7C-m_Od_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Probamos con X2 e y2**"
      ],
      "metadata": {
        "id": "vyrhxJGQ76vK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fiteamos, nótese el agregado del callback con su inicialización. El batch_size lo podemos seleccionar a mano\n",
        "# en general, mientras más grande mejor.\n",
        "hist = model.fit(X2, y2, epochs=50, callbacks=[PplCallback(tokenized_sentences_val)], batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "pOPph0Yb7_mx",
        "outputId": "f6e11192-ae5c-4388-e8a6-d5c65495d5c4"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "622/625 [============================>.] - ETA: 0s - loss: 5.1629\n",
            " mean perplexity: 19767.268920897553 \n",
            "\n",
            "625/625 [==============================] - 70s 66ms/step - loss: 5.1611\n",
            "Epoch 2/50\n",
            "625/625 [==============================] - ETA: 0s - loss: 4.9851\n",
            " mean perplexity: 54769.74406464513 \n",
            "\n",
            "625/625 [==============================] - 41s 65ms/step - loss: 4.9851\n",
            "Epoch 3/50\n",
            "623/625 [============================>.] - ETA: 0s - loss: 4.8613\n",
            " mean perplexity: 489060.36950228014 \n",
            "\n",
            "625/625 [==============================] - 39s 62ms/step - loss: 4.8615\n",
            "Epoch 4/50\n",
            "144/625 [=====>........................] - ETA: 6s - loss: 4.7624"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-93ec3a5ebbd8>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# fiteamos, nótese el agregado del callback con su inicialización. El batch_size lo podemos seleccionar a mano\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# en general, mientras más grande mejor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPplCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_sentences_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Entreno el segundo modelo\n",
        "hist_2 = model_2.fit(X2, y2, epochs=50, callbacks=[PplCallback(tokenized_sentences_val)], batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "Rey55-T48RLl",
        "outputId": "76d4b546-9368-4b36-c77f-2392b71820f0"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "624/625 [============================>.] - ETA: 0s - loss: 5.4280\n",
            " mean perplexity: 259825.48942084692 \n",
            "\n",
            "625/625 [==============================] - 105s 81ms/step - loss: 5.4280\n",
            "Epoch 2/50\n",
            "625/625 [==============================] - ETA: 0s - loss: 5.2549\n",
            " mean perplexity: 430225.3325464904 \n",
            "\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 5.2549\n",
            "Epoch 3/50\n",
            "624/625 [============================>.] - ETA: 0s - loss: 5.1549\n",
            " mean perplexity: 509352.4216083253 \n",
            "\n",
            "625/625 [==============================] - 40s 64ms/step - loss: 5.1548\n",
            "Epoch 4/50\n",
            "447/625 [====================>.........] - ETA: 4s - loss: 5.0840"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-7ee2e894ad7c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Entreno el segundo modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhist_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPplCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_sentences_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Entreno el tercer modelo\n",
        "hist_3 = model_3.fit(X2, y2, epochs=50, callbacks=[PplCallback(tokenized_sentences_val)], batch_size=32)"
      ],
      "metadata": {
        "id": "_KqEeNJN8REP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Con este nuevo dataset (X2,y2) tenemos mejores resultados comparativos en las primeras épocas en loss pero no en perplexity.\n",
        "- ¿Vale la pena plantearse usar loss en vez de perplexity?"
      ],
      "metadata": {
        "id": "iWpBxYkOARtZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Graficamos los resultados**"
      ],
      "metadata": {
        "id": "504sKabX8bnz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_orBXOrCsNn"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Entrenamiento\n",
        "epoch_count = range(1, len(hist.history['accuracy']) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=hist.history['accuracy'], label='train')\n",
        "sns.lineplot(x=epoch_count,  y=hist.history['val_accuracy'], label='valid')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Nuevo corpus, mayor al de canciones"
      ],
      "metadata": {
        "id": "DXI-64WpAJBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "91WnFx-pAPUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HxPUnCbWAPJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ev1r__xOAO_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN6Fg_BsxJe6"
      },
      "source": [
        "\n",
        "### Predicción de próxima palabra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iy_AXWQWzeeE"
      },
      "outputs": [],
      "source": [
        "# Keras pad_sequences\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences\n",
        "# Si la secuencia de entrada supera al input_seq_len (3) se trunca\n",
        "# Si la secuencia es más corta se agregna ceros al comienzo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBvKHFPmzpy2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f66080a1-5b92-48fd-b313-a129403ff43d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.9/91.9 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Se utilizará gradio para ensayar el modelo\n",
        "# Herramienta poderosa para crear interfaces rápidas para ensayar modelos\n",
        "# https://gradio.app/\n",
        "import sys\n",
        "!{sys.executable} -m pip install gradio --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNyBykvhzs7-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "outputId": "a7080560-5af0-4507-f59a-7d819920d157"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://91124fb4030ff59298.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://91124fb4030ff59298.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 713ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://91124fb4030ff59298.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def model_response(human_text):\n",
        "\n",
        "    # Encodeamos\n",
        "    encoded = tok.texts_to_sequences([human_text])[0]\n",
        "    # Si tienen distinto largo\n",
        "    encoded = pad_sequences([encoded], maxlen=3, padding='pre')\n",
        "\n",
        "    # Predicción softmax\n",
        "    y_hat = model.predict(encoded).argmax(axis=-1)\n",
        "\n",
        "    # Debemos buscar en el vocabulario la palabra\n",
        "    # que corresopnde al indice (y_hat) predicho por le modelo\n",
        "    out_word = ''\n",
        "    for word, index in tok.word_index.items():\n",
        "        if index == y_hat:\n",
        "            out_word = word\n",
        "            break\n",
        "\n",
        "    # Agrego la palabra a la frase predicha\n",
        "    return human_text + ' ' + out_word\n",
        "\n",
        "iface = gr.Interface(fn=model_response,\n",
        "                     inputs=[\"textbox\"],\n",
        "                     outputs=\"text\")#,    layout=\"vertical\")\n",
        "\n",
        "iface.launch(debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCeMWWupxN1-"
      },
      "source": [
        "### Generación de secuencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwbS_pfhxvB3"
      },
      "outputs": [],
      "source": [
        "def generate_seq(model, tokenizer, seed_text, max_length, n_words):\n",
        "    \"\"\"\n",
        "        Exec model sequence prediction\n",
        "\n",
        "        Args:\n",
        "            model (keras): modelo entrenado\n",
        "            tokenizer (keras tokenizer): tonenizer utilizado en el preprocesamiento\n",
        "            seed_text (string): texto de entrada (input_seq)\n",
        "            max_length (int): máxima longitud de la sequencia de entrada\n",
        "            n_words (int): números de palabras a agregar a la sequencia de entrada\n",
        "        returns:\n",
        "            output_text (string): sentencia con las \"n_words\" agregadas\n",
        "    \"\"\"\n",
        "    output_text = seed_text\n",
        "\t# generate a fixed number of words\n",
        "    for _ in range(n_words):\n",
        "\t\t# Encodeamos\n",
        "        encoded = tokenizer.texts_to_sequences([output_text])[0]\n",
        "\t\t# Si tienen distinto largo\n",
        "        encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "\t\t# Predicción softmax\n",
        "        y_hat = model.predict(encoded).argmax(axis=-1)\n",
        "\t\t# Vamos concatenando las predicciones\n",
        "        out_word = ''\n",
        "\n",
        "        # Debemos buscar en el vocabulario la palabra\n",
        "        # que corresopnde al indice (y_hat) predicho por le modelo\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == y_hat:\n",
        "                out_word = word\n",
        "                break\n",
        "\n",
        "\t\t# Agrego las palabras a la frase predicha\n",
        "        output_text += ' ' + out_word\n",
        "    return output_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoFqRC5pxzqS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "7ba768be-a7ff-4ed4-ae6d-89cf217c1d10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"hey jude don't help you\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "input_text='hey jude don\\'t'\n",
        "\n",
        "generate_seq(model, tok, input_text, max_length=3, n_words=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drJ6xn5qW1Hl"
      },
      "source": [
        "###  Beam search y muestreo aleatorio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vovn9XZW1Hl"
      },
      "outputs": [],
      "source": [
        "# funcionalidades para hacer encoding y decoding\n",
        "\n",
        "def encode(text,max_length=3):\n",
        "\n",
        "    encoded = tok.texts_to_sequences([text])[0]\n",
        "    encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "    return encoded\n",
        "\n",
        "def decode(seq):\n",
        "    return tok.sequences_to_texts([seq])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_lZiQwkW1Hl"
      },
      "outputs": [],
      "source": [
        "from scipy.special import softmax\n",
        "\n",
        "# función que selecciona candidatos para el beam search\n",
        "def select_candidates(pred,num_beams,vocab_size,history_probs,history_tokens,temp=1):\n",
        "\n",
        "  # colectar todas las probabilidades para la siguiente búsqueda\n",
        "  pred_large = []\n",
        "\n",
        "  for idx,pp in enumerate(pred):\n",
        "    pred_large.extend(np.log(pp+1E-10)+history_probs[idx])\n",
        "\n",
        "  pred_large = np.array(pred_large)\n",
        "\n",
        "  # criterio de selección\n",
        "  # idx_select = np.argsort(pred_large)[::-1][:num_beams] # beam search determinista\n",
        "  idx_select = np.random.choice(np.arange(pred_large.shape[0]), num_beams, p=softmax(pred_large/temp)) # beam search con muestreo\n",
        "\n",
        "  # traducir a índices de token en el vocabulario\n",
        "  new_history_tokens = np.concatenate((np.array(history_tokens)[idx_select//vocab_size],\n",
        "                        np.array([idx_select%vocab_size]).T),\n",
        "                      axis=1)\n",
        "\n",
        "  # devolver el producto de las probabilidades (log) y la secuencia de tokens seleccionados\n",
        "  return pred_large[idx_select.astype(int)], new_history_tokens.astype(int)\n",
        "\n",
        "\n",
        "def beam_search(model,num_beams,num_words,input):\n",
        "\n",
        "    # first iteration\n",
        "\n",
        "    # encode\n",
        "    encoded = encode(input)\n",
        "\n",
        "    # first prediction\n",
        "    y_hat = np.squeeze(model.predict(encoded))\n",
        "\n",
        "    # get vocabulary size\n",
        "    vocab_size = y_hat.shape[0]\n",
        "\n",
        "    # initialize history\n",
        "    history_probs = [0]*num_beams\n",
        "    history_tokens = [encoded[0]]*num_beams\n",
        "\n",
        "    # select num_beams candidates\n",
        "    history_probs, history_tokens = select_candidates([y_hat],\n",
        "                                        num_beams,\n",
        "                                        vocab_size,\n",
        "                                        history_probs,\n",
        "                                        history_tokens)\n",
        "\n",
        "    # beam search loop\n",
        "    for i in range(num_words-1):\n",
        "\n",
        "      preds = []\n",
        "\n",
        "      for hist in history_tokens:\n",
        "\n",
        "        # actualizar secuencia de tokens\n",
        "        input_update = np.array([hist[i+1:]]).copy()\n",
        "\n",
        "        # predicción\n",
        "        y_hat = np.squeeze(model.predict(input_update))\n",
        "\n",
        "        preds.append(y_hat)\n",
        "\n",
        "      history_probs, history_tokens = select_candidates(preds,\n",
        "                                                        num_beams,\n",
        "                                                        vocab_size,\n",
        "                                                        history_probs,\n",
        "                                                        history_tokens)\n",
        "\n",
        "    return history_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GeLqAoOYW1Hm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "outputId": "8fef23d3-e25f-4b66-d12a-d25613e40d9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 12), found shape=(None, 3)\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-0a61a96453eb>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# predicción con beam search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msalidas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeam_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_beams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"when i find myself in times\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-42-72ac958562bd>\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(model, num_beams, num_words, input)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# predicción\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_update\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 12), found shape=(None, 3)\n"
          ]
        }
      ],
      "source": [
        "# predicción con beam search\n",
        "salidas = beam_search(model,num_beams=10,num_words=6,input=\"when i find myself in times\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2S3_I3S1W1Hm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "5d692054-7400-4410-d2f6-9e24f80a18be"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'salidas' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-6c81da74e3ed>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# veamos las salidas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msalidas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'salidas' is not defined"
          ]
        }
      ],
      "source": [
        "# veamos las salidas\n",
        "decode(salidas[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2SHmXbgxQH9"
      },
      "source": [
        "### Conclusiones\n",
        "El modelo entrenado tuvo un muy mail desempeño en el entrenamiento además de overfitting. Cuestiones que podrían mejorarse:\n",
        "- Agregar más capas o neuronaes\n",
        "- Incrementar la cantidad de épocas\n",
        "- Agregar BRNN\n",
        "\n",
        "Es importante destacar que en este ejemplo estamos entrenando nuestro propios Embeddings, y para ello se requiere mucha data. En los ejemplos que realizaremos de aquí en más utilizaremos más datos, embeddings pre-enternados o modelos pre-entrenados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_LlqmtEW1Hn"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}